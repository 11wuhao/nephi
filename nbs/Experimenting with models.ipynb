{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Russell Ault\n",
    "\n",
    "# This Notebook Contains code for exploring the functionality of the Pytorch Handwriting Recognition Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It is clear to me that I need to write interactive code to load a model that we have trained and test it on a validation set, and have it output accuracy and word error rates. \n",
    "\n",
    "## The present way that the library is written is clearly not easily conducive to this\n",
    "\n",
    "## Here are some comments I have about the code and how to improve it:\n",
    "- In evaluating model accuracy a character by character accuracy is being used, not an edit distance. I need to put character and word error rates into the model. I should include a mean and sd of these parameters.\n",
    "- I think I need to just run the validation code right now to see what it does.\n",
    "- I think that the main python module should be refactored to allow its use in other python modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Main Functionality in Notebook fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from warpctc_pytorch import CTCLoss\n",
    "import os\n",
    "import utils\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (crnn.py, line 70)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"models/crnn.py\"\u001b[1;36m, line \u001b[1;32m70\u001b[0m\n\u001b[1;33m    self.rnn = nn.Sequential(\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import models.crnn as crnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latin-1\n"
     ]
    }
   ],
   "source": [
    "import sys  \n",
    "stdout = sys.stdout\n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('latin-1')\n",
    "from model_error import cer, wer\n",
    "\n",
    "\n",
    "#My workaround was that at the top of the script, I import sys, and store sys.stdout in a separate variable, e.g. stdout.\n",
    "sys.stdout = stdout\n",
    "print(sys.getdefaultencoding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model_error import cer, wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(3+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--trainroot', required=True, help='path to dataset')\n",
    "parser.add_argument('--valroot', required=True, help='path to dataset')\n",
    "parser.add_argument('--workers', type=int, help='number of data loading workers', default=2)\n",
    "parser.add_argument('--batchSize', type=int, default=64, help='input batch size')\n",
    "parser.add_argument('--imgH', type=int, default=32, help='the height of the input image to network')\n",
    "parser.add_argument('--imgW', type=int, default=100, help='the width of the input image to network')\n",
    "parser.add_argument('--nh', type=int, default=256, help='size of the lstm hidden state')\n",
    "parser.add_argument('--niter', type=int, default=25, help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=0.01, help='learning rate for Critic, default=0.00005')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
    "parser.add_argument('--ngpu', type=int, default=1, help='number of GPUs to use')\n",
    "parser.add_argument('--crnn', default='', help=\"path to crnn (to continue training)\")\n",
    "parser.add_argument('--alphabet', type=str, default='0123456789abcdefghijklmnopqrstuvwxyz')\n",
    "parser.add_argument('--experiment', default=None, help='Where to store samples and models')\n",
    "parser.add_argument('--displayInterval', type=int, default=500, help='Interval to be displayed')\n",
    "parser.add_argument('--n_test_disp', type=int, default=10, help='Number of samples to display when test')\n",
    "parser.add_argument('--valInterval', type=int, default=500, help='Interval to be displayed')\n",
    "parser.add_argument('--saveInterval', type=int, default=500, help='Interval to be displayed')\n",
    "parser.add_argument('--adam', action='store_true', help='Whether to use adam (default is rmsprop)')\n",
    "parser.add_argument('--adadelta', action='store_true', help='Whether to use adadelta (default is rmsprop)')\n",
    "parser.add_argument('--keep_ratio', action='store_true', help='whether to keep ratio for image resize')\n",
    "parser.add_argument('--random_sample', action='store_true', help='whether to sample the dataset with random sampler')\n",
    "opt = parser.parse_args()\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if experiment is None:\n",
    "    experiment = 'expr'\n",
    "os.system('mkdir {0}'.format(experiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainroot = \"/home/ubuntu/russell/nephi/data/lmdb/train\"\n",
    "valroot = \"/home/ubuntu/russell/nephi/data/lmdb/val\"\n",
    "batchSize = 64\n",
    "nh = 256                  # size of the LSTM hidden state\n",
    "imgW = 100\n",
    "imgH = 32\n",
    "ngpu = 1\n",
    "beta1 = 0.5\n",
    "lr = 0.0001\n",
    "workers = 10\n",
    "keep_ratio = True\n",
    "adam = True\n",
    "adadelta = False\n",
    "n_test_disp = 100\n",
    "\n",
    "alph_file_dylan = \"/home/ubuntu/dylan/nephi/alphabet.txt\"\n",
    "alph_file_russell = \"/home/ubuntu/russell/nephi/alphabet.txt\"\n",
    "alphabet = '0123456789abcdefghijklmnopqrstuvwxyzB- EÂ¬Ã¼.RSÅ«J/DHA:K¤¿ZLGFNTPCOVWIM<8d>Ä<81><9f>,<93>È³¶'\n",
    "#0123456789abcdefghijklmnopqrstuvwxyzW VCGū¬.HM,ILAZ:BTÿSER<BC>JFāP<9F>NDKOȳ<B6>\n",
    "#<A4><8D>()—̈-<84><93>Q<96>/Y<BE>U<>+  # This is what I got from Dylan's file\n",
    "\n",
    "untrained_crnn_dylan = \"/home/ubuntu/dylan/nephi/expr/netCRNN_1_100.pth\"\n",
    "#less trained 29\n",
    "lesstrained_crnn_dylan = \"/home/ubuntu/dylan/nephi/expr/netCRNN_1000_100.pth\"\n",
    "trained_crnn_russell = \"/home/ubuntu/russell/nephi/expr/netCRNN_3870_100.pth\"\n",
    "trained_crnn_dylan = \"/home/ubuntu/dylan/nephi/expr/netCRNN_3210_100.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manualSeed = random.randint(1, 10000)  # fix seed\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "np.random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "cuda = True\n",
    "\n",
    "#if torch.cuda.is_available() and not cuda:\n",
    "#    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "train_dataset = dataset.lmdbDataset(root=trainroot)\n",
    "sampler = dataset.randomSequentialSampler(train_dataset, batchSize)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batchSize, sampler=sampler,\n",
    "    num_workers=int(workers),\n",
    "    collate_fn=dataset.alignCollate(imgH=imgH, imgW=imgW, keep_ratio=keep_ratio))\n",
    "\n",
    "training_eval_set = dataset.lmdbDataset(\n",
    "    root=trainroot, transform=dataset.resizeNormalize((imgW, imgH))) \n",
    "test_dataset = dataset.lmdbDataset(\n",
    "    root=valroot, transform=dataset.resizeNormalize((imgW, imgH)))   # I have changed this line from the original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "class Normalize(object):\n",
    "\n",
    "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "        self.toTensor = transforms.ToTensor()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        #img = img.resize(self.size, self.interpolation)\n",
    "        img = self.toTensor(img)\n",
    "        img.sub_(0.5).div_(0.5)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_loader = dataset.lmdbDataset(root=trainroot, transform=Normalize((imgW, imgH)))\n",
    "\n",
    "trainer = torch.utils.data.DataLoader(\n",
    "    train_test_loader, batch_size=batchSize, sampler=sampler,\n",
    "    num_workers=int(workers),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_loader\n",
    "trainer = iter(train_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = trainer.next()\n",
    "cpu_images, _ = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.87450981,  0.87450981,  0.83529413, ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 0.81176472,  0.81176472,  0.82745099, ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 0.8509804 ,  0.85882354,  0.89019608, ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        ..., \n",
       "        [ 1.        ,  1.        ,  1.        , ...,  0.89019608,\n",
       "          0.88235295,  0.89019608],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  0.9137255 ,\n",
       "          0.87450981,  0.84313726],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  0.92156863,\n",
       "          0.85882354,  0.80392158]]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_images.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions on image resizing:\n",
    "- Does the keep ratio resizing do the largest aspect ratio within a batch, or within the whole dataset (I think batch)?\n",
    "- For applying same approach to test set, do i need to use the largest training aspect ratio, or, if training aspect ratio is by batch, do I just do largest by batch within the test set?\n",
    "- Can the CNN-RNN take any dimension? (different widths for different batches, or even every photo being a different width)?\n",
    "- With the rules of matrix multiplication, it makes sense to me that the aspect ratio would have to be the same in a given batch, else you couldn't use a matrix for the RNN part (and maybe the CNN too, depending on how it is calculated)\n",
    "      \n",
    "### From this morning's thoughts (23 February 2018):\n",
    "- I think the best first stab at a complete solution would be to use the BYU heigh size and just let the code do renormalizing on its own.\n",
    "- also, I should have the validation function load a data loader, rather than an lmdb dataset, or I just make sure the same aspect ratio thing is done.\n",
    "- Well, with the training set, I just want to load the original training batches, given how the aspect ratio has been done, validation can do their own thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need more than 1 value to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-c59fc4aece93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcpu_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mimage_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_count\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcpu_images\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mwidths\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mheights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: need more than 1 value to unpack"
     ]
    }
   ],
   "source": [
    "#trainer\n",
    "#max_iter = min(max_iter, len(data_loader))\n",
    "#max_iter = len(data_loader)\n",
    "image_count = 0\n",
    "widths = []\n",
    "heights = []\n",
    "for i in range(len(train_test_loader)):\n",
    "    data = trainer.next()\n",
    "    i += 1\n",
    "    cpu_images, cpu_texts = data\n",
    "    batch_size = cpu_images.size(0)\n",
    "    image_count = image_count + batch_size\n",
    "    _, h, w = cpu_images\n",
    "    widths.append(w)\n",
    "    heights.append(h)\n",
    "    \n",
    "    #if self.keep_ratio:\n",
    "     #       ratios = []\n",
    "    # ##       for image in images:\n",
    "    #            w, h = image.size\n",
    "    #            ratios.append(w / float(h))\n",
    "    #        ratios.sort()\n",
    "    #        max_ratio = ratios[-1]\n",
    "    #        imgW = int(np.floor(max_ratio * imgH))\n",
    "            \n",
    "            #RA: I don't understand the purpose of this line, and for handwriting recognition imgW >= imgH\n",
    "            #imgW = max(imgH * self.min_ratio, imgW)  # assure imgH >= imgW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the two alphabets\n",
    "alphabet_russell = ''\n",
    "alphabet_dylan = ''\n",
    "\n",
    "with open(alph_file_russell, 'r') as myfile:\n",
    "    alphabet_russell = myfile.read()\n",
    "with open(alph_file_dylan, 'r') as myfile:\n",
    "    alphabet_dylan = myfile.read()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test the dylan ALphabet and model first\n",
    "alphabet = alphabet_dylan\n",
    "\n",
    "nclass = len(alphabet) + 1\n",
    "nc = 1\n",
    "\n",
    "converter = utils.strLabelConverter(alphabet)\n",
    "criterion = CTCLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on crnn\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crnn = crnn.CRNN(imgH, nc, nclass, nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crnn.apply(weights_init)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on the above unexpected key error, I will assume that when I try to run the original code with a validation epoch number, I will get the same error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = torch.FloatTensor(batchSize, 3, imgH, imgH)\n",
    "text = torch.IntTensor(batchSize * 5)          # RA: I don't understand why the text has this size\n",
    "length = torch.IntTensor(batchSize)\n",
    "\n",
    "if cuda:\n",
    "    crnn.cuda()\n",
    "    crnn = torch.nn.DataParallel(crnn, device_ids=range(ngpu))\n",
    "    image = image.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Dylan's pretrained model first\n",
    "trained_crnn = trained_crnn_dylan\n",
    "if trained_crnn != '':\n",
    "    print('loading pretrained model from %s' % trained_crnn)\n",
    "    crnn.load_state_dict(torch.load(trained_crnn))\n",
    "print(crnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = Variable(image)\n",
    "text = Variable(text)\n",
    "length = Variable(length)\n",
    "\n",
    "# loss averager\n",
    "loss_avg = utils.averager()\n",
    "\n",
    "# setup optimizer\n",
    "if adam:\n",
    "    optimizer = optim.Adam(crnn.parameters(), lr=lr,\n",
    "                           betas=(beta1, 0.999))\n",
    "elif adadelta:\n",
    "    optimizer = optim.Adadelta(crnn.parameters(), lr=lr)\n",
    "else:\n",
    "    optimizer = optim.RMSprop(crnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is where I will test out the code.\n",
    "\n",
    "### First order of business is to see what val outputs currently on these pretrained models using the test set.\n",
    "### Then add word and character error rate and a way to calculate mean and standard deviation of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val(net, dataset, criterion, max_iter=100):\n",
    "    print('Start val')\n",
    "\n",
    "    for p in crnn.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    net.eval()\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, shuffle=True, batch_size=batchSize, num_workers=int(workers))\n",
    "    val_iter = iter(data_loader)\n",
    "\n",
    "    i = 0\n",
    "    n_correct = 0\n",
    "    loss_avg = utils.averager()\n",
    "    \n",
    "    image_count = 0\n",
    "    \n",
    "    # Character and word error rate lists\n",
    "    char_error = []\n",
    "    w_error = []\n",
    "\n",
    "    max_iter = min(max_iter, len(data_loader))\n",
    "    #max_iter = len(data_loader)\n",
    "    for i in range(max_iter):\n",
    "        data = val_iter.next()\n",
    "        i += 1\n",
    "        cpu_images, cpu_texts = data\n",
    "        batch_size = cpu_images.size(0)\n",
    "        image_count = image_count + batch_size\n",
    "        utils.loadData(image, cpu_images)\n",
    "        t, l = converter.encode(cpu_texts)\n",
    "        utils.loadData(text, t)\n",
    "        utils.loadData(length, l)\n",
    "\n",
    "        preds = crnn(image)\n",
    "        preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
    "        cost = criterion(preds, text, preds_size, length) / batch_size\n",
    "        loss_avg.add(cost)\n",
    "        \n",
    "        \n",
    "        # RA: While I am not sure yet, it looks like a greedy decoder and not beam search is being used here\n",
    "        # Also, a simple character by character accuracy is being used, not an edit distance.\n",
    "        # Case is ignored in the accuracy, which is not ideal for an actual working system\n",
    "        \n",
    "        _, preds = preds.max(2)\n",
    "        preds = preds.squeeze(2)\n",
    "        preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "        sim_preds = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "        for pred, target in zip(sim_preds, cpu_texts):\n",
    "            if pred == target.lower():\n",
    "                n_correct += 1\n",
    "            #print(pred)\n",
    "            #print(\"Pred: %s; target: %s\" % (pred, target))\n",
    "            char_error.append(cer(pred, target.lower()))\n",
    "            w_error.append(wer(pred, target.lower()))\n",
    "\n",
    "    raw_preds = converter.decode(preds.data, preds_size.data, raw=True)[:n_test_disp]\n",
    "    for raw_pred, pred, gt in zip(raw_preds, sim_preds, cpu_texts):\n",
    "        print('%-20s => %-20s, gt: %-20s' % (raw_pred, pred, gt))\n",
    "\n",
    "    accuracy = n_correct / float(max_iter * batchSize)\n",
    "    print('Test loss: %f, accuracy: %f' % (loss_avg.val(), accuracy))\n",
    "    \n",
    "    char_arr =np.array(char_error)\n",
    "    w_arr = np.array(w_error)\n",
    "    #numpy.std(arr, ddof=1)\n",
    "    #numpy.mean(arr, axis=0)\n",
    "    #print(\"All character error rates:\")\n",
    "    #print(char_error)\n",
    "    #print(\"All word error rates\")\n",
    "    #print(w_error)\n",
    "    print(\"Character error rate mean: %4.4f; Character error rate sd: %4.4f\" % (np.mean(char_arr), np.std(char_arr, ddof=1)))\n",
    "    print(\"Word error rate mean: %4.4f; Word error rate sd: %4.4f\" % (np.mean(w_arr), np.std(w_arr, ddof=1)))\n",
    "    print(\"Total number of images in validation set: %8d\" % image_count)\n",
    "    return (char_error, w_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainBatch(net, criterion, optimizer):\n",
    "    data = train_iter.next()\n",
    "    cpu_images, cpu_texts = data\n",
    "    batch_size = cpu_images.size(0)\n",
    "    utils.loadData(image, cpu_images)\n",
    "    t, l = converter.encode(cpu_texts)\n",
    "    utils.loadData(text, t)\n",
    "    utils.loadData(length, l)\n",
    "\n",
    "    preds = crnn(image)\n",
    "    preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
    "    cost = criterion(preds, text, preds_size, length) / batch_size\n",
    "    crnn.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now see how the pre-trained model works on the validation set\n",
    "oops, I have to figure out how to change the kernal of this python notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val(crnn, test_dataset, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val(crnn_dylan_trained, test_dataset, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now with the character and word error rates\n",
    "char_e, w_e = val(crnn, test_dataset, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crnn.load_state_dict(torch.load(lesstrained_crnn_dylan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_e, w_e = val(crnn, test_dataset, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next things to do:\n",
    "1) Make the word error and character error code robust to empty sets (\"such as give a dummy variable if length < 1\")\n",
    "2) Incorporate character and word error rates into the training set too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained_crnn = trained_crnn_dylan\n",
    "if trained_crnn != '':\n",
    "    print('loading pretrained model from %s' % trained_crnn)\n",
    "    crnn.load_state_dict(torch.load(trained_crnn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_e, w_e = val(crnn, test_dataset, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_e\n",
    "char_a = np.array(char_e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(char_a)\n",
    "print(\"%4.3f\" % np.mean(char_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#crnn_dylan_trained = crnn\n",
    "crnn_dylan_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As of 17 February 2018, the machine is learning to read. It is rough, but it is learning. This is exciting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(niter):\n",
    "    train_iter = iter(train_loader)\n",
    "    i = 0\n",
    "    while i < len(train_loader):\n",
    "        for p in crnn.parameters():\n",
    "            p.requires_grad = True\n",
    "        crnn.train()\n",
    "\n",
    "        cost = trainBatch(crnn, criterion, optimizer)\n",
    "        loss_avg.add(cost)\n",
    "        i += 1\n",
    "\n",
    "        if i % displayInterval == 0:\n",
    "            print('[%d/%d][%d/%d] Loss: %f' %\n",
    "                  (epoch, niter, i, len(train_loader), loss_avg.val()))\n",
    "            loss_avg.reset()\n",
    "\n",
    "        if i % valInterval == 0:\n",
    "            val(crnn, test_dataset, criterion)\n",
    "\n",
    "        # do checkpointing\n",
    "        if i % saveInterval == 0:\n",
    "            torch.save(\n",
    "                crnn.state_dict(), '{0}/netCRNN_{1}_{2}.pth'.format(experiment, epoch, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Goal: Loop over all trained dylan models and see word error rate and character error rate on training and test data\n",
    "### I will have a dictionary for training and a dictionary for test results, each of which will have a dictionary for character error mean and SD and word error mean and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! ls expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "#glob.glob('expr/*')\n",
    "\n",
    "# We are focusing on dylan's models here\n",
    "model_path = '/home/ubuntu/dylan/nephi/expr/'\n",
    "train_results = {}\n",
    "test_results = {}\n",
    "for model in glob.glob(model_path + '*'):\n",
    "    # Load the weights of the model\n",
    "    print('loading pretrained model from %s' % (model_path + model))\n",
    "    crnn.load_state_dict(torch.load(model))     # In my first run through of this code, this was incorrectly trained_crnn. Now it is correct.\n",
    "    \n",
    "    char_error, w_error = val(crnn, test_dataset, criterion)\n",
    "    test_results[model] = {\"char\" : (np.mean(char_error), np.std(char_error, ddof=1)),\n",
    "                          \"word\": (np.mean(w_error), np.std(w_error, ddof=1))}\n",
    "    char_error, w_error = val(crnn, training_eval_set, criterion)\n",
    "    train_results[model] = {\"char\" : (np.mean(char_error), np.std(char_error, ddof=1)),\n",
    "                          \"word\": (np.mean(w_error), np.std(w_error, ddof=1))}\n",
    "    print(\"Finished model: %s\" % model)\n",
    "    \n",
    "# Now let's write the output to a csv file\n",
    "with open ('dylan_results.csv', 'w') as f:\n",
    "    f.write('Model, Dataset, Character Error (mean), Character Error (sd), Word Error (mean), Word Error (sd)\\n')\n",
    "    for key, value in test_results.items():\n",
    "        f.write(\"%s, %s, %4.4f, %4.4f, %4.4f, %4.4f\\n\" % (key, 'validation', value['char'][0], value['char'][1], value['word'][0], value['word'][1]))\n",
    "        \n",
    "    for key, value in train_results.items():\n",
    "        f.write(\"%s, %s, %4.4f, %4.4f, %4.4f, %4.4f\\n\" % (key, 'training', value['char'][0], value['char'][1], value['word'][0], value['word'][1]))\n",
    "\n",
    "# I think putting all this in a panda spreadsheet would probably be best. I'll do this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nums = (1.4, 2.5, 3.5)\n",
    "\n",
    "print(\"%f, %f, %f, %f\" % (1.3, nums[1], nums[2], nums[0] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The Current Goal for 20 Feb 2018 is to be able to test a model on all images and sort images by character and/or word error rates, displaying images, predictions, ground truth and character and word error rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I am going to try to reverse engineer the validation function to get at the images at this point. I think this is the fastest way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = crnn\n",
    "dataset = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Start val')\n",
    "\n",
    "for p in crnn.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "net.eval()\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, shuffle=True, batch_size=batchSize, num_workers=int(workers))\n",
    "val_iter = iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "n_correct = 0\n",
    "loss_avg = utils.averager()\n",
    "\n",
    "image_count = 0\n",
    "\n",
    "# Character and word error rate lists\n",
    "char_error = []\n",
    "w_error = []\n",
    "max_iter = 100\n",
    "max_iter = min(max_iter, len(data_loader))\n",
    "#max_iter = len(data_loader)\n",
    "#for i in range(max_iter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = val_iter.next()\n",
    "i += 1\n",
    "cpu_images, cpu_texts = data\n",
    "batch_size = cpu_images.size(0)\n",
    "image_count = image_count + batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(image)\n",
    "print(cpu_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I am following the instructions at these websites to display a pytorch tensor as an image\n",
    "https://discuss.pytorch.org/t/how-to-visualize-display-a-data-image-in-torch-floattensor-type/7770\n",
    "\n",
    "https://matplotlib.org/users/image_tutorial.html#plotting-numpy-arrays-as-images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_np = cpu_images.numpy()\n",
    "\n",
    "image_1 = images_np[0, :, :, :]\n",
    "print(image_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_reshape = np.swapaxes(image_1, 0, 2)\n",
    "image_reshape = np.swapaxes(image_reshape, 0, 1)\n",
    "print(image_reshape.shape)\n",
    "image_reshape = np.squeeze(image_reshape)\n",
    "print(image_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.color import gray2rgb, rgb2gray\n",
    "#print(gray2rgb(image_reshape).shape)\n",
    "#imgplot = plt.imshow(image_reshape)\n",
    "plt.imshow(image_reshape, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skimage.color.gray2rgb(image, alpha=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### So, I can print a grey-scale image of any tensor in this project. So I will load all images in a validation run in a list, together with predictions and ground truth as well as word and error rates. Then I can find word and character rates that I want to display, and i can graph accordingly.\n",
    "\n",
    "The following files at fastai can help me with graphing things how I want to:\n",
    "\n",
    "https://github.com/fastai/courses/blob/master/deeplearning1/nbs/utils.py\n",
    "\n",
    "https://github.com/fastai/courses/blob/master/deeplearning2/utils2.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_grayscale(img):\n",
    "    image_reshape = np.swapaxes(img, 0, 2)\n",
    "    image_reshape = np.swapaxes(image_reshape, 0, 1)\n",
    "    image_reshape = np.squeeze(image_reshape)\n",
    "    return(image_reshape)\n",
    "\n",
    "def val(net, dataset, criterion, max_iter=100):\n",
    "    print('Start val')\n",
    "\n",
    "    for p in crnn.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    net.eval()\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, shuffle=True, batch_size=batchSize, num_workers=int(workers))\n",
    "    val_iter = iter(data_loader)\n",
    "\n",
    "    i = 0\n",
    "    n_correct = 0\n",
    "    loss_avg = utils.averager()\n",
    "    \n",
    "    image_count = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Character and word error rate lists\n",
    "    char_error = []\n",
    "    w_error = []\n",
    "    \n",
    "    # Lists of images, predictions and ground truth to correlate with character and word error rates\n",
    "    image_list = []\n",
    "    pred_list = []\n",
    "    gt_list = []\n",
    "    \n",
    "    \n",
    "\n",
    "    max_iter = min(max_iter, len(data_loader))\n",
    "    #max_iter = len(data_loader)\n",
    "    for i in range(max_iter):\n",
    "        data = val_iter.next()\n",
    "        i += 1\n",
    "        cpu_images, cpu_texts = data\n",
    "        batch_size = cpu_images.size(0)\n",
    "        image_count = image_count + batch_size\n",
    "        utils.loadData(image, cpu_images)\n",
    "        t, l = converter.encode(cpu_texts)\n",
    "        utils.loadData(text, t)\n",
    "        utils.loadData(length, l)\n",
    "\n",
    "        preds = crnn(image)\n",
    "        preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
    "        cost = criterion(preds, text, preds_size, length) / batch_size\n",
    "        loss_avg.add(cost)\n",
    "        \n",
    "        \n",
    "        # RA: While I am not sure yet, it looks like a greedy decoder and not beam search is being used here\n",
    "        # Also, a simple character by character accuracy is being used, not an edit distance.\n",
    "        # Case is ignored in the accuracy, which is not ideal for an actual working system\n",
    "        \n",
    "        _, preds = preds.max(2)\n",
    "        preds = preds.squeeze(2)\n",
    "        preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "        sim_preds = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "        for pred, target, img in zip(sim_preds, cpu_texts, cpu_images.numpy()):\n",
    "            if pred == target.lower():\n",
    "                n_correct += 1\n",
    "            #print(pred)\n",
    "            #print(\"Pred: %s; target: %s\" % (pred, target))\n",
    "            char_error.append(cer(pred, target.lower()))\n",
    "            w_error.append(wer(pred, target.lower()))\n",
    "            image_list.append(to_grayscale(img))\n",
    "            pred_list.append(pred)\n",
    "            gt_list.append(target)\n",
    "\n",
    "    raw_preds = converter.decode(preds.data, preds_size.data, raw=True)[:n_test_disp]\n",
    "    for raw_pred, pred, gt in zip(raw_preds, sim_preds, cpu_texts):\n",
    "        print('%-20s => %-20s, gt: %-20s' % (raw_pred, pred, gt))\n",
    "\n",
    "    accuracy = n_correct / float(max_iter * batchSize)\n",
    "    print('Test loss: %f, accuracy: %f' % (loss_avg.val(), accuracy))\n",
    "    \n",
    "    char_arr =np.array(char_error)\n",
    "    w_arr = np.array(w_error)\n",
    "    #numpy.std(arr, ddof=1)\n",
    "    #numpy.mean(arr, axis=0)\n",
    "    #print(\"All character error rates:\")\n",
    "    #print(char_error)\n",
    "    #print(\"All word error rates\")\n",
    "    #print(w_error)\n",
    "    print(\"Character error rate mean: %4.4f; Character error rate sd: %4.4f\" % (np.mean(char_arr), np.std(char_arr, ddof=1)))\n",
    "    print(\"Word error rate mean: %4.4f; Word error rate sd: %4.4f\" % (np.mean(w_arr), np.std(w_arr, ddof=1)))\n",
    "    print(\"Total number of images in validation set: %8d\" % image_count)\n",
    "    return (char_error, w_error, image_list, pred_list, gt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-2202e384c2d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchar_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_gts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_eval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'crnn' is not defined"
     ]
    }
   ],
   "source": [
    "char_error, w_error, all_images, all_preds, all_gts = val(crnn, training_eval_set, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://gist.github.com/soply/f3eec2e79c165e39c9d540e916142ae1\n",
    "def show_images(images, cols = 1, titles = None):\n",
    "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    images: List of np.arrays compatible with plt.imshow.\n",
    "    \n",
    "    cols (Default = 1): Number of columns in figure (number of rows is \n",
    "                        set to np.ceil(n_images/float(cols))).\n",
    "    \n",
    "    titles: List of titles corresponding to each image. Must have\n",
    "            the same length as titles.\n",
    "    \"\"\"\n",
    "    assert((titles is None)or (len(images) == len(titles)))\n",
    "    n_images = len(images)\n",
    "    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n",
    "    fig = plt.figure()\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1023/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plots_extreme(char_err, w_err, images, preds, gts, n=5, err=\"char\", best=True, median=False):\n",
    "    # Fixing random state for reproducibility\n",
    "    np.random.seed(19680801)\n",
    "\n",
    "    # Ascending sort\n",
    "    to_sort = None\n",
    "    if err==\"char\":\n",
    "        to_sort = char_err\n",
    "    elif err == \"word\":\n",
    "        to_sort = w_err\n",
    "    elif err == \"both\":\n",
    "        to_sort = [j/2 for j in (char_err + w_err)]\n",
    "    s_idxs = [i[0] for i in sorted(enumerate(to_sort), key=lambda x:x[1], reverse = False if best else True)]\n",
    "    s_char_err = [char_err[i] for i in s_idxs]\n",
    "    s_w_err = [w_err[i] for i in s_idxs]\n",
    "    s_images = [images[i] for i in s_idxs]\n",
    "    s_preds = [preds[i] for i in s_idxs]\n",
    "    s_gts = [gts[i] for i in s_idxs]\n",
    "    \n",
    "    titles = [\"Prediction: %-20s\\nGround Truth: %-20s\" % (pred, gt) for pred, gt in zip(s_preds, s_gts)]\n",
    "    #for raw_pred, pred, gt in zip(raw_preds, sim_preds, cpu_texts):\n",
    "        #print('%-20s => %-20s, gt: %-20s' % (raw_pred, pred, gt))\n",
    "\n",
    "    print(\"Got through all the sorting in plots_best\")\n",
    "    if median:\n",
    "        show_images(s_images[len(s_images)/2:len(s_images)/2+n], cols=5, titles=titles[len(s_images)/2:len(s_images)/2+n])\n",
    "    else:\n",
    "        show_images(s_images[0:n], cols=5, titles=titles[0:n])   \n",
    "    return(1)\n",
    "    \n",
    "    \n",
    "    # Need to give show images all correct order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorts = np.argsort(char_error)\n",
    "\n",
    "sortes = [i[0] for i in sorted(enumerate(char_error), key=lambda x:x[1], reverse=True)]\n",
    "#for idx in sorts:\n",
    "#    print(char_error[sorts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in sortes:\n",
    "    print(char_error[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[j/2 for j in (w_error + char_error)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(w_error, range=(0, 2), bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_error[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plots_extreme(char_error, w_error, all_images, all_preds, all_gts, n=5, err=\"char\", best=False)  # maybe a both char and word too using a linear combination\n",
    "#plots_average()   # plots around the average I really just need to sort indices\n",
    "#plots_worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_error, w_error, all_images, all_preds, all_gts = val(crnn, test_dataset, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plots_extreme(char_error, w_error, all_images, all_preds, all_gts, n=5, err=\"char\", best=True, median=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.loadData(image, cpu_images)\n",
    "t, l = converter.encode(cpu_texts)\n",
    "utils.loadData(text, t)\n",
    "utils.loadData(length, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = crnn(image)\n",
    "preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
    "cost = criterion(preds, text, preds_size, length) / batch_size\n",
    "loss_avg.add(cost)\n",
    "\n",
    "\n",
    "# RA: While I am not sure yet, it looks like a greedy decoder and not beam search is being used here\n",
    "# Also, a simple character by character accuracy is being used, not an edit distance.\n",
    "# Case is ignored in the accuracy, which is not ideal for an actual working system\n",
    "\n",
    "_, preds = preds.max(2)\n",
    "preds = preds.squeeze(2)\n",
    "preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "sim_preds = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "for pred, target in zip(sim_preds, cpu_texts):\n",
    "    if pred == target.lower():\n",
    "        n_correct += 1\n",
    "    #print(pred)\n",
    "    #print(\"Pred: %s; target: %s\" % (pred, target))\n",
    "    char_error.append(cer(pred, target.lower()))\n",
    "    w_error.append(wer(pred, target.lower()))\n",
    "\n",
    "raw_preds = converter.decode(preds.data, preds_size.data, raw=True)[:n_test_disp]\n",
    "for raw_pred, pred, gt in zip(raw_preds, sim_preds, cpu_texts):\n",
    "print('%-20s => %-20s, gt: %-20s' % (raw_pred, pred, gt))\n",
    "\n",
    "accuracy = n_correct / float(max_iter * batchSize)\n",
    "print('Test loss: %f, accuracy: %f' % (loss_avg.val(), accuracy))\n",
    "\n",
    "char_arr =np.array(char_error)\n",
    "w_arr = np.array(w_error)\n",
    "#numpy.std(arr, ddof=1)\n",
    "#numpy.mean(arr, axis=0)\n",
    "#print(\"All character error rates:\")\n",
    "#print(char_error)\n",
    "#print(\"All word error rates\")\n",
    "#print(w_error)\n",
    "print(\"Character error rate mean: %4.4f; Character error rate sd: %4.4f\" % (np.mean(char_arr), np.std(char_arr, ddof=1)))\n",
    "print(\"Word error rate mean: %4.4f; Word error rate sd: %4.4f\" % (np.mean(w_arr), np.std(w_arr, ddof=1)))\n",
    "print(\"Total number of images in validation set: %8d\" % image_count)\n",
    "return (char_error, w_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Oliver:\n",
    "#### The data and model are loaded. Here's the code to generate all the pictures of the powerpoint. The call to val() will take a minute fore the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training set pictures\n",
    "char_error, w_error, all_images, all_preds, all_gts = val(crnn, training_eval_set, criterion)\n",
    "\n",
    "# Plot 5 of the best pictures by character error rate\n",
    "plots_extreme(char_error, w_error, all_images, all_preds, all_gts, n=5, err=\"char\", best=True, median=False) \n",
    "\n",
    "# Plot 5 of the worst pictures\n",
    "plots_extreme(char_error, w_error, all_images, all_preds, all_gts, n=5, err=\"char\", best=False, median=False)\n",
    "\n",
    "# Plot 5 pictures around the median performance\n",
    "plots_extreme(char_error, w_error, all_images, all_preds, all_gts, n=5, err=\"char\", best=True, median=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Validation set pictures\n",
    "char_error, w_error, all_images, all_preds, all_gts = val(crnn, test_dataset, criterion)\n",
    "\n",
    "# Plot 5 of the best pictures by character error rate\n",
    "plots_extreme(char_error, w_error, all_images, all_preds, all_gts, n=5, err=\"char\", best=True, median=False) \n",
    "\n",
    "# Plot 5 of the worst pictures\n",
    "plots_extreme(char_error, w_error, all_images, all_preds, all_gts, n=5, err=\"char\", best=False, median=False)\n",
    "\n",
    "# Plot 5 pictures around the median performance\n",
    "plots_extreme(char_error, w_error, all_images, all_preds, all_gts, n=5, err=\"char\", best=True, median=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_error[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
