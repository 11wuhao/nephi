{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Russell Ault\n",
    "\n",
    "# This Notebook Contains code for exploring the functionality of the Pytorch Handwriting Recognition Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It is clear to me that I need to write interactive code to load a model that we have trained and test it on a validation set, and have it output accuracy and word error rates. \n",
    "\n",
    "## The present way that the library is written is clearly not easily conducive to this\n",
    "\n",
    "## Here are some comments I have about the code and how to improve it:\n",
    "- In evaluating model accuracy a character by character accuracy is being used, not an edit distance. I need to put character and word error rates into the model. I should include a mean and sd of these parameters.\n",
    "- I think I need to just run the validation code right now to see what it does.\n",
    "- I think that the main python module should be refactored to allow its use in other python modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Main Functionality in Notebook fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from warpctc_pytorch import CTCLoss\n",
    "import os\n",
    "import utils\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import models.crnn as crnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latin-1\n"
     ]
    }
   ],
   "source": [
    "import sys  \n",
    "stdout = sys.stdout\n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('latin-1')\n",
    "from model_error import cer, wer\n",
    "\n",
    "\n",
    "#My workaround was that at the top of the script, I import sys, and store sys.stdout in a separate variable, e.g. stdout.\n",
    "sys.stdout = stdout\n",
    "print(sys.getdefaultencoding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model_error import cer, wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(3+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--trainroot', required=True, help='path to dataset')\n",
    "parser.add_argument('--valroot', required=True, help='path to dataset')\n",
    "parser.add_argument('--workers', type=int, help='number of data loading workers', default=2)\n",
    "parser.add_argument('--batchSize', type=int, default=64, help='input batch size')\n",
    "parser.add_argument('--imgH', type=int, default=32, help='the height of the input image to network')\n",
    "parser.add_argument('--imgW', type=int, default=100, help='the width of the input image to network')\n",
    "parser.add_argument('--nh', type=int, default=256, help='size of the lstm hidden state')\n",
    "parser.add_argument('--niter', type=int, default=25, help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=0.01, help='learning rate for Critic, default=0.00005')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
    "parser.add_argument('--ngpu', type=int, default=1, help='number of GPUs to use')\n",
    "parser.add_argument('--crnn', default='', help=\"path to crnn (to continue training)\")\n",
    "parser.add_argument('--alphabet', type=str, default='0123456789abcdefghijklmnopqrstuvwxyz')\n",
    "parser.add_argument('--experiment', default=None, help='Where to store samples and models')\n",
    "parser.add_argument('--displayInterval', type=int, default=500, help='Interval to be displayed')\n",
    "parser.add_argument('--n_test_disp', type=int, default=10, help='Number of samples to display when test')\n",
    "parser.add_argument('--valInterval', type=int, default=500, help='Interval to be displayed')\n",
    "parser.add_argument('--saveInterval', type=int, default=500, help='Interval to be displayed')\n",
    "parser.add_argument('--adam', action='store_true', help='Whether to use adam (default is rmsprop)')\n",
    "parser.add_argument('--adadelta', action='store_true', help='Whether to use adadelta (default is rmsprop)')\n",
    "parser.add_argument('--keep_ratio', action='store_true', help='whether to keep ratio for image resize')\n",
    "parser.add_argument('--random_sample', action='store_true', help='whether to sample the dataset with random sampler')\n",
    "opt = parser.parse_args()\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if experiment is None:\n",
    "    experiment = 'expr'\n",
    "os.system('mkdir {0}'.format(experiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainroot = \"/home/ubuntu/russell/nephi/data/lmdb/train\"\n",
    "valroot = \"/home/ubuntu/russell/nephi/data/lmdb/val\"\n",
    "batchSize = 64\n",
    "nh = 256                  # size of the LSTM hidden state\n",
    "imgW = 100\n",
    "imgH = 32\n",
    "ngpu = 1\n",
    "beta1 = 0.5\n",
    "lr = 0.0001\n",
    "workers = 10\n",
    "keep_ratio = True\n",
    "adam = True\n",
    "adadelta = False\n",
    "n_test_disp = 100\n",
    "\n",
    "alph_file_dylan = \"/home/ubuntu/dylan/nephi/alphabet.txt\"\n",
    "alph_file_russell = \"/home/ubuntu/russell/nephi/alphabet.txt\"\n",
    "alphabet = '0123456789abcdefghijklmnopqrstuvwxyzB- EÂ¬Ã¼.RSÅ«J/DHA:K¤¿ZLGFNTPCOVWIM<8d>Ä<81><9f>,<93>È³¶'\n",
    "#0123456789abcdefghijklmnopqrstuvwxyzW VCGū¬.HM,ILAZ:BTÿSER<BC>JFāP<9F>NDKOȳ<B6>\n",
    "#<A4><8D>()—̈-<84><93>Q<96>/Y<BE>U<>+  # This is what I got from Dylan's file\n",
    "\n",
    "untrained_crnn_dylan = \"/home/ubuntu/dylan/nephi/expr/netCRNN_1_100.pth\"\n",
    "less trained 29\n",
    "lesstrained_crnn_dylan = \"/home/ubuntu/dylan/nephi/expr/netCRNN_1000_100.pth\"\n",
    "trained_crnn_russell = \"/home/ubuntu/russell/nephi/expr/netCRNN_3870_100.pth\"\n",
    "trained_crnn_dylan = \"/home/ubuntu/dylan/nephi/expr/netCRNN_3210_100.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  6501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa9d0bf2ba0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manualSeed = random.randint(1, 10000)  # fix seed\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "np.random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "cuda = True\n",
    "\n",
    "#if torch.cuda.is_available() and not cuda:\n",
    "#    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "train_dataset = dataset.lmdbDataset(root=trainroot)\n",
    "sampler = dataset.randomSequentialSampler(train_dataset, batchSize)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batchSize, sampler=sampler,\n",
    "    num_workers=int(workers),\n",
    "    collate_fn=dataset.alignCollate(imgH=imgH, imgW=imgW, keep_ratio=keep_ratio))\n",
    "test_dataset = dataset.lmdbDataset(\n",
    "    root=valroot, transform=dataset.resizeNormalize((imgW, imgH)))   # I have changed this line from the original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the two alphabets\n",
    "alphabet_russell = ''\n",
    "alphabet_dylan = ''\n",
    "\n",
    "with open(alph_file_russell, 'r') as myfile:\n",
    "    alphabet_russell = myfile.read()\n",
    "with open(alph_file_dylan, 'r') as myfile:\n",
    "    alphabet_dylan = myfile.read()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test the dylan ALphabet and model first\n",
    "alphabet = alphabet_dylan\n",
    "\n",
    "nclass = len(alphabet) + 1\n",
    "nc = 1\n",
    "\n",
    "converter = utils.strLabelConverter(alphabet)\n",
    "criterion = CTCLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on crnn\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crnn = crnn.CRNN(imgH, nc, nclass, nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN (\n",
       "  (cnn): Sequential (\n",
       "    (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu0): ReLU (inplace)\n",
       "    (pooling0): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu1): ReLU (inplace)\n",
       "    (pooling1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (relu2): ReLU (inplace)\n",
       "    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu3): ReLU (inplace)\n",
       "    (pooling2): MaxPool2d (size=(2, 2), stride=(2, 1), dilation=(1, 1))\n",
       "    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (relu4): ReLU (inplace)\n",
       "    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu5): ReLU (inplace)\n",
       "    (pooling3): MaxPool2d (size=(2, 2), stride=(2, 1), dilation=(1, 1))\n",
       "    (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (relu6): ReLU (inplace)\n",
       "  )\n",
       "  (rnn): Sequential (\n",
       "    (0): BidirectionalLSTM (\n",
       "      (rnn): LSTM(512, 256, bidirectional=True)\n",
       "      (embedding): Linear (512 -> 256)\n",
       "    )\n",
       "    (1): BidirectionalLSTM (\n",
       "      (rnn): LSTM(256, 256, bidirectional=True)\n",
       "      (embedding): Linear (512 -> 97)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crnn.apply(weights_init)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on the above unexpected key error, I will assume that when I try to run the original code with a validation epoch number, I will get the same error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = torch.FloatTensor(batchSize, 3, imgH, imgH)\n",
    "text = torch.IntTensor(batchSize * 5)          # RA: I don't understand why the text has this size\n",
    "length = torch.IntTensor(batchSize)\n",
    "\n",
    "if cuda:\n",
    "    crnn.cuda()\n",
    "    crnn = torch.nn.DataParallel(crnn, device_ids=range(ngpu))\n",
    "    image = image.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained model from /home/ubuntu/dylan/nephi/expr/netCRNN_3210_100.pth\n",
      "DataParallel (\n",
      "  (module): CRNN (\n",
      "    (cnn): Sequential (\n",
      "      (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu0): ReLU (inplace)\n",
      "      (pooling0): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu1): ReLU (inplace)\n",
      "      (pooling1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu2): ReLU (inplace)\n",
      "      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu3): ReLU (inplace)\n",
      "      (pooling2): MaxPool2d (size=(2, 2), stride=(2, 1), dilation=(1, 1))\n",
      "      (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu4): ReLU (inplace)\n",
      "      (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu5): ReLU (inplace)\n",
      "      (pooling3): MaxPool2d (size=(2, 2), stride=(2, 1), dilation=(1, 1))\n",
      "      (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu6): ReLU (inplace)\n",
      "    )\n",
      "    (rnn): Sequential (\n",
      "      (0): BidirectionalLSTM (\n",
      "        (rnn): LSTM(512, 256, bidirectional=True)\n",
      "        (embedding): Linear (512 -> 256)\n",
      "      )\n",
      "      (1): BidirectionalLSTM (\n",
      "        (rnn): LSTM(256, 256, bidirectional=True)\n",
      "        (embedding): Linear (512 -> 97)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load Dylan's pretrained model first\n",
    "trained_crnn = trained_crnn_dylan\n",
    "if trained_crnn != '':\n",
    "    print('loading pretrained model from %s' % trained_crnn)\n",
    "    crnn.load_state_dict(torch.load(trained_crnn))\n",
    "print(crnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = Variable(image)\n",
    "text = Variable(text)\n",
    "length = Variable(length)\n",
    "\n",
    "# loss averager\n",
    "loss_avg = utils.averager()\n",
    "\n",
    "# setup optimizer\n",
    "if adam:\n",
    "    optimizer = optim.Adam(crnn.parameters(), lr=lr,\n",
    "                           betas=(beta1, 0.999))\n",
    "elif adadelta:\n",
    "    optimizer = optim.Adadelta(crnn.parameters(), lr=lr)\n",
    "else:\n",
    "    optimizer = optim.RMSprop(crnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is where I will test out the code.\n",
    "\n",
    "### First order of business is to see what val outputs currently on these pretrained models using the test set.\n",
    "### Then add word and character error rate and a way to calculate mean and standard deviation of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val(net, dataset, criterion, max_iter=100):\n",
    "    print('Start val')\n",
    "\n",
    "    for p in crnn.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    net.eval()\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, shuffle=True, batch_size=batchSize, num_workers=int(workers))\n",
    "    val_iter = iter(data_loader)\n",
    "\n",
    "    i = 0\n",
    "    n_correct = 0\n",
    "    loss_avg = utils.averager()\n",
    "    \n",
    "    image_count = 0\n",
    "    \n",
    "    # Character and word error rate lists\n",
    "    char_error = []\n",
    "    w_error = []\n",
    "\n",
    "    max_iter = min(max_iter, len(data_loader))\n",
    "    #max_iter = len(data_loader)\n",
    "    for i in range(max_iter):\n",
    "        data = val_iter.next()\n",
    "        i += 1\n",
    "        cpu_images, cpu_texts = data\n",
    "        batch_size = cpu_images.size(0)\n",
    "        image_count = image_count + batch_size\n",
    "        utils.loadData(image, cpu_images)\n",
    "        t, l = converter.encode(cpu_texts)\n",
    "        utils.loadData(text, t)\n",
    "        utils.loadData(length, l)\n",
    "\n",
    "        preds = crnn(image)\n",
    "        preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
    "        cost = criterion(preds, text, preds_size, length) / batch_size\n",
    "        loss_avg.add(cost)\n",
    "        \n",
    "        \n",
    "        # RA: While I am not sure yet, it looks like a greedy decoder and not beam search is being used here\n",
    "        # Also, a simple character by character accuracy is being used, not an edit distance.\n",
    "        # Case is ignored in the accuracy, which is not ideal for an actual working system\n",
    "        \n",
    "        _, preds = preds.max(2)\n",
    "        preds = preds.squeeze(2)\n",
    "        preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "        sim_preds = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "        for pred, target in zip(sim_preds, cpu_texts):\n",
    "            if pred == target.lower():\n",
    "                n_correct += 1\n",
    "            #print(pred)\n",
    "            #print(\"Pred: %s; target: %s\" % (pred, target))\n",
    "            char_error.append(cer(pred, target.lower()))\n",
    "            w_error.append(wer(pred, target.lower()))\n",
    "\n",
    "    raw_preds = converter.decode(preds.data, preds_size.data, raw=True)[:n_test_disp]\n",
    "    for raw_pred, pred, gt in zip(raw_preds, sim_preds, cpu_texts):\n",
    "        print('%-20s => %-20s, gt: %-20s' % (raw_pred, pred, gt))\n",
    "\n",
    "    accuracy = n_correct / float(max_iter * batchSize)\n",
    "    print('Test loss: %f, accuray: %f' % (loss_avg.val(), accuracy))\n",
    "    \n",
    "    char_arr =np.array(char_error)\n",
    "    w_arr = np.array(w_error)\n",
    "    #numpy.std(arr, ddof=1)\n",
    "    #numpy.mean(arr, axis=0)\n",
    "    #print(\"All character error rates:\")\n",
    "    #print(char_error)\n",
    "    #print(\"All word error rates\")\n",
    "    #print(w_error)\n",
    "    print(\"Character error rate mean: %4.4f; Character error rate sd: %4.4f\" % (np.mean(char_arr), np.std(char_arr, ddof=1)))\n",
    "    print(\"Word error rate mean: %4.4f; Word error rate sd: %4.4f\" % (np.mean(w_arr), np.std(w_arr, ddof=1)))\n",
    "    print(\"Total number of images in validation set: %8d\" % image_count)\n",
    "    return (char_error, w_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainBatch(net, criterion, optimizer):\n",
    "    data = train_iter.next()\n",
    "    cpu_images, cpu_texts = data\n",
    "    batch_size = cpu_images.size(0)\n",
    "    utils.loadData(image, cpu_images)\n",
    "    t, l = converter.encode(cpu_texts)\n",
    "    utils.loadData(text, t)\n",
    "    utils.loadData(length, l)\n",
    "\n",
    "    preds = crnn(image)\n",
    "    preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
    "    cost = criterion(preds, text, preds_size, length) / batch_size\n",
    "    crnn.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now see how the pre-trained model works on the validation set\n",
    "oops, I have to figure out how to change the kernal of this python notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start val\n",
      "aas dernnaet  ann h- daaa. => as dernaet an h da. , gt: Die Genneral ambts Rait¬\n",
      "llchr t--n dz�-�-n-ewiils. => lchr tn dzÿnewils. , gt: Alhie. sonnder Meniglich\n",
      "aamme-  bllrz--neem-mma-ns => ame blrznemmans     , gt: Ainer Loblichen Regierūng.\n",
      "maa---nin. deoornū�nnssen => manin. deornūnsen  , gt: Locheman. Jeronimūsen\n",
      "wal------n  win---dde----. => waln winde.         , gt: Melchior Wūrmbrandt.\n",
      "air-ranster  aibe -geegmn. => airranster aibe gegmn., gt: aūf negsten Ratstag wid¬\n",
      "aeeaan d2  lea---w- olsien => aean d2 leaw olsien , gt: Aber Ain CoPȳ an Ir G:\n",
      "aab  mal  aenn iimee  d��. => ab mal aen ime d��. , gt: Als well man seiner aūf\n",
      "haarautr  dewezzi wed ww-n => harautr dewezi wed wn, gt: Mandaten. dergleichen Wöhrn\n",
      "vme saūrwednt a�h bem-mon => vme saūrwednt a�h bemmon, gt: von Rovereid, aūf Laȳen\n",
      "zei-----merw---ppaa-n---n. => zeimerwpann.        , gt: Reinhardt von Pūechhaim.\n",
      "vnn---dd-ll-tt hze---t---. => vndlt hzet.         , gt: Landts bet:         \n",
      "ma�-�rr  ha--reirgge-nden  => maūr hareirgenden  , gt: Geōrg Schaler liegenden\n",
      "aaa-�mer dvvnd hūn--nnenn => a�mer dvnd hūnnen  , gt: Haimen. vnd Hannsen \n",
      "vnnddziligeisjen lichnfn¬ => vndziligeisjen lichnfn¬, gt: Wilhalmen von KiePach.\n",
      "v--cchhūgnnnn hh�be mmar. => vchūgn h�be mar.   , gt: Wilhalm von Hofkhirchen\n",
      "toa----�ū�--�zzz--laa---h => toaū�zlah          , gt: wonūng. Tax        \n",
      "megg-n�ū  degenden slais. => megnū degenden slais., gt: mag. Zū dienern hat.\n",
      "a�bbl-it  o-  wnwiillaū�t => a�blit o wnwilaūt  , gt: mall. 6 fl gewilligt. \n",
      "Test loss: 134.090870, accuray: 0.000919\n"
     ]
    }
   ],
   "source": [
    "val(crnn, test_dataset, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start val\n",
      "imns sggtel�in  wer�n��ntt => imns sgtel�in wer�n�nt, gt: dise Motiūen, worūmb\n",
      "herrren lann-nddshh�ūbba� => heren lanndshūba�  , gt: herrn Lanndthaūbt¬\n",
      "im  rr-s---r  anzzail zint => im rsr anzail zint  , gt: in grosser Anzal aūf.\n",
      "aiiee, a�s  bacchen olllig => aie, a�s bachen olig, gt: Ainer aūf Laÿen etlich \n",
      "die  herr--megehenns. vvnd => die hermegehens. vnd, gt: die Thor angehengt: vnd\n",
      "------------1-----------35 => 135                 , gt: 203                 \n",
      "man--en,, aaddlli- vnnddet => manen, adli vndet   , gt: gannzer Adelich. vnd Er¬\n",
      "vnd ma�-s ee dammedthherr. => vnd ma�s e damedther., gt: vnd Aūsser Lanndtsūer¬\n",
      "vmdd aamz-eiengg-n-e malll => vmd amzeiengne mal  , gt: vnd Aūsgeben Zūūerhalt\n",
      "herrr-n an-nnd h�ūlbta-nn => hern annd hūlbtan  , gt: herrn Lanndthaūbtman\n",
      "zūeggihibenn werdden  iin => zūegihiben werden in, gt: Zūegschriben werden. ain\n",
      "lem--ngaarr  an--ee. bea¬ => lemngar ane. bea¬  , gt: Pennzinger. hannsen Loche¬\n",
      "būeehen  aūnnddn  wofffr => būehen aūndn wofr , gt: būecher, Daūiden Waff¬\n",
      "zam-x.  ddb  raafhhee  tis => zamx. db rafhe tis  , gt: Schmalz. das Roch P: 12 k. 1 f.\n",
      "za----------hh----------�  => zah�                , gt: Caspar              \n",
      "ferrssen-nn vnn parbrmaej. => fersenn vn parbrmaej., gt: Personen one Patenten\n",
      "vdd beeghhe-sen billhsionn => vd beghesen bilhsion, gt: vnd Mathiasen Feichtner\n",
      "pan-- der  a�--ntewwendatt => pan der a�ntewendat , gt: Wann der Grūsstner vmb\n",
      "vo----ns ch------stteeeer. => vons chster.        , gt: Otto Fridrich Geȳer.\n",
      "Test loss: 149.597148, accuray: 0.000919\n"
     ]
    }
   ],
   "source": [
    "val(crnn_dylan_trained, test_dataset, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start val\n",
      "-------11---------------66 => 16                  , gt: 193                 \n",
      "gns pūrrrennninssee-  nnd => gns pūreninse nd   , gt: N. Būrgermaisster: vnd\n",
      "haūnddroeeen  srrffffer�. => haūndroen srfer�.  , gt: Anndreen Rotten¬   \n",
      "hannnnnn aūgeen senndeer. => han aūgen sender.  , gt: khomen migen. sonnder\n",
      "m-ttrt hū� hehers tr bi¬ => mtrt hū hehers tr bi¬, gt: Matheūs Hofsteter  \n",
      "airttei wlls s-felwmmmee-s => airtei wls sfelwmes , gt: Aūfkhaūfft. Als soll deßweg\n",
      "pen ssgeegch aa-sccileienn => pen sgegch ascileien, gt: Passbrief Angehalten.\n",
      "fen-ns nnnden ii tetrge--. => fenns nden i tetrge., gt: Personen An Jezt verseh.\n",
      "wee-nn-ntenn vnnndderrlcch => wennten vnderlch    , gt: darūnter sonnderlich\n",
      "han�stt vdd i  grbgggzai¬ => han�st vd i grbgzai¬, gt: haūß. vnd Zū Rūgg Zieh.\n",
      "vn--n-tttgeern----snmfffff => vnntgernsnmf        , gt: vnd versich¬       \n",
      "lileerpos gefeoo wa--f-nr� => lilerpos gefeo wafnr�, gt: es bei der getanen Abschaff¬\n",
      "tatterannichee. gen-ndict  => tateraniche. genndict , gt: Schrannckhen gemacht¬\n",
      "ger-nnweeen ii ten garab-. => gernwen i ten garab., gt: Derowegen sei Ir Gnaden\n",
      "mensst powweee sesss i-e-. => menst powe ses ie.  , gt: wolt das L. P .15 k geb.\n",
      "-------11---------------66 => 16                  , gt: 193                 \n",
      "aan-ger enbeebeen zerroon. => anger enbeben zeron., gt: Inntercediern herrn \n",
      "senn airrrnnnn brmsl ggi�. => sen airn brmsl gi�. , gt: Vom Ingram daselbst \n",
      "aa--spūs  asscz�sbmaaese. => aspūs ascz�sbmaese., gt: gwalts mit haūs wesen\n",
      "Test loss: 139.930357, accuray: 0.000919\n",
      "Character error rate mean: 0.8858; Character error rate sd: 0.4875\n",
      "Word error rate mean: 1.3256; Word error rate sd: 0.6271\n",
      "Total number of images in validation set:     1043\n"
     ]
    }
   ],
   "source": [
    "# Now with the character and word error rates\n",
    "char_e, w_e = val(crnn, test_dataset, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crnn.load_state_dict(torch.load(lesstrained_crnn_dylan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start val\n",
      "ha-  der herrrrūen-nnicht => ha der herūennicht , gt: hat der herr Būrgermaist\n",
      "an� gbllss--nneiierd- ciss => an� gblsneierd cis  , gt: Aūsglassen wūrde. sich \n",
      "gennnnddeennn scshgmm-lh-t => genden scshgmlht    , gt: geennden .2. Vieh Märckht\n",
      "o----lllccher go--n-e-err� => olcher goneer�      , gt: Loblichen Cammer    \n",
      "gr----tt-----r  ete-----¬ => grtr ete¬          , gt: Antoni Jacob        \n",
      "pa---fer peerweennses dder => pafer perwenses der , gt: Talfer Prūggen, so der\n",
      "sa-ss-ss  wesssseiigenmen. => sass weseigenmen.   , gt: Straff verboten wirdet,\n",
      "-------------------------. => .                   , gt: bet:                \n",
      "mi---. va�fth za-tmnnrinj. => mi. va�fth zatmnrinj., gt: groß noch khlain vieh\n",
      "wa--rdden  an- sssllbee-nn => warden an slben     , gt: werden. Inen Zollern\n",
      "ge----see--mpe--s-fer-ier. => gesempesferier.     , gt: Caspar Artsteter.   \n",
      "vn---ndd  paa-----n----tr. => vnnd pantr.         , gt: vnd Lanndts¬       \n",
      "v-------iibb----------t--. => vibt.               , gt: willigt.            \n",
      "ma�n jjm ae-nn rdddmbrribt => ma�n jm aen rdmbribt, gt: Das de Deum Laudamūs\n",
      "vo--n-nooo  s111-------..t => vonno s1.t          , gt: Anno: 1620.t        \n",
      "pii�teer gnda�  wnndlldeet => pi�ter gnda� wndldet, gt: Pinter gsöll von Nider¬\n",
      "si--nniisoojoo-fffn-nnibr. => sinisojofnnibr.     , gt: Jonas HillePranndt. \n",
      "wo-lddiinng beggern  aerrn => wolding begern aern , gt: besoldūng begern. Inen\n",
      "-------1-----------------3 => 13                  , gt: 189                 \n",
      "Test loss: 140.739242, accuray: 0.000919\n",
      "Character error rate mean: 0.8858; Character error rate sd: 0.4875\n",
      "Word error rate mean: 1.3256; Word error rate sd: 0.6271\n",
      "Total number of images in validation set:     1043\n"
     ]
    }
   ],
   "source": [
    "char_e, w_e = val(crnn, test_dataset, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next things to do:\n",
    "1) Make the word error and character error code robust to empty sets (\"such as give a dummy variable if length < 1\")\n",
    "2) Incorporate character and word error rates into the training set too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained model from /home/ubuntu/dylan/nephi/expr/netCRNN_3210_100.pth\n"
     ]
    }
   ],
   "source": [
    "trained_crnn = trained_crnn_dylan\n",
    "if trained_crnn != '':\n",
    "    print('loading pretrained model from %s' % trained_crnn)\n",
    "    crnn.load_state_dict(torch.load(trained_crnn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start val\n",
      "daaenn bietter  di wwerrr. => daen bieter di wer. , gt: Dem doctor Carära  \n",
      "ain--nga dde--llhtsssriinn => ainnga delhtsrin    , gt: Ingedenckh sein.    \n",
      "walaai-nn  voobbedd   be�. => walain vobed be�.   , gt: schlagūng verbleibe. Ge¬\n",
      "vin   ū  n-n  ragb-bbeen. => vin ū nn ragbben.  , gt: ūng ain SūPplication \n",
      "daz--tangen. iss pine diit => daztangen. is pine dit, gt: zeschlagen. Ist Ime aūf \n",
      "ma�-�rr  ha--reirgge-nden  => maūr hareirgenden  , gt: Geōrg Schaler liegenden\n",
      "-------n---e-a----------z. => neaz.               , gt: amus                \n",
      "hardblmeee  ū�ebbllinben. => hardblme ūeblinben., gt: hat dabei Zūverbleiben.\n",
      "fiii wmmnn-nn niichhl-mint => fi wmnn nichlmint   , gt: seie mann noch nit  \n",
      "oa�chgolnnnes pelaatttviis => oa�chgolnes pelatvis, gt: Rath habenden Pflicht. nit\n",
      "ma---n ūf�eltenn  aūdass => man ūf�elten aūdas, gt: Wegen Haūbtmann Kōlers\n",
      "anddmat  ae--l se derraenn => andmat ael se deraen, gt: vnd nit Tÿrolische Personen.\n",
      "vdd beeghhe-sen billhsionn => vd beghesen bilhsion, gt: vnd Mathiasen Feichtner\n",
      "derrs sa�mrtt deg wwa-chg� => ders sa�mrt deg wachg�, gt: der wiert verraist. \n",
      "aafstr�mfffli�ngge tiii-nn => afstr�mfli�nge tin  , gt: Abstraffūngen Ainem\n",
      "-------111-------------222 => 12                  , gt:                     \n",
      "a----r-----  bbeer-baaib¬ => ar berbaib¬        , gt: ära bet:           \n",
      "aū-nnnngs ee- hlte  all�. => aūngs e hlte al�.  , gt: Als mags Er Hiler Alhie\n",
      "aab  ziis ebr-lūt  �ieg¬ => ab zis ebrlūt �ieg¬, gt: noch Zūm v̄berflūss firge¬\n",
      "Test loss: 150.395698, accuray: 0.000919\n",
      "Character error rate mean: 0.8619; Character error rate sd: 0.6543\n",
      "Word error rate mean: 1.1630; Word error rate sd: 0.4065\n",
      "Total number of images in validation set:     1043\n"
     ]
    }
   ],
   "source": [
    "char_e, w_e = val(crnn, test_dataset, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_e\n",
    "char_a = np.array(char_e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77777778  0.5         1.04761905 ...,  1.30769231  0.63636364\n",
      "  0.52631579]\n",
      "0.862\n"
     ]
    }
   ],
   "source": [
    "print(char_a)\n",
    "print(\"%4.3f\" % np.mean(char_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crnn_dylan_trained' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d63a2322b89a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#crnn_dylan_trained = crnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcrnn_dylan_trained\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'crnn_dylan_trained' is not defined"
     ]
    }
   ],
   "source": [
    "#crnn_dylan_trained = crnn\n",
    "crnn_dylan_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As of 17 February 2018, the machine is learning to read. It is rough, but it is learning. This is exciting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(niter):\n",
    "    train_iter = iter(train_loader)\n",
    "    i = 0\n",
    "    while i < len(train_loader):\n",
    "        for p in crnn.parameters():\n",
    "            p.requires_grad = True\n",
    "        crnn.train()\n",
    "\n",
    "        cost = trainBatch(crnn, criterion, optimizer)\n",
    "        loss_avg.add(cost)\n",
    "        i += 1\n",
    "\n",
    "        if i % displayInterval == 0:\n",
    "            print('[%d/%d][%d/%d] Loss: %f' %\n",
    "                  (epoch, niter, i, len(train_loader), loss_avg.val()))\n",
    "            loss_avg.reset()\n",
    "\n",
    "        if i % valInterval == 0:\n",
    "            val(crnn, test_dataset, criterion)\n",
    "\n",
    "        # do checkpointing\n",
    "        if i % saveInterval == 0:\n",
    "            torch.save(\n",
    "                crnn.state_dict(), '{0}/netCRNN_{1}_{2}.pth'.format(experiment, epoch, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Goal: Loop over all trained dylan models and see word error rate and character error rate on training and test data\n",
    "### I will have a dictionary for training and a dictionary for test results, each of which will have a dictionary for character error mean and SD and word error mean and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netCRNN_0_100.pth     netCRNN_2500_100.pth  netCRNN_3871_100.pth\r\n",
      "netCRNN_1000_100.pth  netCRNN_250_100.pth   netCRNN_3872_100.pth\r\n",
      "netCRNN_100_100.pth   netCRNN_2510_100.pth  netCRNN_3873_100.pth\r\n",
      "netCRNN_10_100.pth    netCRNN_2520_100.pth  netCRNN_3874_100.pth\r\n",
      "netCRNN_1010_100.pth  netCRNN_2530_100.pth  netCRNN_3875_100.pth\r\n",
      "netCRNN_1020_100.pth  netCRNN_2540_100.pth  netCRNN_3876_100.pth\r\n",
      "netCRNN_1030_100.pth  netCRNN_2550_100.pth  netCRNN_3877_100.pth\r\n",
      "netCRNN_1040_100.pth  netCRNN_2560_100.pth  netCRNN_3878_100.pth\r\n",
      "netCRNN_1050_100.pth  netCRNN_2570_100.pth  netCRNN_3879_100.pth\r\n",
      "netCRNN_1060_100.pth  netCRNN_2580_100.pth  netCRNN_3880_100.pth\r\n",
      "netCRNN_1070_100.pth  netCRNN_2590_100.pth  netCRNN_3881_100.pth\r\n",
      "netCRNN_1080_100.pth  netCRNN_2600_100.pth  netCRNN_3882_100.pth\r\n",
      "netCRNN_1090_100.pth  netCRNN_260_100.pth   netCRNN_3883_100.pth\r\n",
      "netCRNN_1100_100.pth  netCRNN_2610_100.pth  netCRNN_3884_100.pth\r\n",
      "netCRNN_110_100.pth   netCRNN_2620_100.pth  netCRNN_3885_100.pth\r\n",
      "netCRNN_1110_100.pth  netCRNN_2630_100.pth  netCRNN_3886_100.pth\r\n",
      "netCRNN_1120_100.pth  netCRNN_2640_100.pth  netCRNN_3887_100.pth\r\n",
      "netCRNN_1130_100.pth  netCRNN_2650_100.pth  netCRNN_3888_100.pth\r\n",
      "netCRNN_1140_100.pth  netCRNN_2660_100.pth  netCRNN_3889_100.pth\r\n",
      "netCRNN_1150_100.pth  netCRNN_2670_100.pth  netCRNN_3890_100.pth\r\n",
      "netCRNN_1160_100.pth  netCRNN_2680_100.pth  netCRNN_3891_100.pth\r\n",
      "netCRNN_1170_100.pth  netCRNN_2690_100.pth  netCRNN_3892_100.pth\r\n",
      "netCRNN_1180_100.pth  netCRNN_2700_100.pth  netCRNN_3893_100.pth\r\n",
      "netCRNN_1190_100.pth  netCRNN_270_100.pth   netCRNN_3894_100.pth\r\n",
      "netCRNN_1200_100.pth  netCRNN_2710_100.pth  netCRNN_3895_100.pth\r\n",
      "netCRNN_120_100.pth   netCRNN_2720_100.pth  netCRNN_3896_100.pth\r\n",
      "netCRNN_1210_100.pth  netCRNN_2730_100.pth  netCRNN_3897_100.pth\r\n",
      "netCRNN_1220_100.pth  netCRNN_2740_100.pth  netCRNN_3898_100.pth\r\n",
      "netCRNN_1230_100.pth  netCRNN_2750_100.pth  netCRNN_3899_100.pth\r\n",
      "netCRNN_1240_100.pth  netCRNN_2760_100.pth  netCRNN_3900_100.pth\r\n",
      "netCRNN_1250_100.pth  netCRNN_2770_100.pth  netCRNN_390_100.pth\r\n",
      "netCRNN_1260_100.pth  netCRNN_2780_100.pth  netCRNN_3901_100.pth\r\n",
      "netCRNN_1270_100.pth  netCRNN_2790_100.pth  netCRNN_3902_100.pth\r\n",
      "netCRNN_1280_100.pth  netCRNN_2800_100.pth  netCRNN_3903_100.pth\r\n",
      "netCRNN_1290_100.pth  netCRNN_280_100.pth   netCRNN_3904_100.pth\r\n",
      "netCRNN_1300_100.pth  netCRNN_2810_100.pth  netCRNN_3905_100.pth\r\n",
      "netCRNN_130_100.pth   netCRNN_2820_100.pth  netCRNN_3906_100.pth\r\n",
      "netCRNN_1310_100.pth  netCRNN_2830_100.pth  netCRNN_3907_100.pth\r\n",
      "netCRNN_1320_100.pth  netCRNN_2840_100.pth  netCRNN_3908_100.pth\r\n",
      "netCRNN_1330_100.pth  netCRNN_2850_100.pth  netCRNN_3909_100.pth\r\n",
      "netCRNN_1340_100.pth  netCRNN_2860_100.pth  netCRNN_3910_100.pth\r\n",
      "netCRNN_1350_100.pth  netCRNN_2870_100.pth  netCRNN_3911_100.pth\r\n",
      "netCRNN_1360_100.pth  netCRNN_2880_100.pth  netCRNN_3912_100.pth\r\n",
      "netCRNN_1370_100.pth  netCRNN_2890_100.pth  netCRNN_3913_100.pth\r\n",
      "netCRNN_1380_100.pth  netCRNN_2900_100.pth  netCRNN_3914_100.pth\r\n",
      "netCRNN_1390_100.pth  netCRNN_290_100.pth   netCRNN_3915_100.pth\r\n",
      "netCRNN_1400_100.pth  netCRNN_2910_100.pth  netCRNN_3916_100.pth\r\n",
      "netCRNN_140_100.pth   netCRNN_2920_100.pth  netCRNN_3917_100.pth\r\n",
      "netCRNN_1410_100.pth  netCRNN_2930_100.pth  netCRNN_3918_100.pth\r\n",
      "netCRNN_1420_100.pth  netCRNN_2940_100.pth  netCRNN_3919_100.pth\r\n",
      "netCRNN_1430_100.pth  netCRNN_2950_100.pth  netCRNN_3920_100.pth\r\n",
      "netCRNN_1440_100.pth  netCRNN_2960_100.pth  netCRNN_3921_100.pth\r\n",
      "netCRNN_1450_100.pth  netCRNN_2970_100.pth  netCRNN_3922_100.pth\r\n",
      "netCRNN_1460_100.pth  netCRNN_2980_100.pth  netCRNN_3923_100.pth\r\n",
      "netCRNN_1470_100.pth  netCRNN_2990_100.pth  netCRNN_3924_100.pth\r\n",
      "netCRNN_1480_100.pth  netCRNN_3000_100.pth  netCRNN_3925_100.pth\r\n",
      "netCRNN_1490_100.pth  netCRNN_300_100.pth   netCRNN_3926_100.pth\r\n",
      "netCRNN_1500_100.pth  netCRNN_30_100.pth    netCRNN_3927_100.pth\r\n",
      "netCRNN_150_100.pth   netCRNN_3010_100.pth  netCRNN_3928_100.pth\r\n",
      "netCRNN_1510_100.pth  netCRNN_3020_100.pth  netCRNN_3929_100.pth\r\n",
      "netCRNN_1520_100.pth  netCRNN_3030_100.pth  netCRNN_3930_100.pth\r\n",
      "netCRNN_1530_100.pth  netCRNN_3040_100.pth  netCRNN_3931_100.pth\r\n",
      "netCRNN_1540_100.pth  netCRNN_3050_100.pth  netCRNN_3932_100.pth\r\n",
      "netCRNN_1550_100.pth  netCRNN_3060_100.pth  netCRNN_3933_100.pth\r\n",
      "netCRNN_1560_100.pth  netCRNN_3070_100.pth  netCRNN_3934_100.pth\r\n",
      "netCRNN_1570_100.pth  netCRNN_3080_100.pth  netCRNN_3935_100.pth\r\n",
      "netCRNN_1580_100.pth  netCRNN_3090_100.pth  netCRNN_3936_100.pth\r\n",
      "netCRNN_1590_100.pth  netCRNN_3100_100.pth  netCRNN_3937_100.pth\r\n",
      "netCRNN_1600_100.pth  netCRNN_310_100.pth   netCRNN_3938_100.pth\r\n",
      "netCRNN_160_100.pth   netCRNN_3110_100.pth  netCRNN_3939_100.pth\r\n",
      "netCRNN_1610_100.pth  netCRNN_3120_100.pth  netCRNN_3940_100.pth\r\n",
      "netCRNN_1620_100.pth  netCRNN_3130_100.pth  netCRNN_3941_100.pth\r\n",
      "netCRNN_1630_100.pth  netCRNN_3140_100.pth  netCRNN_3942_100.pth\r\n",
      "netCRNN_1640_100.pth  netCRNN_3150_100.pth  netCRNN_3943_100.pth\r\n",
      "netCRNN_1650_100.pth  netCRNN_3160_100.pth  netCRNN_3944_100.pth\r\n",
      "netCRNN_1660_100.pth  netCRNN_3170_100.pth  netCRNN_3945_100.pth\r\n",
      "netCRNN_1670_100.pth  netCRNN_3180_100.pth  netCRNN_3946_100.pth\r\n",
      "netCRNN_1680_100.pth  netCRNN_3190_100.pth  netCRNN_3947_100.pth\r\n",
      "netCRNN_1690_100.pth  netCRNN_3200_100.pth  netCRNN_3948_100.pth\r\n",
      "netCRNN_1700_100.pth  netCRNN_320_100.pth   netCRNN_3949_100.pth\r\n",
      "netCRNN_170_100.pth   netCRNN_3210_100.pth  netCRNN_3950_100.pth\r\n",
      "netCRNN_1710_100.pth  netCRNN_3220_100.pth  netCRNN_3951_100.pth\r\n",
      "netCRNN_1720_100.pth  netCRNN_3230_100.pth  netCRNN_3952_100.pth\r\n",
      "netCRNN_1730_100.pth  netCRNN_3240_100.pth  netCRNN_3953_100.pth\r\n",
      "netCRNN_1740_100.pth  netCRNN_3250_100.pth  netCRNN_3954_100.pth\r\n",
      "netCRNN_1750_100.pth  netCRNN_3260_100.pth  netCRNN_3955_100.pth\r\n",
      "netCRNN_1760_100.pth  netCRNN_3270_100.pth  netCRNN_3956_100.pth\r\n",
      "netCRNN_1770_100.pth  netCRNN_3280_100.pth  netCRNN_3957_100.pth\r\n",
      "netCRNN_1780_100.pth  netCRNN_3290_100.pth  netCRNN_3958_100.pth\r\n",
      "netCRNN_1790_100.pth  netCRNN_3300_100.pth  netCRNN_3959_100.pth\r\n",
      "netCRNN_1800_100.pth  netCRNN_330_100.pth   netCRNN_3960_100.pth\r\n",
      "netCRNN_180_100.pth   netCRNN_3310_100.pth  netCRNN_3961_100.pth\r\n",
      "netCRNN_1810_100.pth  netCRNN_3320_100.pth  netCRNN_3962_100.pth\r\n",
      "netCRNN_1820_100.pth  netCRNN_3330_100.pth  netCRNN_3963_100.pth\r\n",
      "netCRNN_1830_100.pth  netCRNN_3340_100.pth  netCRNN_3964_100.pth\r\n",
      "netCRNN_1840_100.pth  netCRNN_3350_100.pth  netCRNN_3965_100.pth\r\n",
      "netCRNN_1850_100.pth  netCRNN_3360_100.pth  netCRNN_3966_100.pth\r\n",
      "netCRNN_1860_100.pth  netCRNN_3370_100.pth  netCRNN_3967_100.pth\r\n",
      "netCRNN_1870_100.pth  netCRNN_3380_100.pth  netCRNN_3968_100.pth\r\n",
      "netCRNN_1880_100.pth  netCRNN_3390_100.pth  netCRNN_3969_100.pth\r\n",
      "netCRNN_1890_100.pth  netCRNN_3400_100.pth  netCRNN_3970_100.pth\r\n",
      "netCRNN_1900_100.pth  netCRNN_340_100.pth   netCRNN_3971_100.pth\r\n",
      "netCRNN_190_100.pth   netCRNN_3410_100.pth  netCRNN_400_100.pth\r\n",
      "netCRNN_1910_100.pth  netCRNN_3420_100.pth  netCRNN_40_100.pth\r\n",
      "netCRNN_1920_100.pth  netCRNN_3430_100.pth  netCRNN_410_100.pth\r\n",
      "netCRNN_1930_100.pth  netCRNN_3440_100.pth  netCRNN_420_100.pth\r\n",
      "netCRNN_1940_100.pth  netCRNN_3450_100.pth  netCRNN_430_100.pth\r\n",
      "netCRNN_1950_100.pth  netCRNN_3460_100.pth  netCRNN_440_100.pth\r\n",
      "netCRNN_1960_100.pth  netCRNN_3470_100.pth  netCRNN_450_100.pth\r\n",
      "netCRNN_1970_100.pth  netCRNN_3480_100.pth  netCRNN_460_100.pth\r\n",
      "netCRNN_1980_100.pth  netCRNN_3490_100.pth  netCRNN_470_100.pth\r\n",
      "netCRNN_1990_100.pth  netCRNN_3500_100.pth  netCRNN_480_100.pth\r\n",
      "netCRNN_2000_100.pth  netCRNN_350_100.pth   netCRNN_490_100.pth\r\n",
      "netCRNN_200_100.pth   netCRNN_3510_100.pth  netCRNN_500_100.pth\r\n",
      "netCRNN_20_100.pth    netCRNN_3520_100.pth  netCRNN_50_100.pth\r\n",
      "netCRNN_2010_100.pth  netCRNN_3530_100.pth  netCRNN_510_100.pth\r\n",
      "netCRNN_2020_100.pth  netCRNN_3540_100.pth  netCRNN_520_100.pth\r\n",
      "netCRNN_2030_100.pth  netCRNN_3550_100.pth  netCRNN_530_100.pth\r\n",
      "netCRNN_2040_100.pth  netCRNN_3560_100.pth  netCRNN_540_100.pth\r\n",
      "netCRNN_2050_100.pth  netCRNN_3570_100.pth  netCRNN_550_100.pth\r\n",
      "netCRNN_2060_100.pth  netCRNN_3580_100.pth  netCRNN_560_100.pth\r\n",
      "netCRNN_2070_100.pth  netCRNN_3590_100.pth  netCRNN_570_100.pth\r\n",
      "netCRNN_2080_100.pth  netCRNN_3600_100.pth  netCRNN_580_100.pth\r\n",
      "netCRNN_2090_100.pth  netCRNN_360_100.pth   netCRNN_590_100.pth\r\n",
      "netCRNN_2100_100.pth  netCRNN_3610_100.pth  netCRNN_600_100.pth\r\n",
      "netCRNN_210_100.pth   netCRNN_3620_100.pth  netCRNN_60_100.pth\r\n",
      "netCRNN_2110_100.pth  netCRNN_3630_100.pth  netCRNN_610_100.pth\r\n",
      "netCRNN_2120_100.pth  netCRNN_3640_100.pth  netCRNN_620_100.pth\r\n",
      "netCRNN_2130_100.pth  netCRNN_3650_100.pth  netCRNN_630_100.pth\r\n",
      "netCRNN_2140_100.pth  netCRNN_3660_100.pth  netCRNN_640_100.pth\r\n",
      "netCRNN_2150_100.pth  netCRNN_3670_100.pth  netCRNN_650_100.pth\r\n",
      "netCRNN_2160_100.pth  netCRNN_3680_100.pth  netCRNN_660_100.pth\r\n",
      "netCRNN_2170_100.pth  netCRNN_3690_100.pth  netCRNN_670_100.pth\r\n",
      "netCRNN_2180_100.pth  netCRNN_3700_100.pth  netCRNN_680_100.pth\r\n",
      "netCRNN_2190_100.pth  netCRNN_370_100.pth   netCRNN_690_100.pth\r\n",
      "netCRNN_2200_100.pth  netCRNN_3710_100.pth  netCRNN_700_100.pth\r\n",
      "netCRNN_220_100.pth   netCRNN_3720_100.pth  netCRNN_70_100.pth\r\n",
      "netCRNN_2210_100.pth  netCRNN_3730_100.pth  netCRNN_710_100.pth\r\n",
      "netCRNN_2220_100.pth  netCRNN_3740_100.pth  netCRNN_720_100.pth\r\n",
      "netCRNN_2230_100.pth  netCRNN_3750_100.pth  netCRNN_730_100.pth\r\n",
      "netCRNN_2240_100.pth  netCRNN_3760_100.pth  netCRNN_740_100.pth\r\n",
      "netCRNN_2250_100.pth  netCRNN_3770_100.pth  netCRNN_750_100.pth\r\n",
      "netCRNN_2260_100.pth  netCRNN_3780_100.pth  netCRNN_760_100.pth\r\n",
      "netCRNN_2270_100.pth  netCRNN_3790_100.pth  netCRNN_770_100.pth\r\n",
      "netCRNN_2280_100.pth  netCRNN_3800_100.pth  netCRNN_780_100.pth\r\n",
      "netCRNN_2290_100.pth  netCRNN_380_100.pth   netCRNN_790_100.pth\r\n",
      "netCRNN_2300_100.pth  netCRNN_3810_100.pth  netCRNN_800_100.pth\r\n",
      "netCRNN_230_100.pth   netCRNN_3820_100.pth  netCRNN_80_100.pth\r\n",
      "netCRNN_2310_100.pth  netCRNN_3830_100.pth  netCRNN_810_100.pth\r\n",
      "netCRNN_2320_100.pth  netCRNN_3840_100.pth  netCRNN_820_100.pth\r\n",
      "netCRNN_2330_100.pth  netCRNN_3850_100.pth  netCRNN_830_100.pth\r\n",
      "netCRNN_2340_100.pth  netCRNN_3854_100.pth  netCRNN_840_100.pth\r\n",
      "netCRNN_2350_100.pth  netCRNN_3855_100.pth  netCRNN_850_100.pth\r\n",
      "netCRNN_2360_100.pth  netCRNN_3856_100.pth  netCRNN_860_100.pth\r\n",
      "netCRNN_2370_100.pth  netCRNN_3857_100.pth  netCRNN_870_100.pth\r\n",
      "netCRNN_2380_100.pth  netCRNN_3858_100.pth  netCRNN_880_100.pth\r\n",
      "netCRNN_2390_100.pth  netCRNN_3859_100.pth  netCRNN_890_100.pth\r\n",
      "netCRNN_2400_100.pth  netCRNN_3860_100.pth  netCRNN_900_100.pth\r\n",
      "netCRNN_240_100.pth   netCRNN_3861_100.pth  netCRNN_90_100.pth\r\n",
      "netCRNN_2410_100.pth  netCRNN_3862_100.pth  netCRNN_910_100.pth\r\n",
      "netCRNN_2420_100.pth  netCRNN_3863_100.pth  netCRNN_920_100.pth\r\n",
      "netCRNN_2430_100.pth  netCRNN_3864_100.pth  netCRNN_930_100.pth\r\n",
      "netCRNN_2440_100.pth  netCRNN_3865_100.pth  netCRNN_940_100.pth\r\n",
      "netCRNN_2450_100.pth  netCRNN_3866_100.pth  netCRNN_950_100.pth\r\n",
      "netCRNN_2460_100.pth  netCRNN_3867_100.pth  netCRNN_960_100.pth\r\n",
      "netCRNN_2470_100.pth  netCRNN_3868_100.pth  netCRNN_970_100.pth\r\n",
      "netCRNN_2480_100.pth  netCRNN_3869_100.pth  netCRNN_980_100.pth\r\n",
      "netCRNN_2490_100.pth  netCRNN_3870_100.pth  netCRNN_990_100.pth\r\n"
     ]
    }
   ],
   "source": [
    "! ls expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['expr/netCRNN_2300_100.pth',\n",
       " 'expr/netCRNN_3620_100.pth',\n",
       " 'expr/netCRNN_3190_100.pth',\n",
       " 'expr/netCRNN_3730_100.pth',\n",
       " 'expr/netCRNN_3861_100.pth',\n",
       " 'expr/netCRNN_3867_100.pth',\n",
       " 'expr/netCRNN_2500_100.pth',\n",
       " 'expr/netCRNN_3971_100.pth',\n",
       " 'expr/netCRNN_1350_100.pth',\n",
       " 'expr/netCRNN_450_100.pth',\n",
       " 'expr/netCRNN_90_100.pth',\n",
       " 'expr/netCRNN_2680_100.pth',\n",
       " 'expr/netCRNN_1600_100.pth',\n",
       " 'expr/netCRNN_2080_100.pth',\n",
       " 'expr/netCRNN_1290_100.pth',\n",
       " 'expr/netCRNN_3871_100.pth',\n",
       " 'expr/netCRNN_720_100.pth',\n",
       " 'expr/netCRNN_3929_100.pth',\n",
       " 'expr/netCRNN_2060_100.pth',\n",
       " 'expr/netCRNN_3915_100.pth',\n",
       " 'expr/netCRNN_3470_100.pth',\n",
       " 'expr/netCRNN_1120_100.pth',\n",
       " 'expr/netCRNN_2670_100.pth',\n",
       " 'expr/netCRNN_3080_100.pth',\n",
       " 'expr/netCRNN_1870_100.pth',\n",
       " 'expr/netCRNN_1160_100.pth',\n",
       " 'expr/netCRNN_2200_100.pth',\n",
       " 'expr/netCRNN_3580_100.pth',\n",
       " 'expr/netCRNN_2050_100.pth',\n",
       " 'expr/netCRNN_3400_100.pth',\n",
       " 'expr/netCRNN_2390_100.pth',\n",
       " 'expr/netCRNN_3300_100.pth',\n",
       " 'expr/netCRNN_300_100.pth',\n",
       " 'expr/netCRNN_1470_100.pth',\n",
       " 'expr/netCRNN_430_100.pth',\n",
       " 'expr/netCRNN_170_100.pth',\n",
       " 'expr/netCRNN_690_100.pth',\n",
       " 'expr/netCRNN_2650_100.pth',\n",
       " 'expr/netCRNN_3240_100.pth',\n",
       " 'expr/netCRNN_3650_100.pth',\n",
       " 'expr/netCRNN_3280_100.pth',\n",
       " 'expr/netCRNN_2700_100.pth',\n",
       " 'expr/netCRNN_3780_100.pth',\n",
       " 'expr/netCRNN_2940_100.pth',\n",
       " 'expr/netCRNN_0_100.pth',\n",
       " 'expr/netCRNN_1070_100.pth',\n",
       " 'expr/netCRNN_3858_100.pth',\n",
       " 'expr/netCRNN_910_100.pth',\n",
       " 'expr/netCRNN_3350_100.pth',\n",
       " 'expr/netCRNN_2130_100.pth',\n",
       " 'expr/netCRNN_3920_100.pth',\n",
       " 'expr/netCRNN_2290_100.pth',\n",
       " 'expr/netCRNN_3120_100.pth',\n",
       " 'expr/netCRNN_2870_100.pth',\n",
       " 'expr/netCRNN_800_100.pth',\n",
       " 'expr/netCRNN_3750_100.pth',\n",
       " 'expr/netCRNN_380_100.pth',\n",
       " 'expr/netCRNN_960_100.pth',\n",
       " 'expr/netCRNN_2860_100.pth',\n",
       " 'expr/netCRNN_390_100.pth',\n",
       " 'expr/netCRNN_3290_100.pth',\n",
       " 'expr/netCRNN_610_100.pth',\n",
       " 'expr/netCRNN_110_100.pth',\n",
       " 'expr/netCRNN_2460_100.pth',\n",
       " 'expr/netCRNN_2340_100.pth',\n",
       " 'expr/netCRNN_20_100.pth',\n",
       " 'expr/netCRNN_2360_100.pth',\n",
       " 'expr/netCRNN_2260_100.pth',\n",
       " 'expr/netCRNN_2710_100.pth',\n",
       " 'expr/netCRNN_3890_100.pth',\n",
       " 'expr/netCRNN_590_100.pth',\n",
       " 'expr/netCRNN_1250_100.pth',\n",
       " 'expr/netCRNN_3180_100.pth',\n",
       " 'expr/netCRNN_3896_100.pth',\n",
       " 'expr/netCRNN_2220_100.pth',\n",
       " 'expr/netCRNN_2170_100.pth',\n",
       " 'expr/netCRNN_3943_100.pth',\n",
       " 'expr/netCRNN_1000_100.pth',\n",
       " 'expr/netCRNN_1930_100.pth',\n",
       " 'expr/netCRNN_3700_100.pth',\n",
       " 'expr/netCRNN_1660_100.pth',\n",
       " 'expr/netCRNN_2140_100.pth',\n",
       " 'expr/netCRNN_150_100.pth',\n",
       " 'expr/netCRNN_3790_100.pth',\n",
       " 'expr/netCRNN_2900_100.pth',\n",
       " 'expr/netCRNN_3938_100.pth',\n",
       " 'expr/netCRNN_570_100.pth',\n",
       " 'expr/netCRNN_2490_100.pth',\n",
       " 'expr/netCRNN_3905_100.pth',\n",
       " 'expr/netCRNN_1430_100.pth',\n",
       " 'expr/netCRNN_220_100.pth',\n",
       " 'expr/netCRNN_40_100.pth',\n",
       " 'expr/netCRNN_3390_100.pth',\n",
       " 'expr/netCRNN_1590_100.pth',\n",
       " 'expr/netCRNN_3878_100.pth',\n",
       " 'expr/netCRNN_900_100.pth',\n",
       " 'expr/netCRNN_130_100.pth',\n",
       " 'expr/netCRNN_3869_100.pth',\n",
       " 'expr/netCRNN_2720_100.pth',\n",
       " 'expr/netCRNN_1780_100.pth',\n",
       " 'expr/netCRNN_1130_100.pth',\n",
       " 'expr/netCRNN_3958_100.pth',\n",
       " 'expr/netCRNN_2410_100.pth',\n",
       " 'expr/netCRNN_500_100.pth',\n",
       " 'expr/netCRNN_490_100.pth',\n",
       " 'expr/netCRNN_3170_100.pth',\n",
       " 'expr/netCRNN_2620_100.pth',\n",
       " 'expr/netCRNN_3740_100.pth',\n",
       " 'expr/netCRNN_3270_100.pth',\n",
       " 'expr/netCRNN_3923_100.pth',\n",
       " 'expr/netCRNN_1750_100.pth',\n",
       " 'expr/netCRNN_1360_100.pth',\n",
       " 'expr/netCRNN_1770_100.pth',\n",
       " 'expr/netCRNN_3963_100.pth',\n",
       " 'expr/netCRNN_230_100.pth',\n",
       " 'expr/netCRNN_2350_100.pth',\n",
       " 'expr/netCRNN_3560_100.pth',\n",
       " 'expr/netCRNN_340_100.pth',\n",
       " 'expr/netCRNN_350_100.pth',\n",
       " 'expr/netCRNN_1140_100.pth',\n",
       " 'expr/netCRNN_3888_100.pth',\n",
       " 'expr/netCRNN_10_100.pth',\n",
       " 'expr/netCRNN_3590_100.pth',\n",
       " 'expr/netCRNN_3949_100.pth',\n",
       " 'expr/netCRNN_1260_100.pth',\n",
       " 'expr/netCRNN_3420_100.pth',\n",
       " 'expr/netCRNN_1880_100.pth',\n",
       " 'expr/netCRNN_560_100.pth',\n",
       " 'expr/netCRNN_3440_100.pth',\n",
       " 'expr/netCRNN_2820_100.pth',\n",
       " 'expr/netCRNN_3919_100.pth',\n",
       " 'expr/netCRNN_1180_100.pth',\n",
       " 'expr/netCRNN_3894_100.pth',\n",
       " 'expr/netCRNN_3940_100.pth',\n",
       " 'expr/netCRNN_3924_100.pth',\n",
       " 'expr/netCRNN_1200_100.pth',\n",
       " 'expr/netCRNN_1530_100.pth',\n",
       " 'expr/netCRNN_3050_100.pth',\n",
       " 'expr/netCRNN_540_100.pth',\n",
       " 'expr/netCRNN_3810_100.pth',\n",
       " 'expr/netCRNN_3956_100.pth',\n",
       " 'expr/netCRNN_710_100.pth',\n",
       " 'expr/netCRNN_3630_100.pth',\n",
       " 'expr/netCRNN_3917_100.pth',\n",
       " 'expr/netCRNN_1910_100.pth',\n",
       " 'expr/netCRNN_1960_100.pth',\n",
       " 'expr/netCRNN_320_100.pth',\n",
       " 'expr/netCRNN_850_100.pth',\n",
       " 'expr/netCRNN_3210_100.pth',\n",
       " 'expr/netCRNN_780_100.pth',\n",
       " 'expr/netCRNN_3966_100.pth',\n",
       " 'expr/netCRNN_3480_100.pth',\n",
       " 'expr/netCRNN_330_100.pth',\n",
       " 'expr/netCRNN_1840_100.pth',\n",
       " 'expr/netCRNN_3906_100.pth',\n",
       " 'expr/netCRNN_1300_100.pth',\n",
       " 'expr/netCRNN_3863_100.pth',\n",
       " 'expr/netCRNN_1030_100.pth',\n",
       " 'expr/netCRNN_2830_100.pth',\n",
       " 'expr/netCRNN_2800_100.pth',\n",
       " 'expr/netCRNN_3941_100.pth',\n",
       " 'expr/netCRNN_3887_100.pth',\n",
       " 'expr/netCRNN_1690_100.pth',\n",
       " 'expr/netCRNN_1670_100.pth',\n",
       " 'expr/netCRNN_3570_100.pth',\n",
       " 'expr/netCRNN_3953_100.pth',\n",
       " 'expr/netCRNN_3862_100.pth',\n",
       " 'expr/netCRNN_3230_100.pth',\n",
       " 'expr/netCRNN_1540_100.pth',\n",
       " 'expr/netCRNN_520_100.pth',\n",
       " 'expr/netCRNN_2730_100.pth',\n",
       " 'expr/netCRNN_2740_100.pth',\n",
       " 'expr/netCRNN_1810_100.pth',\n",
       " 'expr/netCRNN_2450_100.pth',\n",
       " 'expr/netCRNN_3340_100.pth',\n",
       " 'expr/netCRNN_750_100.pth',\n",
       " 'expr/netCRNN_3530_100.pth',\n",
       " 'expr/netCRNN_3885_100.pth',\n",
       " 'expr/netCRNN_600_100.pth',\n",
       " 'expr/netCRNN_2910_100.pth',\n",
       " 'expr/netCRNN_3520_100.pth',\n",
       " 'expr/netCRNN_1640_100.pth',\n",
       " 'expr/netCRNN_3150_100.pth',\n",
       " 'expr/netCRNN_70_100.pth',\n",
       " 'expr/netCRNN_2000_100.pth',\n",
       " 'expr/netCRNN_2930_100.pth',\n",
       " 'expr/netCRNN_1220_100.pth',\n",
       " 'expr/netCRNN_1280_100.pth',\n",
       " 'expr/netCRNN_1720_100.pth',\n",
       " 'expr/netCRNN_3160_100.pth',\n",
       " 'expr/netCRNN_1740_100.pth',\n",
       " 'expr/netCRNN_3892_100.pth',\n",
       " 'expr/netCRNN_3960_100.pth',\n",
       " 'expr/netCRNN_80_100.pth',\n",
       " 'expr/netCRNN_1710_100.pth',\n",
       " 'expr/netCRNN_3760_100.pth',\n",
       " 'expr/netCRNN_2040_100.pth',\n",
       " 'expr/netCRNN_3872_100.pth',\n",
       " 'expr/netCRNN_3882_100.pth',\n",
       " 'expr/netCRNN_3922_100.pth',\n",
       " 'expr/netCRNN_1790_100.pth',\n",
       " 'expr/netCRNN_3250_100.pth',\n",
       " 'expr/netCRNN_3899_100.pth',\n",
       " 'expr/netCRNN_2030_100.pth',\n",
       " 'expr/netCRNN_510_100.pth',\n",
       " 'expr/netCRNN_2480_100.pth',\n",
       " 'expr/netCRNN_3968_100.pth',\n",
       " 'expr/netCRNN_2400_100.pth',\n",
       " 'expr/netCRNN_2570_100.pth',\n",
       " 'expr/netCRNN_1490_100.pth',\n",
       " 'expr/netCRNN_3450_100.pth',\n",
       " 'expr/netCRNN_160_100.pth',\n",
       " 'expr/netCRNN_3880_100.pth',\n",
       " 'expr/netCRNN_1400_100.pth',\n",
       " 'expr/netCRNN_1820_100.pth',\n",
       " 'expr/netCRNN_730_100.pth',\n",
       " 'expr/netCRNN_1090_100.pth',\n",
       " 'expr/netCRNN_2840_100.pth',\n",
       " 'expr/netCRNN_3967_100.pth',\n",
       " 'expr/netCRNN_2520_100.pth',\n",
       " 'expr/netCRNN_3680_100.pth',\n",
       " 'expr/netCRNN_3640_100.pth',\n",
       " 'expr/netCRNN_290_100.pth',\n",
       " 'expr/netCRNN_3854_100.pth',\n",
       " 'expr/netCRNN_250_100.pth',\n",
       " 'expr/netCRNN_480_100.pth',\n",
       " 'expr/netCRNN_60_100.pth',\n",
       " 'expr/netCRNN_1950_100.pth',\n",
       " 'expr/netCRNN_2750_100.pth',\n",
       " 'expr/netCRNN_3855_100.pth',\n",
       " 'expr/netCRNN_1610_100.pth',\n",
       " 'expr/netCRNN_1800_100.pth',\n",
       " 'expr/netCRNN_3900_100.pth',\n",
       " 'expr/netCRNN_3550_100.pth',\n",
       " 'expr/netCRNN_2020_100.pth',\n",
       " 'expr/netCRNN_2180_100.pth',\n",
       " 'expr/netCRNN_100_100.pth',\n",
       " 'expr/netCRNN_1270_100.pth',\n",
       " 'expr/netCRNN_3944_100.pth',\n",
       " 'expr/netCRNN_3933_100.pth',\n",
       " 'expr/netCRNN_3946_100.pth',\n",
       " 'expr/netCRNN_2330_100.pth',\n",
       " 'expr/netCRNN_3914_100.pth',\n",
       " 'expr/netCRNN_760_100.pth',\n",
       " 'expr/netCRNN_1970_100.pth',\n",
       " 'expr/netCRNN_2580_100.pth',\n",
       " 'expr/netCRNN_3670_100.pth',\n",
       " 'expr/netCRNN_3897_100.pth',\n",
       " 'expr/netCRNN_3770_100.pth',\n",
       " 'expr/netCRNN_2890_100.pth',\n",
       " 'expr/netCRNN_3510_100.pth',\n",
       " 'expr/netCRNN_2510_100.pth',\n",
       " 'expr/netCRNN_3850_100.pth',\n",
       " 'expr/netCRNN_370_100.pth',\n",
       " 'expr/netCRNN_3925_100.pth',\n",
       " 'expr/netCRNN_3660_100.pth',\n",
       " 'expr/netCRNN_2270_100.pth',\n",
       " 'expr/netCRNN_1210_100.pth',\n",
       " 'expr/netCRNN_3916_100.pth',\n",
       " 'expr/netCRNN_3540_100.pth',\n",
       " 'expr/netCRNN_3926_100.pth',\n",
       " 'expr/netCRNN_2980_100.pth',\n",
       " 'expr/netCRNN_2950_100.pth',\n",
       " 'expr/netCRNN_2530_100.pth',\n",
       " 'expr/netCRNN_3330_100.pth',\n",
       " 'expr/netCRNN_3720_100.pth',\n",
       " 'expr/netCRNN_3935_100.pth',\n",
       " 'expr/netCRNN_2430_100.pth',\n",
       " 'expr/netCRNN_3932_100.pth',\n",
       " 'expr/netCRNN_860_100.pth',\n",
       " 'expr/netCRNN_1110_100.pth',\n",
       " 'expr/netCRNN_2660_100.pth',\n",
       " 'expr/netCRNN_870_100.pth',\n",
       " 'expr/netCRNN_3873_100.pth',\n",
       " 'expr/netCRNN_3891_100.pth',\n",
       " 'expr/netCRNN_3931_100.pth',\n",
       " 'expr/netCRNN_2690_100.pth',\n",
       " 'expr/netCRNN_2420_100.pth',\n",
       " 'expr/netCRNN_880_100.pth',\n",
       " 'expr/netCRNN_3060_100.pth',\n",
       " 'expr/netCRNN_890_100.pth',\n",
       " 'expr/netCRNN_3952_100.pth',\n",
       " 'expr/netCRNN_2960_100.pth',\n",
       " 'expr/netCRNN_1650_100.pth',\n",
       " 'expr/netCRNN_630_100.pth',\n",
       " 'expr/netCRNN_580_100.pth',\n",
       " 'expr/netCRNN_3961_100.pth',\n",
       " 'expr/netCRNN_360_100.pth',\n",
       " 'expr/netCRNN_3959_100.pth',\n",
       " 'expr/netCRNN_3927_100.pth',\n",
       " 'expr/netCRNN_930_100.pth',\n",
       " 'expr/netCRNN_3856_100.pth',\n",
       " 'expr/netCRNN_50_100.pth',\n",
       " 'expr/netCRNN_3380_100.pth',\n",
       " 'expr/netCRNN_3907_100.pth',\n",
       " 'expr/netCRNN_1900_100.pth',\n",
       " 'expr/netCRNN_270_100.pth',\n",
       " 'expr/netCRNN_3912_100.pth',\n",
       " 'expr/netCRNN_1630_100.pth',\n",
       " 'expr/netCRNN_1340_100.pth',\n",
       " 'expr/netCRNN_3710_100.pth',\n",
       " 'expr/netCRNN_1010_100.pth',\n",
       " 'expr/netCRNN_740_100.pth',\n",
       " 'expr/netCRNN_3864_100.pth',\n",
       " 'expr/netCRNN_3866_100.pth',\n",
       " 'expr/netCRNN_420_100.pth',\n",
       " 'expr/netCRNN_3310_100.pth',\n",
       " 'expr/netCRNN_3957_100.pth',\n",
       " 'expr/netCRNN_3969_100.pth',\n",
       " 'expr/netCRNN_3260_100.pth',\n",
       " 'expr/netCRNN_2560_100.pth',\n",
       " 'expr/netCRNN_2970_100.pth',\n",
       " 'expr/netCRNN_3898_100.pth',\n",
       " 'expr/netCRNN_1620_100.pth',\n",
       " 'expr/netCRNN_2160_100.pth',\n",
       " 'expr/netCRNN_1420_100.pth',\n",
       " 'expr/netCRNN_1310_100.pth',\n",
       " 'expr/netCRNN_1510_100.pth',\n",
       " 'expr/netCRNN_3921_100.pth',\n",
       " 'expr/netCRNN_790_100.pth',\n",
       " 'expr/netCRNN_2610_100.pth',\n",
       " 'expr/netCRNN_140_100.pth',\n",
       " 'expr/netCRNN_1680_100.pth',\n",
       " 'expr/netCRNN_2190_100.pth',\n",
       " 'expr/netCRNN_3902_100.pth',\n",
       " 'expr/netCRNN_3690_100.pth',\n",
       " 'expr/netCRNN_2760_100.pth',\n",
       " 'expr/netCRNN_1560_100.pth',\n",
       " 'expr/netCRNN_3936_100.pth',\n",
       " 'expr/netCRNN_2210_100.pth',\n",
       " 'expr/netCRNN_1980_100.pth',\n",
       " 'expr/netCRNN_1230_100.pth',\n",
       " 'expr/netCRNN_460_100.pth',\n",
       " 'expr/netCRNN_2880_100.pth',\n",
       " 'expr/netCRNN_990_100.pth',\n",
       " 'expr/netCRNN_820_100.pth',\n",
       " 'expr/netCRNN_1080_100.pth',\n",
       " 'expr/netCRNN_200_100.pth',\n",
       " 'expr/netCRNN_3934_100.pth',\n",
       " 'expr/netCRNN_1370_100.pth',\n",
       " 'expr/netCRNN_2470_100.pth',\n",
       " 'expr/netCRNN_440_100.pth',\n",
       " 'expr/netCRNN_1860_100.pth',\n",
       " 'expr/netCRNN_3903_100.pth',\n",
       " 'expr/netCRNN_2150_100.pth',\n",
       " 'expr/netCRNN_3110_100.pth',\n",
       " 'expr/netCRNN_30_100.pth',\n",
       " 'expr/netCRNN_3490_100.pth',\n",
       " 'expr/netCRNN_3020_100.pth',\n",
       " 'expr/netCRNN_3954_100.pth',\n",
       " 'expr/netCRNN_3874_100.pth',\n",
       " 'expr/netCRNN_980_100.pth',\n",
       " 'expr/netCRNN_2090_100.pth',\n",
       " 'expr/netCRNN_3840_100.pth',\n",
       " 'expr/netCRNN_3911_100.pth',\n",
       " 'expr/netCRNN_2540_100.pth',\n",
       " 'expr/netCRNN_2600_100.pth',\n",
       " 'expr/netCRNN_410_100.pth',\n",
       " 'expr/netCRNN_840_100.pth',\n",
       " 'expr/netCRNN_3913_100.pth',\n",
       " 'expr/netCRNN_2850_100.pth',\n",
       " 'expr/netCRNN_1760_100.pth',\n",
       " 'expr/netCRNN_550_100.pth',\n",
       " 'expr/netCRNN_530_100.pth',\n",
       " 'expr/netCRNN_950_100.pth',\n",
       " 'expr/netCRNN_3970_100.pth',\n",
       " 'expr/netCRNN_3859_100.pth',\n",
       " 'expr/netCRNN_2370_100.pth',\n",
       " 'expr/netCRNN_120_100.pth',\n",
       " 'expr/netCRNN_3918_100.pth',\n",
       " 'expr/netCRNN_3100_100.pth',\n",
       " 'expr/netCRNN_3895_100.pth',\n",
       " 'expr/netCRNN_1520_100.pth',\n",
       " 'expr/netCRNN_1830_100.pth',\n",
       " 'expr/netCRNN_3881_100.pth',\n",
       " 'expr/netCRNN_830_100.pth',\n",
       " 'expr/netCRNN_1460_100.pth',\n",
       " 'expr/netCRNN_180_100.pth',\n",
       " 'expr/netCRNN_2630_100.pth',\n",
       " 'expr/netCRNN_970_100.pth',\n",
       " 'expr/netCRNN_1500_100.pth',\n",
       " 'expr/netCRNN_1480_100.pth',\n",
       " 'expr/netCRNN_2320_100.pth',\n",
       " 'expr/netCRNN_1410_100.pth',\n",
       " 'expr/netCRNN_1380_100.pth',\n",
       " 'expr/netCRNN_2770_100.pth',\n",
       " 'expr/netCRNN_3945_100.pth',\n",
       " 'expr/netCRNN_2590_100.pth',\n",
       " 'expr/netCRNN_2380_100.pth',\n",
       " 'expr/netCRNN_3820_100.pth',\n",
       " 'expr/netCRNN_3908_100.pth',\n",
       " 'expr/netCRNN_1390_100.pth',\n",
       " 'expr/netCRNN_1060_100.pth',\n",
       " 'expr/netCRNN_2070_100.pth',\n",
       " 'expr/netCRNN_1890_100.pth',\n",
       " 'expr/netCRNN_3360_100.pth',\n",
       " 'expr/netCRNN_1020_100.pth',\n",
       " 'expr/netCRNN_3947_100.pth',\n",
       " 'expr/netCRNN_3370_100.pth',\n",
       " 'expr/netCRNN_1240_100.pth',\n",
       " 'expr/netCRNN_1850_100.pth',\n",
       " 'expr/netCRNN_3948_100.pth',\n",
       " 'expr/netCRNN_1730_100.pth',\n",
       " 'expr/netCRNN_2810_100.pth',\n",
       " 'expr/netCRNN_260_100.pth',\n",
       " 'expr/netCRNN_280_100.pth',\n",
       " 'expr/netCRNN_2240_100.pth',\n",
       " 'expr/netCRNN_3910_100.pth',\n",
       " 'expr/netCRNN_2310_100.pth',\n",
       " 'expr/netCRNN_3600_100.pth',\n",
       " 'expr/netCRNN_3904_100.pth',\n",
       " 'expr/netCRNN_1170_100.pth',\n",
       " 'expr/netCRNN_190_100.pth',\n",
       " 'expr/netCRNN_2920_100.pth',\n",
       " 'expr/netCRNN_3937_100.pth',\n",
       " 'expr/netCRNN_3965_100.pth',\n",
       " 'expr/netCRNN_1700_100.pth',\n",
       " 'expr/netCRNN_3928_100.pth',\n",
       " 'expr/netCRNN_650_100.pth',\n",
       " 'expr/netCRNN_3200_100.pth',\n",
       " 'expr/netCRNN_3500_100.pth',\n",
       " 'expr/netCRNN_3130_100.pth',\n",
       " 'expr/netCRNN_3909_100.pth',\n",
       " 'expr/netCRNN_3889_100.pth',\n",
       " 'expr/netCRNN_3964_100.pth',\n",
       " 'expr/netCRNN_3930_100.pth',\n",
       " 'expr/netCRNN_3879_100.pth',\n",
       " 'expr/netCRNN_3955_100.pth',\n",
       " 'expr/netCRNN_3962_100.pth',\n",
       " 'expr/netCRNN_470_100.pth',\n",
       " 'expr/netCRNN_3857_100.pth',\n",
       " 'expr/netCRNN_3460_100.pth',\n",
       " 'expr/netCRNN_620_100.pth',\n",
       " 'expr/netCRNN_1320_100.pth',\n",
       " 'expr/netCRNN_1040_100.pth',\n",
       " 'expr/netCRNN_770_100.pth',\n",
       " 'expr/netCRNN_3220_100.pth',\n",
       " 'expr/netCRNN_1920_100.pth',\n",
       " 'expr/netCRNN_940_100.pth',\n",
       " 'expr/netCRNN_660_100.pth',\n",
       " 'expr/netCRNN_240_100.pth',\n",
       " 'expr/netCRNN_3950_100.pth',\n",
       " 'expr/netCRNN_3870_100.pth',\n",
       " 'expr/netCRNN_920_100.pth',\n",
       " 'expr/netCRNN_2780_100.pth',\n",
       " 'expr/netCRNN_3893_100.pth',\n",
       " 'expr/netCRNN_670_100.pth',\n",
       " 'expr/netCRNN_3875_100.pth',\n",
       " 'expr/netCRNN_3951_100.pth',\n",
       " 'expr/netCRNN_3883_100.pth',\n",
       " 'expr/netCRNN_3901_100.pth',\n",
       " 'expr/netCRNN_1450_100.pth',\n",
       " 'expr/netCRNN_810_100.pth',\n",
       " 'expr/netCRNN_3610_100.pth',\n",
       " 'expr/netCRNN_2790_100.pth',\n",
       " 'expr/netCRNN_3939_100.pth',\n",
       " 'expr/netCRNN_210_100.pth',\n",
       " 'expr/netCRNN_3800_100.pth',\n",
       " 'expr/netCRNN_1330_100.pth',\n",
       " 'expr/netCRNN_2640_100.pth',\n",
       " 'expr/netCRNN_3140_100.pth',\n",
       " 'expr/netCRNN_1570_100.pth',\n",
       " 'expr/netCRNN_3830_100.pth',\n",
       " 'expr/netCRNN_3877_100.pth',\n",
       " 'expr/netCRNN_1550_100.pth',\n",
       " 'expr/netCRNN_1990_100.pth',\n",
       " 'expr/netCRNN_3886_100.pth',\n",
       " 'expr/netCRNN_3000_100.pth',\n",
       " 'expr/netCRNN_3040_100.pth',\n",
       " 'expr/netCRNN_3884_100.pth',\n",
       " 'expr/netCRNN_3430_100.pth',\n",
       " 'expr/netCRNN_2280_100.pth',\n",
       " 'expr/netCRNN_3030_100.pth',\n",
       " 'expr/netCRNN_1440_100.pth',\n",
       " 'expr/netCRNN_3070_100.pth',\n",
       " 'expr/netCRNN_2120_100.pth',\n",
       " 'expr/netCRNN_3876_100.pth',\n",
       " 'expr/netCRNN_3320_100.pth',\n",
       " 'expr/netCRNN_680_100.pth',\n",
       " 'expr/netCRNN_1580_100.pth',\n",
       " 'expr/netCRNN_2250_100.pth',\n",
       " 'expr/netCRNN_2440_100.pth',\n",
       " 'expr/netCRNN_3090_100.pth',\n",
       " 'expr/netCRNN_1050_100.pth',\n",
       " 'expr/netCRNN_2100_100.pth',\n",
       " 'expr/netCRNN_700_100.pth',\n",
       " 'expr/netCRNN_3860_100.pth',\n",
       " 'expr/netCRNN_3942_100.pth',\n",
       " 'expr/netCRNN_3865_100.pth',\n",
       " 'expr/netCRNN_640_100.pth',\n",
       " 'expr/netCRNN_3010_100.pth',\n",
       " 'expr/netCRNN_1940_100.pth',\n",
       " 'expr/netCRNN_2990_100.pth',\n",
       " 'expr/netCRNN_2010_100.pth',\n",
       " 'expr/netCRNN_2110_100.pth',\n",
       " 'expr/netCRNN_3868_100.pth',\n",
       " 'expr/netCRNN_1150_100.pth',\n",
       " 'expr/netCRNN_2230_100.pth',\n",
       " 'expr/netCRNN_1100_100.pth',\n",
       " 'expr/netCRNN_3410_100.pth',\n",
       " 'expr/netCRNN_1190_100.pth',\n",
       " 'expr/netCRNN_310_100.pth',\n",
       " 'expr/netCRNN_2550_100.pth',\n",
       " 'expr/netCRNN_400_100.pth']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "#glob.glob('expr/*')\n",
    "\n",
    "# We are focusing on dylan's models here\n",
    "model_path = '/home/ubuntu/dylan/nephi/expr/'\n",
    "train_results = {}\n",
    "test_results = {}\n",
    "for model in glob.glob(model_path + '*'):\n",
    "    # Load the weights of the model\n",
    "    print('loading pretrained model from %s' % (model_path + model))\n",
    "    crnn.load_state_dict(torch.load(trained_crnn))\n",
    "    \n",
    "    char_error, w_error = val(crnn, test_dataset, criterion)\n",
    "    test_results[model] = {\"char\" : (np.mean(char_error), np.std(char_error, ddof=1)),\n",
    "                          \"word\": (np.mean(w_error), np.std(w_error, ddof=1))}\n",
    "    char_error, w_error = val(crnn, train_dataset, criterion)\n",
    "    train_results[model] = {\"char\" : (np.mean(char_error), np.std(char_error, ddof=1)),\n",
    "                          \"word\": (np.mean(w_error), np.std(w_error, ddof=1))}\n",
    "    print(\"Finished model: %s\" % model)\n",
    "    \n",
    "# Now let's write the output to a csv file\n",
    "with open ('dylan_results.csv', 'w') as f:\n",
    "    f.write('Model, Dataset, Character Error (mean), Character Error (sd), Word Error (mean), Word Error (sd)\\n')\n",
    "    for key, value in test_results.items():\n",
    "        f.write(\"%s, %s, %4.4f, %4.4f, %4.4f, %4.4f\\n\" % (key, 'validation', value['char'][0], value['char'][1], value['word'][0], value['word'][1]))\n",
    "        \n",
    "    for key, value in train_results.items():\n",
    "        f.write(\"%s, %s, %4.4f, %4.4f, %4.4f, %4.4f\\n\" % (key, 'training', value['char'][0], value['char'][1], value['word'][0], value['word'][1]))\n",
    "\n",
    "# I think putting all this in a panda spreadsheet would probably be best. I'll do this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.300000, 2.500000, 3.500000, 1.400000\n"
     ]
    }
   ],
   "source": [
    "nums = (1.4, 2.5, 3.5)\n",
    "\n",
    "print(\"%f, %f, %f, %f\" % (1.3, nums[1], nums[2], nums[0] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
