Running with options: Namespace(adadelta=False, adam=False, alphabet='0123456789abcdefghijklmnopqrstuvwxyz', batchSize=2, beta1=0.5, crnn='/deep_data/nephi/experiments/expr_ICFHR_27Mar_alph_werr_fixed/netCRNN_0_5963.pth', cuda=True, displayInterval=120, experiment='experiments/expr_ICFHR_27Mar_alph_werr_fixed', imgH=80, imgW=240, keep_ratio=True, lr=0.0001, n_test_disp=10, ngpu=1, nh=256, niter=200, random_sample=False, saveEpoch=5, test_file='test_file', test_icfhr=False, trainroot='/deep_data/nephi/data/lmdb_ICFHR/general_data', valEpoch=5, valroot='/deep_data/nephi/data/lmdb_ICFHR/specific_data', workers=10)
Random Seed:  3747
This is the alphabet:
eniratsdholcugmv.wbf,zkpySDA-MEjGBIHVßCWP1N¬TJFKRO"ʒLæx2:’q08ZU;–3'4·ø7!5?6)9(—/=┌YQ&X«»[│]§°ειν”τ|ασ 
loading pretrained model from /deep_data/nephi/experiments/expr_ICFHR_27Mar_alph_werr_fixed/netCRNN_0_5963.pth
Your neural network: DataParallel(
  (module): CRNN(
    (cnn): Sequential(
      (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu0): ReLU(inplace)
      (pooling0): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu1): ReLU(inplace)
      (pooling1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
      (relu2): ReLU(inplace)
      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu3): ReLU(inplace)
      (pooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=(1, 1), ceil_mode=False)
      (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
      (relu4): ReLU(inplace)
      (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu5): ReLU(inplace)
      (pooling3): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=(1, 1), ceil_mode=False)
      (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))
      (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
      (relu6): ReLU(inplace)
    )
    (rnn): Sequential(
      (0): BidirectionalLSTM(
        (rnn): LSTM(512, 256, bidirectional=True)
        (embedding): Linear(in_features=512, out_features=256, bias=True)
      )
      (1): BidirectionalLSTM(
        (rnn): LSTM(256, 256, bidirectional=True)
        (embedding): Linear(in_features=512, out_features=103, bias=True)
      )
    )
  )
)
Starting training...
[0/200][120/5963] Loss: 58.463978
[0/200][240/5963] Loss: 54.012676
[0/200][360/5963] Loss: 49.557260
[0/200][480/5963] Loss: 48.205032
[0/200][600/5963] Loss: 50.558604
[0/200][720/5963] Loss: 54.526722
[0/200][840/5963] Loss: 49.516797
[0/200][960/5963] Loss: 46.666422
[0/200][1080/5963] Loss: 50.114162
[0/200][1200/5963] Loss: 44.442392
[0/200][1320/5963] Loss: 48.056215
[0/200][1440/5963] Loss: 48.064760
[0/200][1560/5963] Loss: 41.685924
[0/200][1680/5963] Loss: 43.534823
[0/200][1800/5963] Loss: 43.850569
[0/200][1920/5963] Loss: 42.489910
[0/200][2040/5963] Loss: 45.345961
[0/200][2160/5963] Loss: 46.414685
[0/200][2280/5963] Loss: 45.919908
[0/200][2400/5963] Loss: 38.177155
[0/200][2520/5963] Loss: 48.068121
[0/200][2640/5963] Loss: 38.957755
[0/200][2760/5963] Loss: 38.038689
[0/200][2880/5963] Loss: 44.799543
[0/200][3000/5963] Loss: 48.086832
[0/200][3120/5963] Loss: 39.005417
[0/200][3240/5963] Loss: 41.927955
[0/200][3360/5963] Loss: 39.113507
[0/200][3480/5963] Loss: 36.192698
[0/200][3600/5963] Loss: 41.851550
[0/200][3720/5963] Loss: 41.099159
[0/200][3840/5963] Loss: 34.805707
[0/200][3960/5963] Loss: 39.202400
[0/200][4080/5963] Loss: 38.791445
[0/200][4200/5963] Loss: 33.352544
[0/200][4320/5963] Loss: 35.729425
[0/200][4440/5963] Loss: 40.655959
[0/200][4560/5963] Loss: 38.760288
[0/200][4680/5963] Loss: 40.453088
[0/200][4800/5963] Loss: 38.902185
[0/200][4920/5963] Loss: 35.822059
[0/200][5040/5963] Loss: 36.754594
[0/200][5160/5963] Loss: 34.329102
[0/200][5280/5963] Loss: 34.610329
[0/200][5400/5963] Loss: 35.234436
[0/200][5520/5963] Loss: 36.631107
[0/200][5640/5963] Loss: 31.514190
[0/200][5760/5963] Loss: 33.707196
[0/200][5880/5963] Loss: 35.116370
Start validation set
--B---------u----e----  -G------u---e--f---------------n-----  p------aa----t------------a---------------------t------ => Bue Guefn patat     , gt: Sie hiesz in patelamut
-------------------------------------------------p----e-----------o--------------------------------------------------- => peo                 , gt: gerich              
Total number of images in validation set:     2000
Test loss: 61.594599, accuracy: 0.005500
Character error rate mean: 0.6983; Character error rate sd: 0.3767
Word error rate mean: 1.3510; Word error rate sd: 0.8450
Start validation set
------------------------------------------------------------------------------O---------s-------o--------  -a------l---ll-----a---------- -u----e------s----------p-----r------a-------------------------------------------------------------------------------- => Oso alla uespra     , gt: Oss alla uppa       
------------M--------------------aa-------rr-------  -o------c----k-----------  d-----i----------n--------  D-----------a--------------------e------k--------e-------- --aa-----k--------t------  -b-----ee------g--------k--------a-------t--t---e--r---------- => Mar ock din Daeke akt begkatter-, gt: Har ock sin Dyveke att begrata.
Total number of images in validation set:     2000
Test loss: 45.397338, accuracy: 0.002000
Character error rate mean: 0.4994; Character error rate sd: 1.1743
Word error rate mean: 0.9435; Word error rate sd: 0.5203
Saving epoch experiments/expr_ICFHR_27Mar_alph_werr_fixed/netCRNN_0_5963.pth
[1/200][120/5963] Loss: 33.568922
[1/200][240/5963] Loss: 33.535127
[1/200][360/5963] Loss: 38.564851
[1/200][480/5963] Loss: 33.561219
[1/200][600/5963] Loss: 28.800233
[1/200][720/5963] Loss: 32.735116
[1/200][840/5963] Loss: 33.958030
[1/200][960/5963] Loss: 31.745921
[1/200][1080/5963] Loss: 30.526993
[1/200][1200/5963] Loss: 32.335676
[1/200][1320/5963] Loss: 33.265149
[1/200][1440/5963] Loss: 30.848037
[1/200][1560/5963] Loss: 32.078866
[1/200][1680/5963] Loss: 34.908643
[1/200][1800/5963] Loss: 28.007401
[1/200][1920/5963] Loss: 34.247255
[1/200][2040/5963] Loss: 37.135632
[1/200][2160/5963] Loss: 32.798283
[1/200][2280/5963] Loss: 28.877473
[1/200][2400/5963] Loss: 30.186379
[1/200][2520/5963] Loss: 30.252801
[1/200][2640/5963] Loss: 32.507211
[1/200][2760/5963] Loss: 28.908475
[1/200][2880/5963] Loss: 27.226103
[1/200][3000/5963] Loss: 29.392551
[1/200][3120/5963] Loss: 32.678178
[1/200][3240/5963] Loss: 31.253843
[1/200][3360/5963] Loss: 33.962127
[1/200][3480/5963] Loss: 27.271699
[1/200][3600/5963] Loss: 30.368963
[1/200][3720/5963] Loss: 34.435470
[1/200][3840/5963] Loss: 24.762194
[1/200][3960/5963] Loss: 31.322834
[1/200][4080/5963] Loss: 30.442707
[1/200][4200/5963] Loss: 28.466452
[1/200][4320/5963] Loss: 28.536740
[1/200][4440/5963] Loss: 36.665052
[1/200][4560/5963] Loss: 29.012270
[1/200][4680/5963] Loss: 30.814468
[1/200][4800/5963] Loss: 30.887364
[1/200][4920/5963] Loss: 26.456803
[1/200][5040/5963] Loss: 29.897482
[1/200][5160/5963] Loss: 25.399379
[1/200][5280/5963] Loss: 32.452131
[1/200][5400/5963] Loss: 26.646243
[1/200][5520/5963] Loss: 28.632501
[1/200][5640/5963] Loss: 25.023327
[1/200][5760/5963] Loss: 27.861045
[1/200][5880/5963] Loss: 23.343916
[2/200][120/5963] Loss: 23.307429
[2/200][240/5963] Loss: 21.076541
[2/200][360/5963] Loss: 25.297060
[2/200][480/5963] Loss: 27.097513
[2/200][600/5963] Loss: 28.480365
[2/200][720/5963] Loss: 25.700682
[2/200][840/5963] Loss: 28.996804
[2/200][960/5963] Loss: 27.747602
[2/200][1080/5963] Loss: 25.529008
[2/200][1200/5963] Loss: 25.365510
[2/200][1320/5963] Loss: 23.021705
[2/200][1440/5963] Loss: 26.341259
[2/200][1560/5963] Loss: 25.082552
[2/200][1680/5963] Loss: 25.355005
[2/200][1800/5963] Loss: 30.346273
[2/200][1920/5963] Loss: 24.591897
[2/200][2040/5963] Loss: 25.436151
[2/200][2160/5963] Loss: 30.013179
[2/200][2280/5963] Loss: 24.848464
[2/200][2400/5963] Loss: 25.928006
[2/200][2520/5963] Loss: 24.028489
[2/200][2640/5963] Loss: 24.644194
[2/200][2760/5963] Loss: 20.776075
[2/200][2880/5963] Loss: 27.195885
[2/200][3000/5963] Loss: 24.815400
[2/200][3120/5963] Loss: 25.134660
[2/200][3240/5963] Loss: 23.458631
[2/200][3360/5963] Loss: 22.754047
[2/200][3480/5963] Loss: 26.977860
[2/200][3600/5963] Loss: 22.357190
[2/200][3720/5963] Loss: 26.877459
[2/200][3840/5963] Loss: 23.290481
[2/200][3960/5963] Loss: 19.968181
[2/200][4080/5963] Loss: 22.643693
[2/200][4200/5963] Loss: 23.340626
[2/200][4320/5963] Loss: 29.319173
[2/200][4440/5963] Loss: 23.810260
[2/200][4560/5963] Loss: 23.349013
[2/200][4680/5963] Loss: 23.027159
[2/200][4800/5963] Loss: 21.562349
[2/200][4920/5963] Loss: 22.966337
[2/200][5040/5963] Loss: 22.215008
[2/200][5160/5963] Loss: 26.873411
[2/200][5280/5963] Loss: 24.076268
[2/200][5400/5963] Loss: 23.434242
[2/200][5520/5963] Loss: 20.772401
[2/200][5640/5963] Loss: 19.989168
[2/200][5760/5963] Loss: 21.903602
[2/200][5880/5963] Loss: 21.916602
[3/200][120/5963] Loss: 22.361825
[3/200][240/5963] Loss: 20.012953
[3/200][360/5963] Loss: 19.605674
[3/200][480/5963] Loss: 22.614177
[3/200][600/5963] Loss: 20.419942
[3/200][720/5963] Loss: 20.673245
[3/200][840/5963] Loss: 24.435647
[3/200][960/5963] Loss: 19.905146
[3/200][1080/5963] Loss: 22.752581
[3/200][1200/5963] Loss: 21.826909
[3/200][1320/5963] Loss: 22.619142
[3/200][1440/5963] Loss: 21.200334
[3/200][1560/5963] Loss: 22.248142
[3/200][1680/5963] Loss: 20.460878
[3/200][1800/5963] Loss: 19.668616
[3/200][1920/5963] Loss: 23.173563
[3/200][2040/5963] Loss: 25.705603
[3/200][2160/5963] Loss: 22.395335
[3/200][2280/5963] Loss: 27.298413
[3/200][2400/5963] Loss: 23.385327
[3/200][2520/5963] Loss: 20.502504
[3/200][2640/5963] Loss: 16.999039
[3/200][2760/5963] Loss: 21.479649
[3/200][2880/5963] Loss: 18.153673
[3/200][3000/5963] Loss: 20.615343
[3/200][3120/5963] Loss: 19.396136
[3/200][3240/5963] Loss: 18.028410
[3/200][3360/5963] Loss: 21.839640
[3/200][3480/5963] Loss: 20.846983
[3/200][3600/5963] Loss: 18.330314
[3/200][3720/5963] Loss: 21.057640
[3/200][3840/5963] Loss: 22.141287
[3/200][3960/5963] Loss: 19.318782
[3/200][4080/5963] Loss: 20.253540
[3/200][4200/5963] Loss: 18.946742
[3/200][4320/5963] Loss: 19.790498
[3/200][4440/5963] Loss: 21.195649
[3/200][4560/5963] Loss: 20.155802
[3/200][4680/5963] Loss: 19.553348
[3/200][4800/5963] Loss: 20.026862
[3/200][4920/5963] Loss: 21.121632
[3/200][5040/5963] Loss: 20.361171
[3/200][5160/5963] Loss: 20.053213
[3/200][5280/5963] Loss: 14.137878
[3/200][5400/5963] Loss: 19.620794
[3/200][5520/5963] Loss: 17.630329
[3/200][5640/5963] Loss: 18.109710
[3/200][5760/5963] Loss: 19.233455
[3/200][5880/5963] Loss: 18.837421
[4/200][120/5963] Loss: 19.352534
[4/200][240/5963] Loss: 17.946246
[4/200][360/5963] Loss: 19.590050
[4/200][480/5963] Loss: 19.760527
[4/200][600/5963] Loss: 18.009111
[4/200][720/5963] Loss: 18.016827
[4/200][840/5963] Loss: 15.254256
[4/200][960/5963] Loss: 19.845131
[4/200][1080/5963] Loss: 19.251182
[4/200][1200/5963] Loss: 18.382973
[4/200][1320/5963] Loss: 18.136659
[4/200][1440/5963] Loss: 20.581977
[4/200][1560/5963] Loss: 18.012352
[4/200][1680/5963] Loss: 18.264230
[4/200][1800/5963] Loss: 20.938690
[4/200][1920/5963] Loss: 17.206133
[4/200][2040/5963] Loss: 17.616839
[4/200][2160/5963] Loss: 17.429888
[4/200][2280/5963] Loss: 17.791518
[4/200][2400/5963] Loss: 19.582283
[4/200][2520/5963] Loss: 18.721043
[4/200][2640/5963] Loss: 17.802284
[4/200][2760/5963] Loss: 20.217898
[4/200][2880/5963] Loss: 18.593659
[4/200][3000/5963] Loss: 21.150639
[4/200][3120/5963] Loss: 16.127249
[4/200][3240/5963] Loss: 19.145098
[4/200][3360/5963] Loss: 20.280555
[4/200][3480/5963] Loss: 18.155203
[4/200][3600/5963] Loss: 20.525019
[4/200][3720/5963] Loss: 18.437494
[4/200][3840/5963] Loss: 17.621073
[4/200][3960/5963] Loss: 18.538122
[4/200][4080/5963] Loss: 17.683938
[4/200][4200/5963] Loss: 15.355409
[4/200][4320/5963] Loss: 17.893780
[4/200][4440/5963] Loss: 18.473215
[4/200][4560/5963] Loss: 21.633805
[4/200][4680/5963] Loss: 18.460708
[4/200][4800/5963] Loss: 15.052064
[4/200][4920/5963] Loss: 17.975628
[4/200][5040/5963] Loss: 17.055984
[4/200][5160/5963] Loss: 14.728323
[4/200][5280/5963] Loss: 17.263399
[4/200][5400/5963] Loss: 18.677712
[4/200][5520/5963] Loss: 17.590441
[4/200][5640/5963] Loss: 19.887804
[4/200][5760/5963] Loss: 17.279714
[4/200][5880/5963] Loss: 16.211285
[5/200][120/5963] Loss: 15.438429
[5/200][240/5963] Loss: 16.485599
[5/200][360/5963] Loss: 17.100697
[5/200][480/5963] Loss: 14.020642
[5/200][600/5963] Loss: 20.412084
[5/200][720/5963] Loss: 15.565587
[5/200][840/5963] Loss: 14.304032
[5/200][960/5963] Loss: 16.635805
[5/200][1080/5963] Loss: 14.207138
[5/200][1200/5963] Loss: 16.507117
[5/200][1320/5963] Loss: 16.363493
[5/200][1440/5963] Loss: 15.824447
[5/200][1560/5963] Loss: 17.432561
[5/200][1680/5963] Loss: 18.042729
[5/200][1800/5963] Loss: 15.394521
[5/200][1920/5963] Loss: 19.137578
[5/200][2040/5963] Loss: 16.022153
[5/200][2160/5963] Loss: 15.451293
[5/200][2280/5963] Loss: 18.159297
[5/200][2400/5963] Loss: 19.093183
[5/200][2520/5963] Loss: 18.355710
[5/200][2640/5963] Loss: 17.988032
[5/200][2760/5963] Loss: 12.976446
[5/200][2880/5963] Loss: 15.283360
[5/200][3000/5963] Loss: 16.102806
[5/200][3120/5963] Loss: 14.674086
[5/200][3240/5963] Loss: 14.066905
[5/200][3360/5963] Loss: 20.017455
[5/200][3480/5963] Loss: 13.540723
[5/200][3600/5963] Loss: 15.505932
[5/200][3720/5963] Loss: 11.813009
[5/200][3840/5963] Loss: 12.124914
[5/200][3960/5963] Loss: 18.552076
[5/200][4080/5963] Loss: 16.673565
[5/200][4200/5963] Loss: 18.798896
[5/200][4320/5963] Loss: 18.503423
[5/200][4440/5963] Loss: 19.343408
[5/200][4560/5963] Loss: 13.826166
[5/200][4680/5963] Loss: 17.397103
[5/200][4800/5963] Loss: 13.946847
[5/200][4920/5963] Loss: 13.729587
[5/200][5040/5963] Loss: 14.661174
[5/200][5160/5963] Loss: 16.234979
[5/200][5280/5963] Loss: 14.385239
[5/200][5400/5963] Loss: 12.968062
[5/200][5520/5963] Loss: 15.628170
[5/200][5640/5963] Loss: 15.086083
[5/200][5760/5963] Loss: 15.757127
[5/200][5880/5963] Loss: 16.730960
Start validation set
---------------D------r-----p-------a---t---t---------  s---i-----t------  -g-----e-----n----e----  -D------o---rr----- --n------h------n---t----------------------- => Drpatt sit gene Dor nhnt, gt: Dy hattn sich hene vor irhabn
----D--------------r----------u---f----f-------  ------v-------r----------A-------u------d----------------  -d------i-----ß-----f---------e------  P-----a-----r---- => Druff vrAud dißfe Par, gt: Dar uff eyn andir degke lac
Total number of images in validation set:     2000
Test loss: 60.122875, accuracy: 0.003500
Character error rate mean: 0.5453; Character error rate sd: 0.3214
Word error rate mean: 1.0232; Word error rate sd: 0.4253
Start validation set
-d--e-----n--- C--o---nn--s--ee-n----s----  h---i--n---zz----u------  b----e---ii--b----r----i---n---g---e--n-----,, s---o---- -----w------aa-----r---e---  d---ii-e---s--i--s--- -d--e--s--t-o-- b--i-s----e---r---- => den Consens hinzu beibringen, so ware diesis desto biser, gt: den Consens hiezu beibringen, so ware dieses desto beßer.
------------g---e---r----i---n----g---e----n-----  W-------e---r--t-h-ee---  -a-----u---f-----   d--e----r----- -A----c---a---d--e------m----i--s--c-h-e-----n-- -B---i---b--l-ii--o--t-hh--e-----k-------,---------- => geringen Werthe auf der Academischen Bibliothek,, gt: geringen Werthe auf der Academischen Bibliothek,
Total number of images in validation set:     2000
Test loss: 24.514071, accuracy: 0.067000
Character error rate mean: 0.2462; Character error rate sd: 0.4911
Word error rate mean: 0.5620; Word error rate sd: 0.4610
Saving epoch experiments/expr_ICFHR_27Mar_alph_werr_fixed/netCRNN_5_5963.pth
[6/200][120/5963] Loss: 15.113421
[6/200][240/5963] Loss: 13.710203
[6/200][360/5963] Loss: 13.615505
[6/200][480/5963] Loss: 13.366390
[6/200][600/5963] Loss: 16.167720
[6/200][720/5963] Loss: 14.858481
[6/200][840/5963] Loss: 14.744556
[6/200][960/5963] Loss: 14.376304
[6/200][1080/5963] Loss: 14.835874
[6/200][1200/5963] Loss: 14.998306
[6/200][1320/5963] Loss: 11.862631
[6/200][1440/5963] Loss: 11.709942
[6/200][1560/5963] Loss: 15.563026
[6/200][1680/5963] Loss: 14.400978
[6/200][1800/5963] Loss: 13.819601
[6/200][1920/5963] Loss: 12.404451
[6/200][2040/5963] Loss: 14.982069
[6/200][2160/5963] Loss: 14.306517
[6/200][2280/5963] Loss: 14.534122
[6/200][2400/5963] Loss: 12.570084
[6/200][2520/5963] Loss: 15.453178
[6/200][2640/5963] Loss: 14.529752
[6/200][2760/5963] Loss: 12.924871
[6/200][2880/5963] Loss: 15.257822
[6/200][3000/5963] Loss: 12.802915
[6/200][3120/5963] Loss: 11.987354
[6/200][3240/5963] Loss: 13.865972
[6/200][3360/5963] Loss: 14.627957
[6/200][3480/5963] Loss: 13.995208
[6/200][3600/5963] Loss: 14.757267
[6/200][3720/5963] Loss: 12.340959
[6/200][3840/5963] Loss: 11.897657
[6/200][3960/5963] Loss: 14.700379
[6/200][4080/5963] Loss: 14.974820
[6/200][4200/5963] Loss: 12.404132
[6/200][4320/5963] Loss: nan
[6/200][4440/5963] Loss: 14.288800
[6/200][4560/5963] Loss: 12.785863
[6/200][4680/5963] Loss: 12.657764
[6/200][4800/5963] Loss: 15.592005
[6/200][4920/5963] Loss: 11.416788
[6/200][5040/5963] Loss: 13.675472
[6/200][5160/5963] Loss: 14.120004
[6/200][5280/5963] Loss: 13.549567
[6/200][5400/5963] Loss: 12.061734
[6/200][5520/5963] Loss: 11.403659
[6/200][5640/5963] Loss: 11.587290
[6/200][5760/5963] Loss: 13.481817
[6/200][5880/5963] Loss: 13.325971
[7/200][120/5963] Loss: 12.470771
[7/200][240/5963] Loss: 13.138993
[7/200][360/5963] Loss: 12.629691
[7/200][480/5963] Loss: 14.967806
[7/200][600/5963] Loss: 11.607307
[7/200][720/5963] Loss: 14.160163
[7/200][840/5963] Loss: 17.143042
[7/200][960/5963] Loss: 12.034704
[7/200][1080/5963] Loss: 12.595583
[7/200][1200/5963] Loss: 11.917951
[7/200][1320/5963] Loss: 10.718808
[7/200][1440/5963] Loss: 14.089711
[7/200][1560/5963] Loss: 15.496308
[7/200][1680/5963] Loss: 12.862173
[7/200][1800/5963] Loss: 13.357025
[7/200][1920/5963] Loss: 13.332945
[7/200][2040/5963] Loss: 13.272311
[7/200][2160/5963] Loss: 15.534553
[7/200][2280/5963] Loss: 12.297023
[7/200][2400/5963] Loss: 10.946753
[7/200][2520/5963] Loss: 10.955200
[7/200][2640/5963] Loss: 13.870823
[7/200][2760/5963] Loss: 11.440692
[7/200][2880/5963] Loss: 15.304371
[7/200][3000/5963] Loss: 12.773430
[7/200][3120/5963] Loss: 10.508789
[7/200][3240/5963] Loss: 13.750221
[7/200][3360/5963] Loss: 13.615368
[7/200][3480/5963] Loss: 10.446458
[7/200][3600/5963] Loss: 10.741081
[7/200][3720/5963] Loss: 14.760947
[7/200][3840/5963] Loss: 13.682162
[7/200][3960/5963] Loss: 12.817591
[7/200][4080/5963] Loss: 11.538012
[7/200][4200/5963] Loss: 12.881268
[7/200][4320/5963] Loss: 13.347910
[7/200][4440/5963] Loss: 14.377912
[7/200][4560/5963] Loss: 11.517238
[7/200][4680/5963] Loss: 11.545024
[7/200][4800/5963] Loss: 11.001601
[7/200][4920/5963] Loss: 12.788025
[7/200][5040/5963] Loss: 10.848829
[7/200][5160/5963] Loss: 13.073034
[7/200][5280/5963] Loss: 12.965586
[7/200][5400/5963] Loss: 10.045669
[7/200][5520/5963] Loss: 13.771059
[7/200][5640/5963] Loss: 11.665746
[7/200][5760/5963] Loss: 12.465068
[7/200][5880/5963] Loss: 12.468396
[8/200][120/5963] Loss: 12.775629
[8/200][240/5963] Loss: 12.110431
[8/200][360/5963] Loss: 13.333928
[8/200][480/5963] Loss: 11.833264
[8/200][600/5963] Loss: 12.944378
[8/200][720/5963] Loss: 11.977808
[8/200][840/5963] Loss: 16.815040
[8/200][960/5963] Loss: 11.311940
[8/200][1080/5963] Loss: 10.129140
[8/200][1200/5963] Loss: 13.036222
[8/200][1320/5963] Loss: 8.332338
[8/200][1440/5963] Loss: 9.440730
[8/200][1560/5963] Loss: 12.863341
[8/200][1680/5963] Loss: 12.504660
[8/200][1800/5963] Loss: 11.848560
[8/200][1920/5963] Loss: 11.782083
[8/200][2040/5963] Loss: 11.889855
[8/200][2160/5963] Loss: 12.102680
[8/200][2280/5963] Loss: 8.907737
[8/200][2400/5963] Loss: 14.067640
[8/200][2520/5963] Loss: 10.549558
[8/200][2640/5963] Loss: 10.505005
[8/200][2760/5963] Loss: 11.035029
[8/200][2880/5963] Loss: 12.282615
[8/200][3000/5963] Loss: 14.467102
[8/200][3120/5963] Loss: 10.965827
[8/200][3240/5963] Loss: 7.630120
[8/200][3360/5963] Loss: 11.159225
[8/200][3480/5963] Loss: 9.863527
[8/200][3600/5963] Loss: 10.001129
[8/200][3720/5963] Loss: 14.548910
[8/200][3840/5963] Loss: 10.770622
[8/200][3960/5963] Loss: 11.296638
[8/200][4080/5963] Loss: 10.942842
[8/200][4200/5963] Loss: 12.540550
[8/200][4320/5963] Loss: 10.131570
[8/200][4440/5963] Loss: 9.008749
[8/200][4560/5963] Loss: 13.490427
[8/200][4680/5963] Loss: 10.646353
[8/200][4800/5963] Loss: 9.952933
[8/200][4920/5963] Loss: 12.624073
[8/200][5040/5963] Loss: 10.111226
[8/200][5160/5963] Loss: 10.631113
[8/200][5280/5963] Loss: 11.327265
[8/200][5400/5963] Loss: 8.748544
[8/200][5520/5963] Loss: 10.880222
[8/200][5640/5963] Loss: 10.391028
[8/200][5760/5963] Loss: 11.953881
[8/200][5880/5963] Loss: 9.157833
[9/200][120/5963] Loss: 10.086052
[9/200][240/5963] Loss: 10.204842
[9/200][360/5963] Loss: 9.578478
[9/200][480/5963] Loss: 12.670275
[9/200][600/5963] Loss: 11.852828
[9/200][720/5963] Loss: 9.634924
[9/200][840/5963] Loss: 12.235987
[9/200][960/5963] Loss: 12.170284
[9/200][1080/5963] Loss: 7.418191
[9/200][1200/5963] Loss: 7.870513
[9/200][1320/5963] Loss: 11.407689
[9/200][1440/5963] Loss: 9.751704
[9/200][1560/5963] Loss: 11.143371
[9/200][1680/5963] Loss: 11.378157
[9/200][1800/5963] Loss: 10.301152
[9/200][1920/5963] Loss: 9.956533
[9/200][2040/5963] Loss: 9.235697
[9/200][2160/5963] Loss: 10.568764
[9/200][2280/5963] Loss: 11.202468
[9/200][2400/5963] Loss: 10.793015
[9/200][2520/5963] Loss: 8.659244
[9/200][2640/5963] Loss: 10.241660
[9/200][2760/5963] Loss: 9.260317
[9/200][2880/5963] Loss: 11.535842
[9/200][3000/5963] Loss: 8.855628
[9/200][3120/5963] Loss: 10.773488
[9/200][3240/5963] Loss: 9.717611
[9/200][3360/5963] Loss: 9.653177
[9/200][3480/5963] Loss: 7.395960
[9/200][3600/5963] Loss: 9.390808
[9/200][3720/5963] Loss: 12.602968
[9/200][3840/5963] Loss: 9.169026
[9/200][3960/5963] Loss: 10.922508
[9/200][4080/5963] Loss: 8.878400
[9/200][4200/5963] Loss: 13.328556
[9/200][4320/5963] Loss: 8.265640
[9/200][4440/5963] Loss: 11.508879
[9/200][4560/5963] Loss: 8.933291
[9/200][4680/5963] Loss: 11.226581
[9/200][4800/5963] Loss: 8.896870
[9/200][4920/5963] Loss: 9.409137
[9/200][5040/5963] Loss: 11.573108
[9/200][5160/5963] Loss: 10.374131
[9/200][5280/5963] Loss: 7.174989
[9/200][5400/5963] Loss: 10.424726
[9/200][5520/5963] Loss: 9.612375
[9/200][5640/5963] Loss: 9.116445
[9/200][5760/5963] Loss: 13.223941
[9/200][5880/5963] Loss: 11.765594
[10/200][120/5963] Loss: 9.268231
[10/200][240/5963] Loss: 9.513303
[10/200][360/5963] Loss: 8.954770
[10/200][480/5963] Loss: 9.185050
[10/200][600/5963] Loss: 9.409417
[10/200][720/5963] Loss: 9.645908
[10/200][840/5963] Loss: 9.079272
[10/200][960/5963] Loss: 8.810373
[10/200][1080/5963] Loss: 9.403417
[10/200][1200/5963] Loss: 7.870698
[10/200][1320/5963] Loss: 9.183109
[10/200][1440/5963] Loss: 6.932268
[10/200][1560/5963] Loss: 8.518531
[10/200][1680/5963] Loss: 10.934038
[10/200][1800/5963] Loss: 9.756329
[10/200][1920/5963] Loss: 8.815405
[10/200][2040/5963] Loss: 6.611951
[10/200][2160/5963] Loss: 8.968584
[10/200][2280/5963] Loss: 11.492490
[10/200][2400/5963] Loss: 8.925379
[10/200][2520/5963] Loss: 12.005375
[10/200][2640/5963] Loss: 8.823037
[10/200][2760/5963] Loss: 9.770247
[10/200][2880/5963] Loss: 7.107651
[10/200][3000/5963] Loss: 8.918435
[10/200][3120/5963] Loss: 6.971080
[10/200][3240/5963] Loss: 7.979796
[10/200][3360/5963] Loss: 10.618328
[10/200][3480/5963] Loss: 8.556653
[10/200][3600/5963] Loss: 9.058195
[10/200][3720/5963] Loss: 10.009133
[10/200][3840/5963] Loss: 10.214561
[10/200][3960/5963] Loss: 8.249773
[10/200][4080/5963] Loss: 8.098686
[10/200][4200/5963] Loss: 7.550375
[10/200][4320/5963] Loss: 9.388059
[10/200][4440/5963] Loss: 9.033279
[10/200][4560/5963] Loss: 10.539389
[10/200][4680/5963] Loss: 10.449271
[10/200][4800/5963] Loss: 7.498830
[10/200][4920/5963] Loss: 8.482146
[10/200][5040/5963] Loss: 10.407333
[10/200][5160/5963] Loss: 7.380130
[10/200][5280/5963] Loss: 7.025920
[10/200][5400/5963] Loss: 8.943158
[10/200][5520/5963] Loss: 11.309904
[10/200][5640/5963] Loss: 10.308744
[10/200][5760/5963] Loss: 8.427279
[10/200][5880/5963] Loss: 9.731158
Start validation set
------o---y-----d---..------  -----m---e--nn--d---e--d---i-------  d---ee--rr----------  g---e---ll--e--h--o---t------------  d-----a---s-----c----a---l--- => oyd. mendedi der gelehot dascal, gt: 1640. wendete der gelehrte Pascal
--------"----.--- s---e--ll---k---s-------  r---o---d----   f---ll--a--p---s--e---e---t--------  t---i--t--k----v---e---n--s-k--e----.---  M----a---n------ => ". selks rod flapseet titkvenske. Man, gt: u. selbst 500 Elephant mitbrachte. Nur
Total number of images in validation set:     2000
Test loss: 65.272503, accuracy: 0.002500
Character error rate mean: 0.4806; Character error rate sd: 0.2691
Word error rate mean: 0.9816; Word error rate sd: 0.3667
Start validation set
---------b-----ee----i---t---ee-----nn--------   d----e-----s-----  -D--------r--..-----  WW------e---ii-h---z---------  --uu---b------e-----r-----  E----rr---f-----o-----r---s---cchh-----uu----n--g-- => beiten des Dr. Weihz uber Erforschung, gt: beiten des Dr. Weisz uber Erforschung
-------------------f------e------n-------   -E-------rr-----a--------g------ee-------nn--------  -v-------i----e----ll---l------e-----ii---ccch-----t-----  ss-----cchh-----o-------n------------------- => fen Eragen vielleicht schon, gt: ten Fragen vielleicht schon
Total number of images in validation set:     2000
Test loss: 19.335581, accuracy: 0.083000
Character error rate mean: 0.2043; Character error rate sd: 0.8889
Word error rate mean: 0.4856; Word error rate sd: 0.4193
Saving epoch experiments/expr_ICFHR_27Mar_alph_werr_fixed/netCRNN_10_5963.pth
[11/200][120/5963] Loss: 9.567927
[11/200][240/5963] Loss: 7.395025
[11/200][360/5963] Loss: 7.937051
[11/200][480/5963] Loss: 11.414496
[11/200][600/5963] Loss: 7.265765
[11/200][720/5963] Loss: 6.090696
[11/200][840/5963] Loss: 7.917873
[11/200][960/5963] Loss: 8.934211
[11/200][1080/5963] Loss: 10.256383
[11/200][1200/5963] Loss: 8.536443
[11/200][1320/5963] Loss: 9.674262
[11/200][1440/5963] Loss: 7.944627
[11/200][1560/5963] Loss: 7.614915
[11/200][1680/5963] Loss: 7.834250
[11/200][1800/5963] Loss: 9.838465
[11/200][1920/5963] Loss: 9.965647
[11/200][2040/5963] Loss: 8.658704
[11/200][2160/5963] Loss: 7.691864
[11/200][2280/5963] Loss: 9.270275
[11/200][2400/5963] Loss: 9.508269
[11/200][2520/5963] Loss: 7.537122
[11/200][2640/5963] Loss: 9.959353
[11/200][2760/5963] Loss: 9.216126
[11/200][2880/5963] Loss: 8.660502
[11/200][3000/5963] Loss: 9.468563
[11/200][3120/5963] Loss: 9.237243
[11/200][3240/5963] Loss: 8.757232
[11/200][3360/5963] Loss: 9.638623
[11/200][3480/5963] Loss: 8.510829
[11/200][3600/5963] Loss: 9.827281
[11/200][3720/5963] Loss: 10.103171
[11/200][3840/5963] Loss: 7.860398
[11/200][3960/5963] Loss: 6.376414
[11/200][4080/5963] Loss: 7.405777
[11/200][4200/5963] Loss: 6.330548
[11/200][4320/5963] Loss: 9.237689
[11/200][4440/5963] Loss: 7.650159
[11/200][4560/5963] Loss: 8.856455
[11/200][4680/5963] Loss: 7.543428
[11/200][4800/5963] Loss: 6.730142
[11/200][4920/5963] Loss: 9.977507
[11/200][5040/5963] Loss: 7.475352
[11/200][5160/5963] Loss: 6.766725
[11/200][5280/5963] Loss: 9.725749
[11/200][5400/5963] Loss: 7.859173
[11/200][5520/5963] Loss: 7.695906
[11/200][5640/5963] Loss: 7.071131
[11/200][5760/5963] Loss: 8.860127
[11/200][5880/5963] Loss: 8.037412
[12/200][120/5963] Loss: 6.684429
[12/200][240/5963] Loss: 10.180713
[12/200][360/5963] Loss: 9.843478
[12/200][480/5963] Loss: 8.690182
[12/200][600/5963] Loss: 7.217695
[12/200][720/5963] Loss: 9.343902
[12/200][840/5963] Loss: 8.052084
[12/200][960/5963] Loss: 6.504183
[12/200][1080/5963] Loss: 7.117324
[12/200][1200/5963] Loss: 7.478318
[12/200][1320/5963] Loss: 6.844475
[12/200][1440/5963] Loss: 8.390338
[12/200][1560/5963] Loss: 6.999723
[12/200][1680/5963] Loss: 8.414846
[12/200][1800/5963] Loss: 9.587591
[12/200][1920/5963] Loss: 6.010013
[12/200][2040/5963] Loss: 8.892837
[12/200][2160/5963] Loss: 7.752451
[12/200][2280/5963] Loss: 6.287612
[12/200][2400/5963] Loss: 8.041429
[12/200][2520/5963] Loss: 7.442858
[12/200][2640/5963] Loss: 6.650137
[12/200][2760/5963] Loss: 10.800546
[12/200][2880/5963] Loss: 7.852956
[12/200][3000/5963] Loss: 7.741305
[12/200][3120/5963] Loss: 9.095237
[12/200][3240/5963] Loss: 6.515917
[12/200][3360/5963] Loss: 6.265601
[12/200][3480/5963] Loss: 5.492133
[12/200][3600/5963] Loss: 9.096532
[12/200][3720/5963] Loss: 7.332103
[12/200][3840/5963] Loss: 9.273372
[12/200][3960/5963] Loss: 6.656787
[12/200][4080/5963] Loss: 6.447545
[12/200][4200/5963] Loss: 5.631122
[12/200][4320/5963] Loss: 7.781826
[12/200][4440/5963] Loss: 6.214565
[12/200][4560/5963] Loss: 6.938010
[12/200][4680/5963] Loss: 5.711742
[12/200][4800/5963] Loss: 8.377891
[12/200][4920/5963] Loss: 7.805660
[12/200][5040/5963] Loss: 6.450587
[12/200][5160/5963] Loss: 7.050292
[12/200][5280/5963] Loss: 6.636598
[12/200][5400/5963] Loss: 7.923278
[12/200][5520/5963] Loss: 6.038464
[12/200][5640/5963] Loss: 7.801841
[12/200][5760/5963] Loss: 8.292941
[12/200][5880/5963] Loss: 5.760903
[13/200][120/5963] Loss: 7.189103
[13/200][240/5963] Loss: 6.834639
[13/200][360/5963] Loss: 7.502845
[13/200][480/5963] Loss: 7.720905
[13/200][600/5963] Loss: 5.615491
[13/200][720/5963] Loss: 6.906087
[13/200][840/5963] Loss: 6.803713
[13/200][960/5963] Loss: 8.481863
[13/200][1080/5963] Loss: 6.290914
[13/200][1200/5963] Loss: 6.459217
[13/200][1320/5963] Loss: 7.696236
[13/200][1440/5963] Loss: 5.592358
[13/200][1560/5963] Loss: 5.694877
[13/200][1680/5963] Loss: 5.630850
[13/200][1800/5963] Loss: 6.654515
[13/200][1920/5963] Loss: 7.314761
[13/200][2040/5963] Loss: 6.975761
[13/200][2160/5963] Loss: 6.599418
[13/200][2280/5963] Loss: 5.929029
[13/200][2400/5963] Loss: 6.418654
[13/200][2520/5963] Loss: 7.527815
[13/200][2640/5963] Loss: 6.061242
[13/200][2760/5963] Loss: 7.752287
[13/200][2880/5963] Loss: 6.791816
[13/200][3000/5963] Loss: 6.513137
[13/200][3120/5963] Loss: 6.453288
[13/200][3240/5963] Loss: 6.979408
[13/200][3360/5963] Loss: 6.500069
[13/200][3480/5963] Loss: 5.288076
[13/200][3600/5963] Loss: 6.594481
[13/200][3720/5963] Loss: 8.915972
[13/200][3840/5963] Loss: 6.184517
[13/200][3960/5963] Loss: 4.866663
[13/200][4080/5963] Loss: 5.229520
[13/200][4200/5963] Loss: 6.572413
[13/200][4320/5963] Loss: 7.832869
[13/200][4440/5963] Loss: 8.322616
[13/200][4560/5963] Loss: 5.717554
[13/200][4680/5963] Loss: 7.366519
[13/200][4800/5963] Loss: 7.683917
[13/200][4920/5963] Loss: 5.689138
[13/200][5040/5963] Loss: 6.504206
[13/200][5160/5963] Loss: 6.425997
[13/200][5280/5963] Loss: 8.061225
[13/200][5400/5963] Loss: 5.187275
[13/200][5520/5963] Loss: 7.442100
[13/200][5640/5963] Loss: 7.771030
[13/200][5760/5963] Loss: 6.893900
[13/200][5880/5963] Loss: 7.540126
[14/200][120/5963] Loss: 6.331193
[14/200][240/5963] Loss: 7.370680
[14/200][360/5963] Loss: 7.947639
[14/200][480/5963] Loss: 6.492991
[14/200][600/5963] Loss: 6.752549
[14/200][720/5963] Loss: 5.303529
[14/200][840/5963] Loss: 5.917771
[14/200][960/5963] Loss: 5.964601
[14/200][1080/5963] Loss: 6.000809
[14/200][1200/5963] Loss: 4.839561
[14/200][1320/5963] Loss: 4.721673
[14/200][1440/5963] Loss: 7.986615
[14/200][1560/5963] Loss: 7.154840
[14/200][1680/5963] Loss: 7.464100
[14/200][1800/5963] Loss: 6.255541
[14/200][1920/5963] Loss: 5.933654
[14/200][2040/5963] Loss: 5.788955
[14/200][2160/5963] Loss: 5.837335
[14/200][2280/5963] Loss: 6.076114
[14/200][2400/5963] Loss: 4.381602
[14/200][2520/5963] Loss: 6.805109
[14/200][2640/5963] Loss: 6.561292
[14/200][2760/5963] Loss: 5.963937
[14/200][2880/5963] Loss: 5.269526
[14/200][3000/5963] Loss: 6.372409
[14/200][3120/5963] Loss: 5.970641
[14/200][3240/5963] Loss: 6.861867
[14/200][3360/5963] Loss: 8.577184
[14/200][3480/5963] Loss: 5.339049
[14/200][3600/5963] Loss: 4.328168
[14/200][3720/5963] Loss: 5.012777
[14/200][3840/5963] Loss: 6.325653
[14/200][3960/5963] Loss: 5.097919
[14/200][4080/5963] Loss: 5.929307
[14/200][4200/5963] Loss: 5.552320
[14/200][4320/5963] Loss: 5.352563
[14/200][4440/5963] Loss: 6.733292
[14/200][4560/5963] Loss: 4.938847
[14/200][4680/5963] Loss: 5.738352
[14/200][4800/5963] Loss: 6.825434
[14/200][4920/5963] Loss: 6.113328
[14/200][5040/5963] Loss: 5.753403
[14/200][5160/5963] Loss: 5.085973
[14/200][5280/5963] Loss: 4.953057
[14/200][5400/5963] Loss: 6.853625
[14/200][5520/5963] Loss: 5.295905
[14/200][5640/5963] Loss: 6.994267
[14/200][5760/5963] Loss: 6.815781
[14/200][5880/5963] Loss: 5.651290
[15/200][120/5963] Loss: 5.252257
[15/200][240/5963] Loss: 5.073380
[15/200][360/5963] Loss: 7.180712
[15/200][480/5963] Loss: 7.252448
[15/200][600/5963] Loss: 6.095933
[15/200][720/5963] Loss: 6.042966
[15/200][840/5963] Loss: 5.073331
[15/200][960/5963] Loss: 5.368742
[15/200][1080/5963] Loss: 5.112992
[15/200][1200/5963] Loss: 7.042724
[15/200][1320/5963] Loss: 5.328572
[15/200][1440/5963] Loss: 5.227566
[15/200][1560/5963] Loss: 7.715269
[15/200][1680/5963] Loss: 5.242636
[15/200][1800/5963] Loss: 5.959880
[15/200][1920/5963] Loss: 5.311481
[15/200][2040/5963] Loss: 5.633817
[15/200][2160/5963] Loss: 5.424490
[15/200][2280/5963] Loss: 5.726053
[15/200][2400/5963] Loss: 5.646463
[15/200][2520/5963] Loss: 6.055348
[15/200][2640/5963] Loss: 5.485781
[15/200][2760/5963] Loss: 6.548827
[15/200][2880/5963] Loss: nan
[15/200][3000/5963] Loss: 5.263896
[15/200][3120/5963] Loss: 6.256824
[15/200][3240/5963] Loss: 6.325879
[15/200][3360/5963] Loss: 5.813244
[15/200][3480/5963] Loss: 6.408025
[15/200][3600/5963] Loss: 5.096905
[15/200][3720/5963] Loss: 6.866724
[15/200][3840/5963] Loss: 4.768088
[15/200][3960/5963] Loss: 5.342203
[15/200][4080/5963] Loss: 6.217860
[15/200][4200/5963] Loss: 4.942909
[15/200][4320/5963] Loss: 5.927193
[15/200][4440/5963] Loss: 4.968512
[15/200][4560/5963] Loss: 5.801668
[15/200][4680/5963] Loss: 6.282281
[15/200][4800/5963] Loss: 5.726264
[15/200][4920/5963] Loss: 6.093111
[15/200][5040/5963] Loss: 5.211262
[15/200][5160/5963] Loss: 5.929172
[15/200][5280/5963] Loss: 4.208076
[15/200][5400/5963] Loss: 4.944362
[15/200][5520/5963] Loss: 4.780210
[15/200][5640/5963] Loss: 5.909767
[15/200][5760/5963] Loss: 4.425846
[15/200][5880/5963] Loss: 4.408920
Start validation set
--------------------------------i---ee-----   -n------e-------e--------n-------e----------b------e----i---n---------   -D-------i-e----------------- => ie neenebein Die    , gt: Sie heten erbeite vil
-----A--------pp-------e---r---   mm----o----l---t------  -e--r---e-------  s------i-l-------  -s----i-cc-k-------e---- -M---------o----s---ee--r--- => Aper molt ere sil sicke Moser, gt: Desz er holte her sich dicke widdir
Total number of images in validation set:     2000
Test loss: 69.926816, accuracy: 0.008000
Character error rate mean: 0.4786; Character error rate sd: 0.2394
Word error rate mean: 1.0219; Word error rate sd: 0.4093
Start validation set
---------------------------------------------------b------y--  aa----n----o--t-hh---e---r-------   -----m---a---y----   t---a---k----e----   -p------l--o---c--ee----  -e---c----c---o---r---d----i---n---g------   t-oo-----  -e--e---t-hh---ee--r-------  -o---f-------   T----w----o---------------------------------------------------- => by another may take ploce eccording to eether of Two, gt: by another may take place according to either of two
--is-s-----o---ll--a----tt---i--rn----g-----  cc----h-----a---r----aa---c---t---e---r---ss-----  -a-------nn----dd--  -T-hh-----ii---n----k-----i----nn--g-------  -t-h----e----------------  -a-------s-------  d--e---i--s----t---i----n-------e----f--------  -o---b-----j--e----cc----t---s------   ii--ss------   t--hh-----e--------- => issolatirng characters and Thinking the as deistinef objects is the, gt: isolating characters and thinking them as distinct objects is the
Total number of images in validation set:     2000
Test loss: 15.287949, accuracy: 0.097500
Character error rate mean: 0.1694; Character error rate sd: 0.8634
Word error rate mean: 0.4281; Word error rate sd: 0.3802
Saving epoch experiments/expr_ICFHR_27Mar_alph_werr_fixed/netCRNN_15_5963.pth
[16/200][120/5963] Loss: 5.451734
[16/200][240/5963] Loss: 6.364339
[16/200][360/5963] Loss: 5.725577
[16/200][480/5963] Loss: 6.827819
[16/200][600/5963] Loss: 4.623299
[16/200][720/5963] Loss: 4.468455
[16/200][840/5963] Loss: 4.678143
[16/200][960/5963] Loss: 6.634070
[16/200][1080/5963] Loss: 4.501103
[16/200][1200/5963] Loss: 4.096380
[16/200][1320/5963] Loss: 7.000633
[16/200][1440/5963] Loss: 4.629736
[16/200][1560/5963] Loss: 5.532576
[16/200][1680/5963] Loss: 4.925478
[16/200][1800/5963] Loss: 5.075140
[16/200][1920/5963] Loss: 6.641460
[16/200][2040/5963] Loss: 4.392941
[16/200][2160/5963] Loss: 5.491485
[16/200][2280/5963] Loss: 5.559267
[16/200][2400/5963] Loss: 4.450800
[16/200][2520/5963] Loss: 5.299646
[16/200][2640/5963] Loss: 5.474869
[16/200][2760/5963] Loss: 5.105760
[16/200][2880/5963] Loss: 5.100950
[16/200][3000/5963] Loss: 5.684917
[16/200][3120/5963] Loss: 4.827304
[16/200][3240/5963] Loss: 6.970999
[16/200][3360/5963] Loss: 4.445856
[16/200][3480/5963] Loss: 5.821499
[16/200][3600/5963] Loss: 5.345820
[16/200][3720/5963] Loss: 4.801898
[16/200][3840/5963] Loss: 4.808258
[16/200][3960/5963] Loss: 7.007161
[16/200][4080/5963] Loss: 5.341349
[16/200][4200/5963] Loss: 5.237494
[16/200][4320/5963] Loss: 4.595897
[16/200][4440/5963] Loss: 4.745028
[16/200][4560/5963] Loss: 5.616265
[16/200][4680/5963] Loss: 3.847958
[16/200][4800/5963] Loss: 5.323130
[16/200][4920/5963] Loss: 5.332635
[16/200][5040/5963] Loss: 5.262058
[16/200][5160/5963] Loss: 4.811704
[16/200][5280/5963] Loss: 4.890441
[16/200][5400/5963] Loss: 5.576354
[16/200][5520/5963] Loss: 3.558534
[16/200][5640/5963] Loss: 4.501423
[16/200][5760/5963] Loss: 5.825152
[16/200][5880/5963] Loss: 5.467710
[17/200][120/5963] Loss: 4.805234
[17/200][240/5963] Loss: 5.025687
[17/200][360/5963] Loss: 4.923529
[17/200][480/5963] Loss: 5.321325
[17/200][600/5963] Loss: 5.435058
[17/200][720/5963] Loss: 4.649609
[17/200][840/5963] Loss: 5.525097
[17/200][960/5963] Loss: 4.519340
[17/200][1080/5963] Loss: 5.355241
[17/200][1200/5963] Loss: 4.262347
[17/200][1320/5963] Loss: 4.153178
[17/200][1440/5963] Loss: 5.490371
[17/200][1560/5963] Loss: 4.978150
[17/200][1680/5963] Loss: 5.189630
[17/200][1800/5963] Loss: 5.422207
[17/200][1920/5963] Loss: 4.514316
[17/200][2040/5963] Loss: 5.943496
[17/200][2160/5963] Loss: 3.824836
[17/200][2280/5963] Loss: 4.593599
[17/200][2400/5963] Loss: 3.797060
[17/200][2520/5963] Loss: 5.039758
[17/200][2640/5963] Loss: 4.492378
[17/200][2760/5963] Loss: 4.384195
[17/200][2880/5963] Loss: 4.218227
[17/200][3000/5963] Loss: 4.440780
[17/200][3120/5963] Loss: 7.695349
[17/200][3240/5963] Loss: 3.913674
[17/200][3360/5963] Loss: 4.532571
[17/200][3480/5963] Loss: 4.069525
[17/200][3600/5963] Loss: 3.804923
[17/200][3720/5963] Loss: 4.219724
[17/200][3840/5963] Loss: 6.007657
[17/200][3960/5963] Loss: 6.039745
[17/200][4080/5963] Loss: 4.302551
[17/200][4200/5963] Loss: 4.298301
[17/200][4320/5963] Loss: 3.560785
[17/200][4440/5963] Loss: 6.417211
[17/200][4560/5963] Loss: 4.512506
[17/200][4680/5963] Loss: 4.395643
[17/200][4800/5963] Loss: 4.439861
[17/200][4920/5963] Loss: 5.207647
[17/200][5040/5963] Loss: 5.626863
[17/200][5160/5963] Loss: 5.338910
[17/200][5280/5963] Loss: 4.205164
[17/200][5400/5963] Loss: 4.559175
[17/200][5520/5963] Loss: 4.774750
[17/200][5640/5963] Loss: 4.633754
[17/200][5760/5963] Loss: 4.381994
[17/200][5880/5963] Loss: 5.080952
[18/200][120/5963] Loss: 4.137989
[18/200][240/5963] Loss: 4.217153
[18/200][360/5963] Loss: 5.107639
[18/200][480/5963] Loss: 3.870948
[18/200][600/5963] Loss: 3.715016
[18/200][720/5963] Loss: 5.216513
[18/200][840/5963] Loss: 4.599882
[18/200][960/5963] Loss: 4.571904
[18/200][1080/5963] Loss: 5.873193
[18/200][1200/5963] Loss: 4.201545
[18/200][1320/5963] Loss: 5.349608
[18/200][1440/5963] Loss: 4.423311
[18/200][1560/5963] Loss: 4.255042
[18/200][1680/5963] Loss: 4.281639
[18/200][1800/5963] Loss: 4.130465
[18/200][1920/5963] Loss: 4.594778
[18/200][2040/5963] Loss: 3.963915
[18/200][2160/5963] Loss: 4.586129
[18/200][2280/5963] Loss: 4.443322
[18/200][2400/5963] Loss: 4.017741
[18/200][2520/5963] Loss: 4.828330
[18/200][2640/5963] Loss: 4.631505
[18/200][2760/5963] Loss: 4.454695
[18/200][2880/5963] Loss: 4.607259
[18/200][3000/5963] Loss: 5.480878
[18/200][3120/5963] Loss: 4.496321
[18/200][3240/5963] Loss: 4.616585
[18/200][3360/5963] Loss: 4.152399
[18/200][3480/5963] Loss: 3.172818
[18/200][3600/5963] Loss: 4.420615
[18/200][3720/5963] Loss: 4.000686
[18/200][3840/5963] Loss: 3.777699
[18/200][3960/5963] Loss: 5.488946
[18/200][4080/5963] Loss: 3.791680
[18/200][4200/5963] Loss: 4.441693
[18/200][4320/5963] Loss: 4.944957
[18/200][4440/5963] Loss: 4.859284
[18/200][4560/5963] Loss: 4.657863
[18/200][4680/5963] Loss: 4.454621
[18/200][4800/5963] Loss: 4.954791
[18/200][4920/5963] Loss: 4.311383
[18/200][5040/5963] Loss: 3.475806
[18/200][5160/5963] Loss: 5.454495
[18/200][5280/5963] Loss: 3.904413
[18/200][5400/5963] Loss: 4.025233
[18/200][5520/5963] Loss: 3.607731
[18/200][5640/5963] Loss: 4.087139
[18/200][5760/5963] Loss: 5.242165
[18/200][5880/5963] Loss: 4.230964
[19/200][120/5963] Loss: 4.003298
[19/200][240/5963] Loss: 4.794596
[19/200][360/5963] Loss: 3.950800
[19/200][480/5963] Loss: 5.140808
[19/200][600/5963] Loss: 3.599703
[19/200][720/5963] Loss: 6.676721
[19/200][840/5963] Loss: 4.266746
[19/200][960/5963] Loss: 3.061974
[19/200][1080/5963] Loss: 5.043897
[19/200][1200/5963] Loss: 4.913508
[19/200][1320/5963] Loss: 4.534505
[19/200][1440/5963] Loss: 4.889080
[19/200][1560/5963] Loss: 3.383200
[19/200][1680/5963] Loss: 3.688166
[19/200][1800/5963] Loss: 3.555217
[19/200][1920/5963] Loss: 3.977230
[19/200][2040/5963] Loss: 4.535953
[19/200][2160/5963] Loss: 3.465677
[19/200][2280/5963] Loss: 5.496032
[19/200][2400/5963] Loss: 4.860001
[19/200][2520/5963] Loss: 3.657912
[19/200][2640/5963] Loss: 3.637364
[19/200][2760/5963] Loss: 4.100565
[19/200][2880/5963] Loss: 4.283294
[19/200][3000/5963] Loss: 4.261910
[19/200][3120/5963] Loss: 4.466864
[19/200][3240/5963] Loss: 4.806345
[19/200][3360/5963] Loss: 4.147293
[19/200][3480/5963] Loss: 3.560320
[19/200][3600/5963] Loss: 3.334646
[19/200][3720/5963] Loss: 3.476589
[19/200][3840/5963] Loss: 3.711935
[19/200][3960/5963] Loss: 4.057198
[19/200][4080/5963] Loss: 3.573408
[19/200][4200/5963] Loss: 4.939678
[19/200][4320/5963] Loss: 5.091471
[19/200][4440/5963] Loss: 4.061167
[19/200][4560/5963] Loss: 3.751334
[19/200][4680/5963] Loss: 4.801232
[19/200][4800/5963] Loss: 3.764361
[19/200][4920/5963] Loss: 3.918966
[19/200][5040/5963] Loss: 3.242309
[19/200][5160/5963] Loss: 3.566495
[19/200][5280/5963] Loss: 4.249686
[19/200][5400/5963] Loss: 3.481448
[19/200][5520/5963] Loss: 4.009022
[19/200][5640/5963] Loss: 4.087337
[19/200][5760/5963] Loss: 2.965778
[19/200][5880/5963] Loss: 3.986627
Running with options: Namespace(adadelta=False, adam=False, alphabet='0123456789abcdefghijklmnopqrstuvwxyz', batchSize=2, beta1=0.5, crnn='/deep_data/nephi/experiments/expr_ICFHR_27Mar_alph_werr_fixed/netCRNN_15_5963.pth', cuda=True, displayInterval=120, experiment='experiments/expr_ICFHR_27Mar_alph_werr_fixed_extended', imgH=80, imgW=240, keep_ratio=True, lr=1e-05, n_test_disp=10, ngpu=1, nh=256, niter=200, random_sample=False, saveEpoch=5, test_file='test_file', test_icfhr=False, trainroot='/deep_data/nephi/data/lmdb_ICFHR/general_data', valEpoch=5, valroot='/deep_data/nephi/data/lmdb_ICFHR/specific_data', workers=10)
Random Seed:  6777
This is the alphabet:
eniratsdholcugmv.wbf,zkpySDA-MEjGBIHVßCWP1N¬TJFKRO"ʒLæx2:’q08ZU;–3'4·ø7!5?6)9(—/=┌YQ&X«»[│]§°ειν”τ|ασ 
loading pretrained model from /deep_data/nephi/experiments/expr_ICFHR_27Mar_alph_werr_fixed/netCRNN_15_5963.pth
Your neural network: DataParallel(
  (module): CRNN(
    (cnn): Sequential(
      (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu0): ReLU(inplace)
      (pooling0): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu1): ReLU(inplace)
      (pooling1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
      (relu2): ReLU(inplace)
      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu3): ReLU(inplace)
      (pooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=(1, 1), ceil_mode=False)
      (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
      (relu4): ReLU(inplace)
      (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu5): ReLU(inplace)
      (pooling3): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=(1, 1), ceil_mode=False)
      (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))
      (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
      (relu6): ReLU(inplace)
    )
    (rnn): Sequential(
      (0): BidirectionalLSTM(
        (rnn): LSTM(512, 256, bidirectional=True)
        (embedding): Linear(in_features=512, out_features=256, bias=True)
      )
      (1): BidirectionalLSTM(
        (rnn): LSTM(256, 256, bidirectional=True)
        (embedding): Linear(in_features=512, out_features=103, bias=True)
      )
    )
  )
)
Starting training...
[0/200][120/5963] Loss: 6.288912
[0/200][240/5963] Loss: 4.716542
[0/200][360/5963] Loss: 3.931383
[0/200][480/5963] Loss: 3.785368
[0/200][600/5963] Loss: 4.348444
[0/200][720/5963] Loss: 3.693274
[0/200][840/5963] Loss: 4.162919
[0/200][960/5963] Loss: 3.526063
[0/200][1080/5963] Loss: 3.526928
[0/200][1200/5963] Loss: 3.597564
[0/200][1320/5963] Loss: 3.790769
[0/200][1440/5963] Loss: 3.781869
[0/200][1560/5963] Loss: 2.795592
[0/200][1680/5963] Loss: 2.762963
[0/200][1800/5963] Loss: 4.620184
[0/200][1920/5963] Loss: 3.818098
[0/200][2040/5963] Loss: 2.888801
[0/200][2160/5963] Loss: 3.517865
[0/200][2280/5963] Loss: 4.720600
[0/200][2400/5963] Loss: 3.904429
[0/200][2520/5963] Loss: 3.359669
[0/200][2640/5963] Loss: 2.696006
[0/200][2760/5963] Loss: 3.030100
[0/200][2880/5963] Loss: 3.495545
[0/200][3000/5963] Loss: 3.360866
[0/200][3120/5963] Loss: 2.496642
[0/200][3240/5963] Loss: 2.684636
[0/200][3360/5963] Loss: 3.082059
[0/200][3480/5963] Loss: 2.922963
[0/200][3600/5963] Loss: 2.163256
[0/200][3720/5963] Loss: 3.015141
[0/200][3840/5963] Loss: 2.832255
[0/200][3960/5963] Loss: 2.507692
[0/200][4080/5963] Loss: 2.488653
[0/200][4200/5963] Loss: 2.913710
[0/200][4320/5963] Loss: 1.850554
[0/200][4440/5963] Loss: 2.302736
[0/200][4560/5963] Loss: 2.499829
[0/200][4680/5963] Loss: 3.082868
[0/200][4800/5963] Loss: 2.801757
[0/200][4920/5963] Loss: 2.617929
[0/200][5040/5963] Loss: 3.723538
[0/200][5160/5963] Loss: 2.465773
[0/200][5280/5963] Loss: 3.428461
[0/200][5400/5963] Loss: 3.255483
[0/200][5520/5963] Loss: 3.054773
[0/200][5640/5963] Loss: 2.940928
[0/200][5760/5963] Loss: 3.665732
[0/200][5880/5963] Loss: 2.405912
Start validation set
--------e---------------A--t-----------------e------v------u--------a----i----d-d----ie--r------  -a------u---dd------ii-r--g--  -s------a------n----t---- => eAtevuaiddier audirg sant, gt: Je czwey eyn andir andir hant
---------------------------S-------u--e--- -ff----e---- lb--ee----  v-----e---nd---- -----i--s----i--nn---g----e----   E----o---t------------------------- => Sue fe lbe vend isinge Eot, gt: Sie furte vnd manige kyl
Total number of images in validation set:     2000
Test loss: 68.450932, accuracy: 0.005500
Character error rate mean: 0.4813; Character error rate sd: 0.2876
Word error rate mean: 1.0028; Word error rate sd: 0.4390
Start validation set
------------I---------n-------i-ss----b-------rr---oo-----tt---.---- => Inisbrot.           , gt: Anisbrot.           
---3------5---- -d-----k-------g--------  -M-----------e--hh---l---- => 35 dkg Mehl         , gt: 35 dkg Mehl         
Total number of images in validation set:     2000
Test loss: 10.986742, accuracy: 0.265500
Character error rate mean: 0.1085; Character error rate sd: 0.4373
Word error rate mean: 0.3047; Word error rate sd: 0.3741
Saving epoch experiments/expr_ICFHR_27Mar_alph_werr_fixed_extended/netCRNN_0_5963.pth
[1/200][120/5963] Loss: 2.845624
[1/200][240/5963] Loss: 3.182119
[1/200][360/5963] Loss: 2.911725
[1/200][480/5963] Loss: 3.780943
[1/200][600/5963] Loss: 2.199788
[1/200][720/5963] Loss: 3.192745
[1/200][840/5963] Loss: 3.404951
[1/200][960/5963] Loss: 3.130896
[1/200][1080/5963] Loss: 4.610823
[1/200][1200/5963] Loss: 2.694754
[1/200][1320/5963] Loss: 2.439996
[1/200][1440/5963] Loss: 2.847326
[1/200][1560/5963] Loss: 2.856442
[1/200][1680/5963] Loss: 2.901619
[1/200][1800/5963] Loss: 2.716388
[1/200][1920/5963] Loss: 2.974008
[1/200][2040/5963] Loss: 1.766607
[1/200][2160/5963] Loss: 3.065898
[1/200][2280/5963] Loss: 2.362462
[1/200][2400/5963] Loss: 3.589711
[1/200][2520/5963] Loss: 2.177742
[1/200][2640/5963] Loss: 3.344041
[1/200][2760/5963] Loss: 2.631508
[1/200][2880/5963] Loss: 3.585387
[1/200][3000/5963] Loss: 2.926806
[1/200][3120/5963] Loss: 1.424709
[1/200][3240/5963] Loss: 2.957715
[1/200][3360/5963] Loss: 2.411311
[1/200][3480/5963] Loss: 2.728453
[1/200][3600/5963] Loss: 3.254703
[1/200][3720/5963] Loss: 1.661740
[1/200][3840/5963] Loss: 2.109848
[1/200][3960/5963] Loss: 3.738024
[1/200][4080/5963] Loss: 2.960591
[1/200][4200/5963] Loss: 3.055067
[1/200][4320/5963] Loss: 2.652299
[1/200][4440/5963] Loss: 2.624667
[1/200][4560/5963] Loss: 2.872190
[1/200][4680/5963] Loss: 2.254526
[1/200][4800/5963] Loss: 3.375022
[1/200][4920/5963] Loss: 2.212984
[1/200][5040/5963] Loss: 2.467473
[1/200][5160/5963] Loss: 2.862691
[1/200][5280/5963] Loss: 1.454933
[1/200][5400/5963] Loss: 2.001808
[1/200][5520/5963] Loss: 1.739074
[1/200][5640/5963] Loss: 2.084475
[1/200][5760/5963] Loss: 2.004515
[1/200][5880/5963] Loss: 2.121131
[2/200][120/5963] Loss: 2.259099
[2/200][240/5963] Loss: 1.880673
[2/200][360/5963] Loss: 3.103108
[2/200][480/5963] Loss: 2.310788
[2/200][600/5963] Loss: 1.896276
[2/200][720/5963] Loss: 2.435626
[2/200][840/5963] Loss: 2.931323
[2/200][960/5963] Loss: 1.566609
[2/200][1080/5963] Loss: 2.530405
[2/200][1200/5963] Loss: 2.519919
[2/200][1320/5963] Loss: 1.926815
[2/200][1440/5963] Loss: 2.377830
[2/200][1560/5963] Loss: 1.782264
[2/200][1680/5963] Loss: 1.670802
[2/200][1800/5963] Loss: 2.192115
[2/200][1920/5963] Loss: 2.303288
[2/200][2040/5963] Loss: 1.846759
[2/200][2160/5963] Loss: 2.046998
[2/200][2280/5963] Loss: 1.907090
[2/200][2400/5963] Loss: 2.704908
[2/200][2520/5963] Loss: 2.004546
[2/200][2640/5963] Loss: 1.628647
[2/200][2760/5963] Loss: 2.522636
[2/200][2880/5963] Loss: 2.087479
[2/200][3000/5963] Loss: 2.276763
[2/200][3120/5963] Loss: 2.066826
[2/200][3240/5963] Loss: 1.956898
[2/200][3360/5963] Loss: 2.151968
[2/200][3480/5963] Loss: 2.202774
[2/200][3600/5963] Loss: 2.099651
[2/200][3720/5963] Loss: 1.708455
[2/200][3840/5963] Loss: 1.852366
[2/200][3960/5963] Loss: 1.825144
[2/200][4080/5963] Loss: 1.293600
[2/200][4200/5963] Loss: 2.554080
[2/200][4320/5963] Loss: 2.410569
[2/200][4440/5963] Loss: 3.016487
[2/200][4560/5963] Loss: 2.654026
[2/200][4680/5963] Loss: 2.097528
[2/200][4800/5963] Loss: 2.037913
[2/200][4920/5963] Loss: 1.568633
[2/200][5040/5963] Loss: 2.004345
[2/200][5160/5963] Loss: 3.091746
[2/200][5280/5963] Loss: 1.855082
[2/200][5400/5963] Loss: 1.948825
[2/200][5520/5963] Loss: 1.948822
[2/200][5640/5963] Loss: 2.091648
[2/200][5760/5963] Loss: 2.088235
[2/200][5880/5963] Loss: 1.491514
[3/200][120/5963] Loss: 1.915300
[3/200][240/5963] Loss: 1.998763
[3/200][360/5963] Loss: 1.350294
[3/200][480/5963] Loss: 1.759679
[3/200][600/5963] Loss: 2.010442
[3/200][720/5963] Loss: 1.646728
[3/200][840/5963] Loss: 1.843000
[3/200][960/5963] Loss: 2.313795
[3/200][1080/5963] Loss: 1.714280
[3/200][1200/5963] Loss: 1.537735
[3/200][1320/5963] Loss: 1.941970
[3/200][1440/5963] Loss: 1.448984
[3/200][1560/5963] Loss: 2.147249
[3/200][1680/5963] Loss: 2.892148
[3/200][1800/5963] Loss: 1.251540
[3/200][1920/5963] Loss: 1.562236
[3/200][2040/5963] Loss: 3.114018
[3/200][2160/5963] Loss: 1.431447
[3/200][2280/5963] Loss: 1.632096
[3/200][2400/5963] Loss: 2.984543
[3/200][2520/5963] Loss: 2.313454
[3/200][2640/5963] Loss: 1.113178
[3/200][2760/5963] Loss: 1.500869
[3/200][2880/5963] Loss: 1.411533
[3/200][3000/5963] Loss: 2.446566
[3/200][3120/5963] Loss: 1.909674
[3/200][3240/5963] Loss: 1.646494
[3/200][3360/5963] Loss: 1.608977
[3/200][3480/5963] Loss: 1.993259
[3/200][3600/5963] Loss: 1.351414
[3/200][3720/5963] Loss: 1.689499
[3/200][3840/5963] Loss: 1.134127
[3/200][3960/5963] Loss: 1.731055
[3/200][4080/5963] Loss: 1.809919
[3/200][4200/5963] Loss: 1.748618
[3/200][4320/5963] Loss: 1.717287
[3/200][4440/5963] Loss: 1.296876
[3/200][4560/5963] Loss: 1.157983
[3/200][4680/5963] Loss: 1.816268
[3/200][4800/5963] Loss: 2.647691
[3/200][4920/5963] Loss: 1.813768
[3/200][5040/5963] Loss: 1.746903
[3/200][5160/5963] Loss: 1.645129
[3/200][5280/5963] Loss: 1.463645
[3/200][5400/5963] Loss: 1.372439
[3/200][5520/5963] Loss: 1.414724
[3/200][5640/5963] Loss: 2.816210
[3/200][5760/5963] Loss: 1.614634
[3/200][5880/5963] Loss: 2.171925
[4/200][120/5963] Loss: 1.534816
[4/200][240/5963] Loss: 2.033137
[4/200][360/5963] Loss: 1.691198
[4/200][480/5963] Loss: 1.114080
[4/200][600/5963] Loss: 2.070597
[4/200][720/5963] Loss: 1.524233
[4/200][840/5963] Loss: 1.898854
[4/200][960/5963] Loss: 2.074325
[4/200][1080/5963] Loss: 2.235899
[4/200][1200/5963] Loss: 1.932764
[4/200][1320/5963] Loss: 1.322936
[4/200][1440/5963] Loss: 1.648097
[4/200][1560/5963] Loss: 2.062220
[4/200][1680/5963] Loss: 1.391674
[4/200][1800/5963] Loss: 2.553130
[4/200][1920/5963] Loss: 2.367415
[4/200][2040/5963] Loss: 0.986576
[4/200][2160/5963] Loss: 2.362078
[4/200][2280/5963] Loss: 3.116053
[4/200][2400/5963] Loss: 1.830317
[4/200][2520/5963] Loss: 1.694556
[4/200][2640/5963] Loss: 1.561746
[4/200][2760/5963] Loss: 1.701805
[4/200][2880/5963] Loss: 1.948335
[4/200][3000/5963] Loss: 1.120529
[4/200][3120/5963] Loss: 1.297475
[4/200][3240/5963] Loss: 1.185391
[4/200][3360/5963] Loss: 2.509513
[4/200][3480/5963] Loss: 1.919093
[4/200][3600/5963] Loss: 1.323488
[4/200][3720/5963] Loss: 1.821729
[4/200][3840/5963] Loss: 1.351610
[4/200][3960/5963] Loss: 1.084301
[4/200][4080/5963] Loss: 0.978439
[4/200][4200/5963] Loss: 1.668334
[4/200][4320/5963] Loss: 1.082205
[4/200][4440/5963] Loss: 1.300260
[4/200][4560/5963] Loss: 1.477088
[4/200][4680/5963] Loss: 1.268584
[4/200][4800/5963] Loss: 1.119325
[4/200][4920/5963] Loss: 2.053391
[4/200][5040/5963] Loss: 1.054836
[4/200][5160/5963] Loss: 1.660644
[4/200][5280/5963] Loss: 1.309935
[4/200][5400/5963] Loss: 1.173913
[4/200][5520/5963] Loss: 1.634901
[4/200][5640/5963] Loss: 1.739273
[4/200][5760/5963] Loss: 2.118554
[4/200][5880/5963] Loss: 1.234174
[5/200][120/5963] Loss: 1.787854
[5/200][240/5963] Loss: 1.407414
[5/200][360/5963] Loss: 1.226085
[5/200][480/5963] Loss: 1.751395
[5/200][600/5963] Loss: 2.212792
[5/200][720/5963] Loss: 1.521329
[5/200][840/5963] Loss: 1.286180
[5/200][960/5963] Loss: 0.890198
[5/200][1080/5963] Loss: 1.941823
[5/200][1200/5963] Loss: 1.258594
[5/200][1320/5963] Loss: 1.207609
[5/200][1440/5963] Loss: 1.045255
[5/200][1560/5963] Loss: 1.382430
[5/200][1680/5963] Loss: 1.357251
[5/200][1800/5963] Loss: 2.166788
[5/200][1920/5963] Loss: 2.225489
[5/200][2040/5963] Loss: 1.722156
[5/200][2160/5963] Loss: 1.230071
[5/200][2280/5963] Loss: 1.682554
[5/200][2400/5963] Loss: 1.630781
[5/200][2520/5963] Loss: 1.280615
[5/200][2640/5963] Loss: 1.745720
[5/200][2760/5963] Loss: 0.843219
[5/200][2880/5963] Loss: 1.919198
[5/200][3000/5963] Loss: 1.181769
[5/200][3120/5963] Loss: 1.519348
[5/200][3240/5963] Loss: 1.269654
[5/200][3360/5963] Loss: 1.257939
[5/200][3480/5963] Loss: 1.346108
[5/200][3600/5963] Loss: 1.346588
[5/200][3720/5963] Loss: 1.291462
[5/200][3840/5963] Loss: 1.193205
[5/200][3960/5963] Loss: 0.899302
[5/200][4080/5963] Loss: 1.378482
[5/200][4200/5963] Loss: 2.627566
[5/200][4320/5963] Loss: 1.506646
[5/200][4440/5963] Loss: 2.255380
[5/200][4560/5963] Loss: 1.387445
[5/200][4680/5963] Loss: 1.514817
[5/200][4800/5963] Loss: 1.856894
[5/200][4920/5963] Loss: 1.575632
[5/200][5040/5963] Loss: 1.577441
[5/200][5160/5963] Loss: 1.891818
[5/200][5280/5963] Loss: 0.934932
[5/200][5400/5963] Loss: 0.714099
[5/200][5520/5963] Loss: 1.140187
[5/200][5640/5963] Loss: 1.083350
[5/200][5760/5963] Loss: 0.957668
[5/200][5880/5963] Loss: 1.392400
Start validation set
------------------------------------D----------------o--  s---p---r---e--ccch----  d------r--   C---oo----mm--ss----  -S----o- yy- s--ac-t------------------------------------ => Do sprech dr Coms So y sact, gt: Do sprach der konig kaylet
---s-------------i----x------ -------mm------a-------n----t----e------  -o--------u------  -B------ii----e----   -o----------mm--------r------  -g-------o----t----ii--e---d-- => six mante ou Bie omr gotied, gt: Sie mante on bie orin gotin
Total number of images in validation set:     2000
Test loss: 79.017733, accuracy: 0.005000
Character error rate mean: 0.4744; Character error rate sd: 0.2271
Word error rate mean: 0.9802; Word error rate sd: 0.3767
Start validation set
---------------------------d------a---gg----e----g-----e-----n------   d----ii-e------------   S---t---oo--f---ff---ee-----  -uu----n--dd--------  --n-----a-----m------e------n----t----l--iiiccchh-------  d-----i-e------------------- => dagegen die Stoffe und namentlich die, gt: dagegen die Stoffe und namentlich die 
--------d-----e------n------   e----r----s-----t----ee-----n--------  Z-----------ww----e---cc--kk---------  z-------uuu---------  v-----e----r-----f------e----h-----ll----ee-----nn----,---   --n-----m-----mmm--ll--iiccchh----------- => den ersten Zweck zu verfehlen, nmmlich, gt: den ersten Zweck zu verfehlen, namlich 
Total number of images in validation set:     2000
Test loss: 9.817730, accuracy: 0.290000
Character error rate mean: 0.0876; Character error rate sd: 0.1599
Word error rate mean: 0.2596; Word error rate sd: 0.3068
Saving epoch experiments/expr_ICFHR_27Mar_alph_werr_fixed_extended/netCRNN_5_5963.pth
[6/200][120/5963] Loss: 1.183276
[6/200][240/5963] Loss: 1.578107
[6/200][360/5963] Loss: 1.653833
[6/200][480/5963] Loss: 0.871397
[6/200][600/5963] Loss: 0.927130
[6/200][720/5963] Loss: 0.972175
[6/200][840/5963] Loss: 1.030104
[6/200][960/5963] Loss: 0.828018
[6/200][1080/5963] Loss: 1.208528
[6/200][1200/5963] Loss: 1.148956
[6/200][1320/5963] Loss: 1.466005
[6/200][1440/5963] Loss: 0.925028
[6/200][1560/5963] Loss: 1.810127
[6/200][1680/5963] Loss: 0.863177
[6/200][1800/5963] Loss: 0.873497
[6/200][1920/5963] Loss: 0.836564
[6/200][2040/5963] Loss: 0.814818
[6/200][2160/5963] Loss: 1.396953
[6/200][2280/5963] Loss: 0.909442
[6/200][2400/5963] Loss: 0.739895
[6/200][2520/5963] Loss: 1.040991
[6/200][2640/5963] Loss: 0.524009
[6/200][2760/5963] Loss: 1.834303
[6/200][2880/5963] Loss: 1.782321
[6/200][3000/5963] Loss: 1.276603
[6/200][3120/5963] Loss: 1.615420
[6/200][3240/5963] Loss: 0.917520
[6/200][3360/5963] Loss: 1.398076
[6/200][3480/5963] Loss: 1.196225
[6/200][3600/5963] Loss: 1.023493
[6/200][3720/5963] Loss: 1.295387
[6/200][3840/5963] Loss: 1.146881
[6/200][3960/5963] Loss: 1.491011
[6/200][4080/5963] Loss: 1.532432
[6/200][4200/5963] Loss: 2.233630
[6/200][4320/5963] Loss: 1.266338
[6/200][4440/5963] Loss: 0.618681
[6/200][4560/5963] Loss: 1.685355
[6/200][4680/5963] Loss: 1.066193
[6/200][4800/5963] Loss: 1.617530
[6/200][4920/5963] Loss: 0.756540
[6/200][5040/5963] Loss: 0.892249
[6/200][5160/5963] Loss: 1.353493
[6/200][5280/5963] Loss: 1.074553
[6/200][5400/5963] Loss: 0.830862
[6/200][5520/5963] Loss: 1.208504
[6/200][5640/5963] Loss: 1.171404
[6/200][5760/5963] Loss: 1.186167
[6/200][5880/5963] Loss: 1.268471
[7/200][120/5963] Loss: 0.959287
[7/200][240/5963] Loss: 1.532507
[7/200][360/5963] Loss: 1.079863
[7/200][480/5963] Loss: 1.063011
[7/200][600/5963] Loss: 1.169465
[7/200][720/5963] Loss: 0.977262
[7/200][840/5963] Loss: 1.370104
[7/200][960/5963] Loss: 1.056922
[7/200][1080/5963] Loss: 1.069235
[7/200][1200/5963] Loss: 1.193754
[7/200][1320/5963] Loss: 1.407388
[7/200][1440/5963] Loss: 0.955246
[7/200][1560/5963] Loss: 0.718642
[7/200][1680/5963] Loss: 1.187509
[7/200][1800/5963] Loss: 1.005198
[7/200][1920/5963] Loss: 1.188408
[7/200][2040/5963] Loss: 1.056557
[7/200][2160/5963] Loss: 1.034373
[7/200][2280/5963] Loss: 0.805864
[7/200][2400/5963] Loss: 1.010381
[7/200][2520/5963] Loss: 1.139324
[7/200][2640/5963] Loss: 0.930434
[7/200][2760/5963] Loss: 2.081030
[7/200][2880/5963] Loss: 1.171199
[7/200][3000/5963] Loss: 0.932568
[7/200][3120/5963] Loss: 0.766695
[7/200][3240/5963] Loss: 2.148201
[7/200][3360/5963] Loss: 0.862903
[7/200][3480/5963] Loss: 1.545958
[7/200][3600/5963] Loss: 0.922150
[7/200][3720/5963] Loss: 0.993885
[7/200][3840/5963] Loss: 0.885259
[7/200][3960/5963] Loss: 0.803509
[7/200][4080/5963] Loss: 2.162685
[7/200][4200/5963] Loss: 0.858990
[7/200][4320/5963] Loss: 0.908335
[7/200][4440/5963] Loss: 0.935327
[7/200][4560/5963] Loss: 1.152444
[7/200][4680/5963] Loss: 1.312959
[7/200][4800/5963] Loss: 0.684311
[7/200][4920/5963] Loss: 1.058759
[7/200][5040/5963] Loss: 0.944307
[7/200][5160/5963] Loss: 1.212789
[7/200][5280/5963] Loss: 0.825713
[7/200][5400/5963] Loss: 0.872082
[7/200][5520/5963] Loss: 0.685873
[7/200][5640/5963] Loss: 1.108338
[7/200][5760/5963] Loss: 1.280788
[7/200][5880/5963] Loss: 0.718887
[8/200][120/5963] Loss: 1.153400
[8/200][240/5963] Loss: 0.685942
[8/200][360/5963] Loss: 0.715424
[8/200][480/5963] Loss: 1.615680
[8/200][600/5963] Loss: 1.252166
[8/200][720/5963] Loss: 0.814828
[8/200][840/5963] Loss: 0.747573
[8/200][960/5963] Loss: 2.241762
[8/200][1080/5963] Loss: 0.811274
[8/200][1200/5963] Loss: 0.759797
[8/200][1320/5963] Loss: 1.308831
[8/200][1440/5963] Loss: 0.740994
[8/200][1560/5963] Loss: 0.903654
[8/200][1680/5963] Loss: 1.314850
[8/200][1800/5963] Loss: 1.034556
[8/200][1920/5963] Loss: 1.284508
[8/200][2040/5963] Loss: 0.742102
[8/200][2160/5963] Loss: 1.050418
[8/200][2280/5963] Loss: 0.787037
[8/200][2400/5963] Loss: 1.038143
[8/200][2520/5963] Loss: 1.586625
[8/200][2640/5963] Loss: 0.831080
[8/200][2760/5963] Loss: 0.971202
[8/200][2880/5963] Loss: 0.760586
[8/200][3000/5963] Loss: 0.803810
[8/200][3120/5963] Loss: 1.279189
[8/200][3240/5963] Loss: 1.045093
[8/200][3360/5963] Loss: 0.682642
[8/200][3480/5963] Loss: 1.205934
[8/200][3600/5963] Loss: 1.159426
[8/200][3720/5963] Loss: 1.314491
[8/200][3840/5963] Loss: 1.071280
[8/200][3960/5963] Loss: 0.709798
[8/200][4080/5963] Loss: 0.570715
[8/200][4200/5963] Loss: 0.717983
[8/200][4320/5963] Loss: 0.970184
[8/200][4440/5963] Loss: 0.759315
[8/200][4560/5963] Loss: 1.079241
[8/200][4680/5963] Loss: 0.802461
[8/200][4800/5963] Loss: 1.198052
[8/200][4920/5963] Loss: 0.714844
[8/200][5040/5963] Loss: 1.095860
[8/200][5160/5963] Loss: 0.738334
[8/200][5280/5963] Loss: 0.668354
[8/200][5400/5963] Loss: 0.799357
[8/200][5520/5963] Loss: 0.763880
[8/200][5640/5963] Loss: 0.891805
[8/200][5760/5963] Loss: 1.240422
[8/200][5880/5963] Loss: 0.852551
[9/200][120/5963] Loss: 0.727117
[9/200][240/5963] Loss: 0.725295
[9/200][360/5963] Loss: 1.126837
[9/200][480/5963] Loss: 0.914645
[9/200][600/5963] Loss: 1.530791
[9/200][720/5963] Loss: 0.768444
[9/200][840/5963] Loss: 0.634091
[9/200][960/5963] Loss: 1.484075
[9/200][1080/5963] Loss: 0.613899
[9/200][1200/5963] Loss: 1.040579
[9/200][1320/5963] Loss: 0.613948
[9/200][1440/5963] Loss: 0.721126
[9/200][1560/5963] Loss: 1.383044
[9/200][1680/5963] Loss: 0.524649
[9/200][1800/5963] Loss: 0.698255
[9/200][1920/5963] Loss: 0.883382
[9/200][2040/5963] Loss: 0.585073
[9/200][2160/5963] Loss: 0.916125
[9/200][2280/5963] Loss: 0.731111
[9/200][2400/5963] Loss: 0.724989
[9/200][2520/5963] Loss: 0.862453
[9/200][2640/5963] Loss: 0.590473
[9/200][2760/5963] Loss: 1.267548
[9/200][2880/5963] Loss: 0.838972
[9/200][3000/5963] Loss: 0.796580
[9/200][3120/5963] Loss: 0.954328
[9/200][3240/5963] Loss: 1.200245
[9/200][3360/5963] Loss: 0.768381
[9/200][3480/5963] Loss: 0.588472
[9/200][3600/5963] Loss: 0.931188
[9/200][3720/5963] Loss: 1.519920
[9/200][3840/5963] Loss: 0.696627
[9/200][3960/5963] Loss: 1.060490
[9/200][4080/5963] Loss: 0.667572
[9/200][4200/5963] Loss: 0.796252
[9/200][4320/5963] Loss: 0.660584
[9/200][4440/5963] Loss: 0.625274
[9/200][4560/5963] Loss: 0.639668
[9/200][4680/5963] Loss: 0.829128
[9/200][4800/5963] Loss: 0.662190
[9/200][4920/5963] Loss: 0.574540
[9/200][5040/5963] Loss: 0.444610
[9/200][5160/5963] Loss: 0.585256
[9/200][5280/5963] Loss: 0.631608
[9/200][5400/5963] Loss: 0.884478
[9/200][5520/5963] Loss: 0.946979
[9/200][5640/5963] Loss: 0.671169
[9/200][5760/5963] Loss: 0.801671
[9/200][5880/5963] Loss: 0.621815
[10/200][120/5963] Loss: 0.801236
[10/200][240/5963] Loss: 0.874646
[10/200][360/5963] Loss: 1.023596
[10/200][480/5963] Loss: 0.636585
[10/200][600/5963] Loss: 1.385902
[10/200][720/5963] Loss: 1.821631
[10/200][840/5963] Loss: 0.557476
[10/200][960/5963] Loss: 1.013876
[10/200][1080/5963] Loss: 0.763231
[10/200][1200/5963] Loss: 0.959420
[10/200][1320/5963] Loss: 0.946383
[10/200][1440/5963] Loss: 0.663834
[10/200][1560/5963] Loss: 0.558243
[10/200][1680/5963] Loss: 0.906550
[10/200][1800/5963] Loss: 0.586363
[10/200][1920/5963] Loss: 0.769991
[10/200][2040/5963] Loss: 0.612199
[10/200][2160/5963] Loss: 0.617385
[10/200][2280/5963] Loss: 1.112495
[10/200][2400/5963] Loss: 0.537663
[10/200][2520/5963] Loss: 0.534519
[10/200][2640/5963] Loss: 0.680926
[10/200][2760/5963] Loss: 0.732438
[10/200][2880/5963] Loss: 0.468235
[10/200][3000/5963] Loss: 0.546447
[10/200][3120/5963] Loss: 1.248259
[10/200][3240/5963] Loss: 0.563319
[10/200][3360/5963] Loss: 0.776347
[10/200][3480/5963] Loss: 0.552819
[10/200][3600/5963] Loss: 0.635126
[10/200][3720/5963] Loss: 0.483832
[10/200][3840/5963] Loss: 0.628914
[10/200][3960/5963] Loss: 0.612487
[10/200][4080/5963] Loss: 0.583852
[10/200][4200/5963] Loss: 0.849188
[10/200][4320/5963] Loss: 0.845999
[10/200][4440/5963] Loss: 0.483593
[10/200][4560/5963] Loss: 0.741228
[10/200][4680/5963] Loss: 0.646618
[10/200][4800/5963] Loss: 0.437694
[10/200][4920/5963] Loss: 0.535782
[10/200][5040/5963] Loss: 0.725736
[10/200][5160/5963] Loss: 0.362716
[10/200][5280/5963] Loss: 0.988476
[10/200][5400/5963] Loss: 0.641074
[10/200][5520/5963] Loss: 0.770042
[10/200][5640/5963] Loss: 0.535864
[10/200][5760/5963] Loss: 0.632540
[10/200][5880/5963] Loss: 0.517900
Start validation set
--------W-----------e----b-----i---t---- --t-----    -s-------i----d------  s---o-------O----o-------w----------i----r-----  -p------ee----rr---tt---. => Webit t sid soOowir pert., gt: Gebitet h’re so wesz ir gert
---------------T------a---s---  -e---l--z---  -o------u---------mm----a-----tt---   -o---------------- -c---- -o-------s----t----s--s----------------- => Tas elz oumat o c ostss, gt: Dasz er on nicht gar vorstissze
Total number of images in validation set:     2000
Test loss: 86.318854, accuracy: 0.003500
Character error rate mean: 0.5000; Character error rate sd: 0.2799
Word error rate mean: 0.9961; Word error rate sd: 0.3916
Start validation set
----------K------o----------m----  -----m----a----k------t----ii----g-----  -o----c--hh------  -d----j---e----r-f----------,,-- => Kom maktig och djerf,, gt: Kom, maktig och djerf,
-----------------------bb------a------kk--------o-----------m------  g------r---ii----n----d----e----n---.--------------------- => bakom grinden.      , gt: bakom grinden.      
Total number of images in validation set:     2000
Test loss: 10.505733, accuracy: 0.309500
Character error rate mean: 0.0967; Character error rate sd: 0.4260
Word error rate mean: 0.2675; Word error rate sd: 0.3414
Saving epoch experiments/expr_ICFHR_27Mar_alph_werr_fixed_extended/netCRNN_10_5963.pth
[11/200][120/5963] Loss: 0.608195
[11/200][240/5963] Loss: 0.395099
[11/200][360/5963] Loss: 0.571933
[11/200][480/5963] Loss: 0.691482
[11/200][600/5963] Loss: 1.187451
[11/200][720/5963] Loss: 0.853156
[11/200][840/5963] Loss: 0.572806
[11/200][960/5963] Loss: 0.682632
[11/200][1080/5963] Loss: 0.897828
[11/200][1200/5963] Loss: 1.220292
[11/200][1320/5963] Loss: 0.432128
[11/200][1440/5963] Loss: 0.454485
[11/200][1560/5963] Loss: 0.468138
[11/200][1680/5963] Loss: 1.180983
[11/200][1800/5963] Loss: 0.610737
[11/200][1920/5963] Loss: 0.851905
[11/200][2040/5963] Loss: 0.859193
[11/200][2160/5963] Loss: 0.547890
[11/200][2280/5963] Loss: 0.955299
[11/200][2400/5963] Loss: 0.597289
[11/200][2520/5963] Loss: 0.630676
[11/200][2640/5963] Loss: 0.418464
[11/200][2760/5963] Loss: 0.500846
[11/200][2880/5963] Loss: 0.481395
[11/200][3000/5963] Loss: 1.180035
[11/200][3120/5963] Loss: 0.497755
[11/200][3240/5963] Loss: 0.955950
[11/200][3360/5963] Loss: 0.472210
[11/200][3480/5963] Loss: 0.705646
[11/200][3600/5963] Loss: 0.877767
[11/200][3720/5963] Loss: 0.771808
[11/200][3840/5963] Loss: 0.421000
[11/200][3960/5963] Loss: 0.762374
[11/200][4080/5963] Loss: 0.645968
[11/200][4200/5963] Loss: 0.527573
[11/200][4320/5963] Loss: 0.402481
[11/200][4440/5963] Loss: 0.938677
[11/200][4560/5963] Loss: 0.866321
[11/200][4680/5963] Loss: 0.711143
[11/200][4800/5963] Loss: 0.846716
[11/200][4920/5963] Loss: 0.543723
[11/200][5040/5963] Loss: 0.807854
[11/200][5160/5963] Loss: 0.308356
[11/200][5280/5963] Loss: 0.752206
[11/200][5400/5963] Loss: 0.604348
[11/200][5520/5963] Loss: 0.902213
[11/200][5640/5963] Loss: 0.671303
[11/200][5760/5963] Loss: 0.515809
[11/200][5880/5963] Loss: 1.010932
[12/200][120/5963] Loss: 0.561174
[12/200][240/5963] Loss: 0.746503
[12/200][360/5963] Loss: 0.471577
[12/200][480/5963] Loss: 1.108429
[12/200][600/5963] Loss: 0.439134
[12/200][720/5963] Loss: 0.913009
[12/200][840/5963] Loss: 0.530663
[12/200][960/5963] Loss: 0.871434
[12/200][1080/5963] Loss: 0.366479
[12/200][1200/5963] Loss: 0.508126
[12/200][1320/5963] Loss: 0.662566
[12/200][1440/5963] Loss: 0.692246
[12/200][1560/5963] Loss: 0.311612
[12/200][1680/5963] Loss: 0.724554
[12/200][1800/5963] Loss: 0.480141
[12/200][1920/5963] Loss: 0.887683
[12/200][2040/5963] Loss: 0.921602
[12/200][2160/5963] Loss: 0.559387
[12/200][2280/5963] Loss: 0.444443
[12/200][2400/5963] Loss: 0.452655
[12/200][2520/5963] Loss: 0.412411
[12/200][2640/5963] Loss: 0.449637
[12/200][2760/5963] Loss: 0.756928
[12/200][2880/5963] Loss: 0.619656
[12/200][3000/5963] Loss: 0.568570
[12/200][3120/5963] Loss: 0.718890
[12/200][3240/5963] Loss: 0.663041
[12/200][3360/5963] Loss: 0.438725
[12/200][3480/5963] Loss: 0.404774
[12/200][3600/5963] Loss: 0.490524
[12/200][3720/5963] Loss: 0.580389
[12/200][3840/5963] Loss: 0.369334
[12/200][3960/5963] Loss: 0.553247
[12/200][4080/5963] Loss: 0.398873
[12/200][4200/5963] Loss: 0.598717
[12/200][4320/5963] Loss: 0.688865
[12/200][4440/5963] Loss: 0.581867
[12/200][4560/5963] Loss: 0.757852
[12/200][4680/5963] Loss: 0.381166
[12/200][4800/5963] Loss: 0.445143
[12/200][4920/5963] Loss: 0.727827
[12/200][5040/5963] Loss: 0.378859
[12/200][5160/5963] Loss: 1.185945
[12/200][5280/5963] Loss: 0.896164
[12/200][5400/5963] Loss: 0.446882
[12/200][5520/5963] Loss: 0.681892
[12/200][5640/5963] Loss: 0.431665
[12/200][5760/5963] Loss: 0.473312
[12/200][5880/5963] Loss: 1.267855
[13/200][120/5963] Loss: 0.499247
[13/200][240/5963] Loss: 0.483757
[13/200][360/5963] Loss: 0.849588
[13/200][480/5963] Loss: 0.503461
[13/200][600/5963] Loss: 0.343199
[13/200][720/5963] Loss: 1.384064
[13/200][840/5963] Loss: 0.475279
[13/200][960/5963] Loss: 0.274302
[13/200][1080/5963] Loss: 0.262948
[13/200][1200/5963] Loss: 0.815735
[13/200][1320/5963] Loss: 0.379820
[13/200][1440/5963] Loss: 1.033538
[13/200][1560/5963] Loss: 0.395793
[13/200][1680/5963] Loss: 0.497708
[13/200][1800/5963] Loss: 0.941885
[13/200][1920/5963] Loss: 0.446169
[13/200][2040/5963] Loss: 0.361638
[13/200][2160/5963] Loss: 0.632287
[13/200][2280/5963] Loss: 0.484412
[13/200][2400/5963] Loss: 0.447147
[13/200][2520/5963] Loss: 0.499944
[13/200][2640/5963] Loss: 0.312519
[13/200][2760/5963] Loss: 0.509016
[13/200][2880/5963] Loss: 0.493570
[13/200][3000/5963] Loss: 0.441136
[13/200][3120/5963] Loss: 0.356732
[13/200][3240/5963] Loss: 0.412213
[13/200][3360/5963] Loss: 0.488018
[13/200][3480/5963] Loss: 0.383012
[13/200][3600/5963] Loss: 0.437488
[13/200][3720/5963] Loss: 0.502921
[13/200][3840/5963] Loss: 0.434385
[13/200][3960/5963] Loss: 0.345329
[13/200][4080/5963] Loss: 0.511291
[13/200][4200/5963] Loss: 1.394996
[13/200][4320/5963] Loss: 0.694912
[13/200][4440/5963] Loss: 0.456450
[13/200][4560/5963] Loss: 0.433330
[13/200][4680/5963] Loss: 0.894026
[13/200][4800/5963] Loss: 0.608730
[13/200][4920/5963] Loss: 0.361973
[13/200][5040/5963] Loss: 0.788459
[13/200][5160/5963] Loss: 0.292172
[13/200][5280/5963] Loss: 0.344275
[13/200][5400/5963] Loss: 0.576051
[13/200][5520/5963] Loss: 0.727009
[13/200][5640/5963] Loss: 0.489218
[13/200][5760/5963] Loss: 0.963185
[13/200][5880/5963] Loss: 0.418358
[14/200][120/5963] Loss: 0.368090
[14/200][240/5963] Loss: 0.595096
[14/200][360/5963] Loss: 0.631223
[14/200][480/5963] Loss: 0.333617
[14/200][600/5963] Loss: 0.600281
[14/200][720/5963] Loss: 1.169284
[14/200][840/5963] Loss: 0.305213
[14/200][960/5963] Loss: 0.333713
[14/200][1080/5963] Loss: 0.686230
[14/200][1200/5963] Loss: 0.286953
[14/200][1320/5963] Loss: 0.760922
[14/200][1440/5963] Loss: 0.981198
[14/200][1560/5963] Loss: 0.813206
[14/200][1680/5963] Loss: 0.572407
[14/200][1800/5963] Loss: 0.373695
[14/200][1920/5963] Loss: 0.306871
[14/200][2040/5963] Loss: 0.512589
[14/200][2160/5963] Loss: 0.479349
[14/200][2280/5963] Loss: 0.394629
[14/200][2400/5963] Loss: 0.305983
[14/200][2520/5963] Loss: 0.513760
[14/200][2640/5963] Loss: 0.509765
[14/200][2760/5963] Loss: 0.483488
[14/200][2880/5963] Loss: 0.401489
[14/200][3000/5963] Loss: 0.352417
[14/200][3120/5963] Loss: 0.554321
[14/200][3240/5963] Loss: 1.241173
[14/200][3360/5963] Loss: 0.276827
[14/200][3480/5963] Loss: 0.452609
[14/200][3600/5963] Loss: 0.365655
[14/200][3720/5963] Loss: 0.462018
[14/200][3840/5963] Loss: 0.628457
[14/200][3960/5963] Loss: 0.498654
[14/200][4080/5963] Loss: 0.609403
[14/200][4200/5963] Loss: 0.489298
[14/200][4320/5963] Loss: 0.204565
[14/200][4440/5963] Loss: 0.368248
[14/200][4560/5963] Loss: 0.244516
[14/200][4680/5963] Loss: 0.561929
[14/200][4800/5963] Loss: 0.305176
[14/200][4920/5963] Loss: 0.388145
[14/200][5040/5963] Loss: 0.443360
[14/200][5160/5963] Loss: 0.264768
[14/200][5280/5963] Loss: 0.863379
[14/200][5400/5963] Loss: 0.496809
[14/200][5520/5963] Loss: 0.319498
[14/200][5640/5963] Loss: 0.344268
[14/200][5760/5963] Loss: 0.384696
[14/200][5880/5963] Loss: 0.319244
[15/200][120/5963] Loss: 0.388084
[15/200][240/5963] Loss: 1.156977
[15/200][360/5963] Loss: 0.349517
[15/200][480/5963] Loss: 0.288327
[15/200][600/5963] Loss: 0.436262
[15/200][720/5963] Loss: 0.409005
[15/200][840/5963] Loss: 0.342115
[15/200][960/5963] Loss: 0.645306
[15/200][1080/5963] Loss: 0.700289
[15/200][1200/5963] Loss: 0.348561
[15/200][1320/5963] Loss: 0.729626
[15/200][1440/5963] Loss: 0.592151
[15/200][1560/5963] Loss: 0.473325
[15/200][1680/5963] Loss: 0.392565
[15/200][1800/5963] Loss: 0.331951
[15/200][1920/5963] Loss: 0.297860
[15/200][2040/5963] Loss: 0.627504
[15/200][2160/5963] Loss: 0.380020
[15/200][2280/5963] Loss: 0.317204
[15/200][2400/5963] Loss: 0.467243
[15/200][2520/5963] Loss: 0.306957
[15/200][2640/5963] Loss: 0.376728
[15/200][2760/5963] Loss: 0.457149
[15/200][2880/5963] Loss: 0.306159
[15/200][3000/5963] Loss: 0.433606
[15/200][3120/5963] Loss: 0.231354
[15/200][3240/5963] Loss: 0.346857
[15/200][3360/5963] Loss: 0.329100
[15/200][3480/5963] Loss: 0.598131
[15/200][3600/5963] Loss: 0.585879
[15/200][3720/5963] Loss: 0.215352
[15/200][3840/5963] Loss: 0.284554
[15/200][3960/5963] Loss: 0.228365
[15/200][4080/5963] Loss: 0.367853
[15/200][4200/5963] Loss: 0.391151
[15/200][4320/5963] Loss: 0.444344
[15/200][4440/5963] Loss: 0.683885
[15/200][4560/5963] Loss: 0.340067
[15/200][4680/5963] Loss: 0.412941
[15/200][4800/5963] Loss: 0.275008
[15/200][4920/5963] Loss: 0.296563
[15/200][5040/5963] Loss: 0.248439
[15/200][5160/5963] Loss: 0.290726
[15/200][5280/5963] Loss: 0.381719
[15/200][5400/5963] Loss: 0.990261
[15/200][5520/5963] Loss: 0.218222
[15/200][5640/5963] Loss: 0.682659
[15/200][5760/5963] Loss: 0.583812
[15/200][5880/5963] Loss: 0.322062
Start validation set
---B---------D----d------o------------------a------r---t-------- --w-----------n----dd-------e------e----  -o--------n-------b------ee----------------------m---- => BDdoart wndee onbem , gt: Alda wart vndir on beidin
----------------x------------mm------i---l--t--------  -s----------rr------   -B------i--l------i---------p--------------s-----t---t------  N-------------n-----  => xmilt sr Bilipstt Nn , gt: Desz muste her vil gepriset syn
Total number of images in validation set:     2000
Test loss: 94.773122, accuracy: 0.005000
Character error rate mean: 0.5072; Character error rate sd: 0.2824
Word error rate mean: 1.0905; Word error rate sd: 0.5642
Start validation set
---C---a------n----cc----e-l--ll--a---rr---ii--i------  -d--.--  -d--..-   S----p-------a-------  -d-----  -9--.--  A-------u-----g---s----:---  -a---:--  c---:------  b-----ee---t----rr-----e---f-f-ee------n---dd------- -d--ee-------n--- => Cancellarii d. d. Spa d 9. Augs: a: c: betreffend den, gt: Cancellarii d. d. Spa d 9. Augs: a: c: betreffend den
------------------------------------------------------d--i--e-  -g--ee---w---o---h--n--l--iicchh--e---n---   Z--ii-e--s--ee--n--  h---e---b---ee---nn--   k--o----n------n---e-----n---..----------------------------------------------------- => die gewohnlichen Ziesen heben konnen., gt: die gewohnlichen Zinsen heben konnen.
Total number of images in validation set:     2000
Test loss: 10.336298, accuracy: 0.310000
Character error rate mean: 0.0988; Character error rate sd: 0.4432
Word error rate mean: 0.2702; Word error rate sd: 0.3292
Saving epoch experiments/expr_ICFHR_27Mar_alph_werr_fixed_extended/netCRNN_15_5963.pth
[16/200][120/5963] Loss: 0.259471
[16/200][240/5963] Loss: 0.872895
[16/200][360/5963] Loss: 0.374231
[16/200][480/5963] Loss: 0.263571
[16/200][600/5963] Loss: 0.329095
[16/200][720/5963] Loss: 0.329173
[16/200][840/5963] Loss: 0.290271
[16/200][960/5963] Loss: 0.475740
[16/200][1080/5963] Loss: 0.281030
[16/200][1200/5963] Loss: 0.297684
[16/200][1320/5963] Loss: 0.338488
[16/200][1440/5963] Loss: 0.235434
[16/200][1560/5963] Loss: 0.242539
[16/200][1680/5963] Loss: 0.314576
[16/200][1800/5963] Loss: 0.263386
[16/200][1920/5963] Loss: 0.656635
[16/200][2040/5963] Loss: 0.307123
[16/200][2160/5963] Loss: 0.277920
[16/200][2280/5963] Loss: 0.294767
[16/200][2400/5963] Loss: 0.511874
[16/200][2520/5963] Loss: 0.288409
[16/200][2640/5963] Loss: 0.386063
[16/200][2760/5963] Loss: 0.267312
[16/200][2880/5963] Loss: 0.535808
[16/200][3000/5963] Loss: 0.472049
[16/200][3120/5963] Loss: 0.240864
[16/200][3240/5963] Loss: 0.228065
[16/200][3360/5963] Loss: 0.271702
[16/200][3480/5963] Loss: 0.365510
[16/200][3600/5963] Loss: 0.215134
[16/200][3720/5963] Loss: 0.181780
[16/200][3840/5963] Loss: 0.213743
[16/200][3960/5963] Loss: 0.530674
[16/200][4080/5963] Loss: 0.341794
[16/200][4200/5963] Loss: 0.268389
[16/200][4320/5963] Loss: 0.246953
[16/200][4440/5963] Loss: 0.742798
[16/200][4560/5963] Loss: 0.694448
[16/200][4680/5963] Loss: 0.319197
[16/200][4800/5963] Loss: 0.277470
[16/200][4920/5963] Loss: 0.392046
[16/200][5040/5963] Loss: 0.339215
[16/200][5160/5963] Loss: 0.668348
[16/200][5280/5963] Loss: 0.967877
[16/200][5400/5963] Loss: 0.504625
[16/200][5520/5963] Loss: 0.208261
[16/200][5640/5963] Loss: 0.163477
[16/200][5760/5963] Loss: 0.164009
[16/200][5880/5963] Loss: 0.292235
[17/200][120/5963] Loss: 0.242097
[17/200][240/5963] Loss: 0.293451
[17/200][360/5963] Loss: 0.333292
[17/200][480/5963] Loss: 0.273774
[17/200][600/5963] Loss: 0.175602
[17/200][720/5963] Loss: 0.395121
[17/200][840/5963] Loss: 0.418247
[17/200][960/5963] Loss: 0.280187
[17/200][1080/5963] Loss: 0.211887
[17/200][1200/5963] Loss: 0.263692
[17/200][1320/5963] Loss: 0.211853
[17/200][1440/5963] Loss: 0.254005
[17/200][1560/5963] Loss: 0.400742
[17/200][1680/5963] Loss: 0.298866
[17/200][1800/5963] Loss: 0.233405
[17/200][1920/5963] Loss: 0.606838
[17/200][2040/5963] Loss: 0.791245
[17/200][2160/5963] Loss: 0.238389
[17/200][2280/5963] Loss: 0.287094
[17/200][2400/5963] Loss: 0.297497
[17/200][2520/5963] Loss: 0.312578
[17/200][2640/5963] Loss: 0.285288
[17/200][2760/5963] Loss: 0.234670
[17/200][2880/5963] Loss: 0.915606
[17/200][3000/5963] Loss: 0.172969
[17/200][3120/5963] Loss: 0.336347
[17/200][3240/5963] Loss: 0.285365
[17/200][3360/5963] Loss: 0.311991
[17/200][3480/5963] Loss: 0.517223
[17/200][3600/5963] Loss: 0.557686
[17/200][3720/5963] Loss: 0.539393
[17/200][3840/5963] Loss: 0.424341
[17/200][3960/5963] Loss: 0.233535
[17/200][4080/5963] Loss: 0.376941
[17/200][4200/5963] Loss: 0.254302
[17/200][4320/5963] Loss: 0.624072
[17/200][4440/5963] Loss: 0.389911
[17/200][4560/5963] Loss: 0.366953
[17/200][4680/5963] Loss: 0.151780
[17/200][4800/5963] Loss: 0.335103
[17/200][4920/5963] Loss: 0.294607
[17/200][5040/5963] Loss: 0.456434
[17/200][5160/5963] Loss: 0.287235
[17/200][5280/5963] Loss: 0.328136
[17/200][5400/5963] Loss: 0.330440
[17/200][5520/5963] Loss: 0.317069
[17/200][5640/5963] Loss: 0.301529
[17/200][5760/5963] Loss: 0.479493
[17/200][5880/5963] Loss: 0.275100
[18/200][120/5963] Loss: 0.576558
[18/200][240/5963] Loss: 0.293035
[18/200][360/5963] Loss: 0.236784
[18/200][480/5963] Loss: 0.288136
[18/200][600/5963] Loss: 0.225259
[18/200][720/5963] Loss: 0.253040
[18/200][840/5963] Loss: 0.145951
[18/200][960/5963] Loss: 0.345617
[18/200][1080/5963] Loss: 0.312591
[18/200][1200/5963] Loss: 0.218974
[18/200][1320/5963] Loss: 0.327650
[18/200][1440/5963] Loss: 0.216882
[18/200][1560/5963] Loss: 0.582918
[18/200][1680/5963] Loss: 0.203874
[18/200][1800/5963] Loss: 0.232239
[18/200][1920/5963] Loss: 0.246781
[18/200][2040/5963] Loss: 0.406545
[18/200][2160/5963] Loss: 0.431135
[18/200][2280/5963] Loss: 0.554862
[18/200][2400/5963] Loss: 0.162520
[18/200][2520/5963] Loss: 0.606771
[18/200][2640/5963] Loss: 0.197324
[18/200][2760/5963] Loss: 0.252347
[18/200][2880/5963] Loss: 0.219464
[18/200][3000/5963] Loss: 0.470503
[18/200][3120/5963] Loss: 0.147600
[18/200][3240/5963] Loss: 0.793978
[18/200][3360/5963] Loss: 0.231080
[18/200][3480/5963] Loss: 0.165360
[18/200][3600/5963] Loss: 0.449264
[18/200][3720/5963] Loss: 0.204760
[18/200][3840/5963] Loss: 0.482529
[18/200][3960/5963] Loss: 0.272919
[18/200][4080/5963] Loss: 0.171814
[18/200][4200/5963] Loss: 0.790568
[18/200][4320/5963] Loss: 0.316014
[18/200][4440/5963] Loss: 0.138176
[18/200][4560/5963] Loss: 0.260018
[18/200][4680/5963] Loss: 0.161376
[18/200][4800/5963] Loss: 0.203999
[18/200][4920/5963] Loss: 0.569858
[18/200][5040/5963] Loss: 0.612121
[18/200][5160/5963] Loss: 0.212780
[18/200][5280/5963] Loss: 0.166470
[18/200][5400/5963] Loss: 0.344017
[18/200][5520/5963] Loss: 0.470265
[18/200][5640/5963] Loss: 0.601259
[18/200][5760/5963] Loss: 0.188992
[18/200][5880/5963] Loss: 0.284779
[19/200][120/5963] Loss: 0.252257
[19/200][240/5963] Loss: 0.282526
[19/200][360/5963] Loss: 0.259103
[19/200][480/5963] Loss: 0.171498
[19/200][600/5963] Loss: 0.264639
[19/200][720/5963] Loss: 0.238755
[19/200][840/5963] Loss: 0.116972
[19/200][960/5963] Loss: 0.128598
[19/200][1080/5963] Loss: 0.341583
[19/200][1200/5963] Loss: 0.704169
[19/200][1320/5963] Loss: 0.389625
[19/200][1440/5963] Loss: 0.298545
[19/200][1560/5963] Loss: 0.310295
[19/200][1680/5963] Loss: 0.267585
[19/200][1800/5963] Loss: 0.234465
[19/200][1920/5963] Loss: 0.285685
[19/200][2040/5963] Loss: 0.285426
[19/200][2160/5963] Loss: 0.375765
[19/200][2280/5963] Loss: 0.191252
[19/200][2400/5963] Loss: 0.271770
[19/200][2520/5963] Loss: 0.175516
[19/200][2640/5963] Loss: 0.775702
[19/200][2760/5963] Loss: 0.189047
[19/200][2880/5963] Loss: 0.373065
[19/200][3000/5963] Loss: 0.142490
[19/200][3120/5963] Loss: 0.190637
[19/200][3240/5963] Loss: 0.530044
[19/200][3360/5963] Loss: 0.134384
[19/200][3480/5963] Loss: 0.244438
[19/200][3600/5963] Loss: 0.291118
[19/200][3720/5963] Loss: 0.137669
[19/200][3840/5963] Loss: 0.124886
[19/200][3960/5963] Loss: 0.300495
[19/200][4080/5963] Loss: 0.497615
[19/200][4200/5963] Loss: 0.486010
[19/200][4320/5963] Loss: 0.436970
[19/200][4440/5963] Loss: 0.337896
[19/200][4560/5963] Loss: 0.249723
[19/200][4680/5963] Loss: 0.196822
[19/200][4800/5963] Loss: 0.391183
[19/200][4920/5963] Loss: 0.225963
[19/200][5040/5963] Loss: 0.523868
[19/200][5160/5963] Loss: 0.181643
[19/200][5280/5963] Loss: 0.174320
[19/200][5400/5963] Loss: 0.293879
[19/200][5520/5963] Loss: 0.269545
[19/200][5640/5963] Loss: 0.176421
[19/200][5760/5963] Loss: 0.518399
[19/200][5880/5963] Loss: 0.235697
[20/200][120/5963] Loss: 0.124562
[20/200][240/5963] Loss: 0.561700
[20/200][360/5963] Loss: 0.152342
[20/200][480/5963] Loss: 0.200377
[20/200][600/5963] Loss: 0.102987
[20/200][720/5963] Loss: 0.447166
[20/200][840/5963] Loss: 0.574565
[20/200][960/5963] Loss: 0.256189
[20/200][1080/5963] Loss: 0.390336
[20/200][1200/5963] Loss: 0.211262
[20/200][1320/5963] Loss: 0.173745
[20/200][1440/5963] Loss: 0.425472
[20/200][1560/5963] Loss: 0.190590
[20/200][1680/5963] Loss: 0.282179
[20/200][1800/5963] Loss: 0.216560
[20/200][1920/5963] Loss: 0.163353
[20/200][2040/5963] Loss: 0.205675
[20/200][2160/5963] Loss: 0.179298
[20/200][2280/5963] Loss: 0.700686
[20/200][2400/5963] Loss: 0.119356
[20/200][2520/5963] Loss: 0.192313
[20/200][2640/5963] Loss: 0.155687
[20/200][2760/5963] Loss: 0.240829
[20/200][2880/5963] Loss: 0.140918
[20/200][3000/5963] Loss: 0.257373
[20/200][3120/5963] Loss: 0.276547
[20/200][3240/5963] Loss: 0.624891
[20/200][3360/5963] Loss: 0.114042
[20/200][3480/5963] Loss: 0.203615
[20/200][3600/5963] Loss: 0.473735
[20/200][3720/5963] Loss: 0.484441
[20/200][3840/5963] Loss: 0.155824
[20/200][3960/5963] Loss: 0.139431
[20/200][4080/5963] Loss: 0.314199
[20/200][4200/5963] Loss: 0.232472
[20/200][4320/5963] Loss: 0.115641
[20/200][4440/5963] Loss: 0.371557
[20/200][4560/5963] Loss: 0.309436
[20/200][4680/5963] Loss: 0.121411
[20/200][4800/5963] Loss: 0.176891
[20/200][4920/5963] Loss: 0.221951
[20/200][5040/5963] Loss: 0.240883
[20/200][5160/5963] Loss: 0.195010
[20/200][5280/5963] Loss: 0.260102
[20/200][5400/5963] Loss: 0.233004
[20/200][5520/5963] Loss: 0.353406
[20/200][5640/5963] Loss: 0.622400
[20/200][5760/5963] Loss: 0.514914
[20/200][5880/5963] Loss: 0.494009
Start validation set
------------------------------------------------------------------------------------------------------VV---..- -x---i-m---o------------------------------------------------------------------------------------------------ => V. ximo             , gt: D.mo Suo            
-----------i----n---t---e--t---d-----  -d---ii--r---e-----   d---ii------  c-hh---i-----  ------ -n-------t---a--------  -s--ii------  t--n----a-----t--t---aa--h----l---e-----------   p---e---r----e--s---t----o--------- => intetd dire di chi  nta si tnattahle peresto, gt: inteso dire di chi e cosa si trattasse) presso
Total number of images in validation set:     2000
Test loss: 104.279485, accuracy: 0.004500
Character error rate mean: 0.5124; Character error rate sd: 0.2789
Word error rate mean: 1.0538; Word error rate sd: 0.4695
Start validation set
-------------------------------------------------------------------------------------------------------J--e-rii-g---ne--- -:-------  D---o---mm-ii--n--u-ss---   L-------  p---rr-a-e--p----o--s--i---tt--uu-s (   isstt jj-e--n--ee-r- v--o--n---------------------------------------------------------------------------------------------------- => Jerigne : Dominus L praepositus ( ist jener von, gt: Jerigne : Dominus L praepositus ( ist jener von
---W----all-k--  U------B-- N---..  2---5-4--  -v--  11-2---4--6- . I-I-.. S-ep--tt--.--  J---u---n--o--cc..  I--V---.---  ---m---a---n-d--a--t-- -a-b-b--a-t-ii- d-ee-  W-----a-l--k--e--n--rdd-.,,- qq--u--a-t-e-nn---uuss,  q---uaa-ee-  d--e---  b---o--n-ii-s----  -mm--i----   S--..   MM----a-rr-i--a-e-  N-----o--v--i- O--p-e-riiiss------ => Walk UB N. 254 v 1246 . II. Sept. Junoc. IV. mandat abbati de Walkenrd., quatenus, quae de bonis mi S. Mariae Novi Operis, gt: Walk UB N. 254 v 1246 . II. Sept. Junoc. IV. mandat abbati de Walkenrd., quatenus, quae de bonis mi S. Mariae Novi Operis
Total number of images in validation set:     2000
Test loss: 9.728486, accuracy: 0.350500
Character error rate mean: 0.0960; Character error rate sd: 0.7460
Word error rate mean: 0.2453; Word error rate sd: 0.3999
Saving epoch experiments/expr_ICFHR_27Mar_alph_werr_fixed_extended/netCRNN_20_5963.pth
[21/200][120/5963] Loss: 0.245568
[21/200][240/5963] Loss: 0.188287
[21/200][360/5963] Loss: 0.141814
[21/200][480/5963] Loss: 0.112371
[21/200][600/5963] Loss: 0.315839
[21/200][720/5963] Loss: 0.223408
[21/200][840/5963] Loss: 0.173113
[21/200][960/5963] Loss: 0.336047
[21/200][1080/5963] Loss: 0.300179
[21/200][1200/5963] Loss: 0.421389
[21/200][1320/5963] Loss: 0.157658
[21/200][1440/5963] Loss: 0.231166
[21/200][1560/5963] Loss: 0.181628
[21/200][1680/5963] Loss: 0.352884
[21/200][1800/5963] Loss: 0.342831
[21/200][1920/5963] Loss: 0.283761
[21/200][2040/5963] Loss: 0.239603
[21/200][2160/5963] Loss: 0.146750
[21/200][2280/5963] Loss: 0.095121
[21/200][2400/5963] Loss: 0.109274
[21/200][2520/5963] Loss: 0.327730
[21/200][2640/5963] Loss: 0.229566
[21/200][2760/5963] Loss: 0.097774
[21/200][2880/5963] Loss: 0.140579
[21/200][3000/5963] Loss: 0.344708
[21/200][3120/5963] Loss: 0.136013
[21/200][3240/5963] Loss: 0.142715
[21/200][3360/5963] Loss: 0.198576
[21/200][3480/5963] Loss: 0.538630
[21/200][3600/5963] Loss: 0.219309
[21/200][3720/5963] Loss: 0.231146
[21/200][3840/5963] Loss: 0.421047
[21/200][3960/5963] Loss: 0.313708
[21/200][4080/5963] Loss: 0.149013
[21/200][4200/5963] Loss: 0.688944
[21/200][4320/5963] Loss: 0.206735
[21/200][4440/5963] Loss: 0.303124
[21/200][4560/5963] Loss: 0.194659
[21/200][4680/5963] Loss: 0.077691
[21/200][4800/5963] Loss: 0.141526
[21/200][4920/5963] Loss: 0.126190
[21/200][5040/5963] Loss: 0.167656
[21/200][5160/5963] Loss: 0.319129
[21/200][5280/5963] Loss: 0.170498
[21/200][5400/5963] Loss: 0.125536
[21/200][5520/5963] Loss: 0.170110
[21/200][5640/5963] Loss: 0.109317
[21/200][5760/5963] Loss: 0.322292
[21/200][5880/5963] Loss: 0.235396
[22/200][120/5963] Loss: 0.194011
[22/200][240/5963] Loss: 0.163194
[22/200][360/5963] Loss: 0.156950
[22/200][480/5963] Loss: 0.098550
[22/200][600/5963] Loss: 0.110410
[22/200][720/5963] Loss: 0.156089
[22/200][840/5963] Loss: 0.395142
[22/200][960/5963] Loss: 0.167119
[22/200][1080/5963] Loss: 0.930749
[22/200][1200/5963] Loss: 0.442231
[22/200][1320/5963] Loss: 0.139472
[22/200][1440/5963] Loss: 0.076708
[22/200][1560/5963] Loss: 0.293046
[22/200][1680/5963] Loss: 0.134823
[22/200][1800/5963] Loss: 0.170494
[22/200][1920/5963] Loss: 0.334260
[22/200][2040/5963] Loss: 0.138785
[22/200][2160/5963] Loss: 0.135437
[22/200][2280/5963] Loss: 0.098620
[22/200][2400/5963] Loss: 0.179220
[22/200][2520/5963] Loss: 0.168883
[22/200][2640/5963] Loss: 0.473823
[22/200][2760/5963] Loss: 0.110860
[22/200][2880/5963] Loss: 0.320433
[22/200][3000/5963] Loss: 0.193634
[22/200][3120/5963] Loss: 0.271004
[22/200][3240/5963] Loss: 0.166291
[22/200][3360/5963] Loss: 0.197100
[22/200][3480/5963] Loss: 0.268950
[22/200][3600/5963] Loss: 0.090547
[22/200][3720/5963] Loss: 0.231980
[22/200][3840/5963] Loss: 0.164186
[22/200][3960/5963] Loss: 0.428041
[22/200][4080/5963] Loss: 0.177502
[22/200][4200/5963] Loss: 0.280802
[22/200][4320/5963] Loss: 0.138911
[22/200][4440/5963] Loss: 0.436807
[22/200][4560/5963] Loss: 0.139956
[22/200][4680/5963] Loss: 0.279878
[22/200][4800/5963] Loss: 0.486680
[22/200][4920/5963] Loss: 0.195093
[22/200][5040/5963] Loss: 0.255602
[22/200][5160/5963] Loss: 0.531143
[22/200][5280/5963] Loss: 0.146280
[22/200][5400/5963] Loss: 0.539562
[22/200][5520/5963] Loss: 0.179118
[22/200][5640/5963] Loss: 0.126588
[22/200][5760/5963] Loss: 0.127938
[22/200][5880/5963] Loss: 0.193658
[23/200][120/5963] Loss: 0.111958
[23/200][240/5963] Loss: 0.152307
[23/200][360/5963] Loss: 0.168777
[23/200][480/5963] Loss: 0.124157
[23/200][600/5963] Loss: 0.141276
[23/200][720/5963] Loss: 0.174126
[23/200][840/5963] Loss: 0.067323
[23/200][960/5963] Loss: 0.127091
[23/200][1080/5963] Loss: 0.173560
[23/200][1200/5963] Loss: 0.540443
[23/200][1320/5963] Loss: 0.269863
[23/200][1440/5963] Loss: 0.131552
[23/200][1560/5963] Loss: 0.160759
[23/200][1680/5963] Loss: 0.118796
[23/200][1800/5963] Loss: 0.144650
[23/200][1920/5963] Loss: 0.534966
[23/200][2040/5963] Loss: 0.101052
[23/200][2160/5963] Loss: 0.098683
[23/200][2280/5963] Loss: 0.121675
[23/200][2400/5963] Loss: 0.138163
[23/200][2520/5963] Loss: 0.096460
[23/200][2640/5963] Loss: 0.392557
[23/200][2760/5963] Loss: 0.068248
[23/200][2880/5963] Loss: 0.209029
[23/200][3000/5963] Loss: 0.517153
[23/200][3120/5963] Loss: 0.133030
[23/200][3240/5963] Loss: 0.074561
[23/200][3360/5963] Loss: 0.146758
[23/200][3480/5963] Loss: 0.354847
[23/200][3600/5963] Loss: 0.261272
[23/200][3720/5963] Loss: 0.114372
[23/200][3840/5963] Loss: 0.072293
[23/200][3960/5963] Loss: 0.172338
[23/200][4080/5963] Loss: 0.468862
[23/200][4200/5963] Loss: 0.182879
[23/200][4320/5963] Loss: 0.265547
[23/200][4440/5963] Loss: 0.192494
[23/200][4560/5963] Loss: 0.103215
[23/200][4680/5963] Loss: 0.802907
[23/200][4800/5963] Loss: 0.151786
[23/200][4920/5963] Loss: 0.158991
[23/200][5040/5963] Loss: 0.256146
[23/200][5160/5963] Loss: 0.095801
[23/200][5280/5963] Loss: 0.120782
[23/200][5400/5963] Loss: 0.180031
[23/200][5520/5963] Loss: 0.619711
[23/200][5640/5963] Loss: 0.079930
[23/200][5760/5963] Loss: 0.065817
[23/200][5880/5963] Loss: 0.191834
[24/200][120/5963] Loss: 0.346303
[24/200][240/5963] Loss: 0.131132
[24/200][360/5963] Loss: 0.190844
[24/200][480/5963] Loss: 0.089693
[24/200][600/5963] Loss: 0.105811
[24/200][720/5963] Loss: 0.082546
[24/200][840/5963] Loss: 0.492999
[24/200][960/5963] Loss: 0.237233
[24/200][1080/5963] Loss: 0.092886
[24/200][1200/5963] Loss: 0.151613
[24/200][1320/5963] Loss: 0.147191
[24/200][1440/5963] Loss: 0.122150
[24/200][1560/5963] Loss: 0.366166
[24/200][1680/5963] Loss: 0.167857
[24/200][1800/5963] Loss: 0.111526
[24/200][1920/5963] Loss: 0.320166
[24/200][2040/5963] Loss: 0.101910
[24/200][2160/5963] Loss: 0.116676
[24/200][2280/5963] Loss: 0.144384
[24/200][2400/5963] Loss: 0.109965
[24/200][2520/5963] Loss: 0.295699
[24/200][2640/5963] Loss: 0.492219
[24/200][2760/5963] Loss: 0.226914
[24/200][2880/5963] Loss: 0.196634
[24/200][3000/5963] Loss: 0.116032
[24/200][3120/5963] Loss: 0.095186
[24/200][3240/5963] Loss: 0.855976
[24/200][3360/5963] Loss: 0.093974
[24/200][3480/5963] Loss: 0.115682
[24/200][3600/5963] Loss: 0.082865
[24/200][3720/5963] Loss: 0.091413
[24/200][3840/5963] Loss: 0.111426
[24/200][3960/5963] Loss: 0.380840
[24/200][4080/5963] Loss: 0.238600
[24/200][4200/5963] Loss: 0.102798
[24/200][4320/5963] Loss: 0.127436
[24/200][4440/5963] Loss: 0.101257
[24/200][4560/5963] Loss: 0.257328
[24/200][4680/5963] Loss: 0.080808
[24/200][4800/5963] Loss: 0.105100
[24/200][4920/5963] Loss: 0.118933
[24/200][5040/5963] Loss: 0.079528
[24/200][5160/5963] Loss: 0.181296
[24/200][5280/5963] Loss: 0.110797
[24/200][5400/5963] Loss: 0.102191
[24/200][5520/5963] Loss: 0.109389
[24/200][5640/5963] Loss: 0.205403
[24/200][5760/5963] Loss: 0.268778
[24/200][5880/5963] Loss: 0.069906
[25/200][120/5963] Loss: 0.255398
[25/200][240/5963] Loss: 0.242523
[25/200][360/5963] Loss: 0.117947
[25/200][480/5963] Loss: 0.210015
[25/200][600/5963] Loss: 0.158454
[25/200][720/5963] Loss: 0.303562
[25/200][840/5963] Loss: 0.082999
[25/200][960/5963] Loss: 0.227627
[25/200][1080/5963] Loss: 0.396116
[25/200][1200/5963] Loss: 0.336688
[25/200][1320/5963] Loss: 0.102112
[25/200][1440/5963] Loss: 0.233860
[25/200][1560/5963] Loss: 0.158107
[25/200][1680/5963] Loss: 0.318620
[25/200][1800/5963] Loss: 0.124490
[25/200][1920/5963] Loss: 0.149542
[25/200][2040/5963] Loss: 0.103246
[25/200][2160/5963] Loss: 0.147975
[25/200][2280/5963] Loss: 0.073152
[25/200][2400/5963] Loss: 0.463672
[25/200][2520/5963] Loss: 0.367874
[25/200][2640/5963] Loss: 0.328280
[25/200][2760/5963] Loss: 0.374506
[25/200][2880/5963] Loss: 0.097498
[25/200][3000/5963] Loss: 0.097833
[25/200][3120/5963] Loss: 0.071255
[25/200][3240/5963] Loss: 0.184006
[25/200][3360/5963] Loss: 0.189943
[25/200][3480/5963] Loss: 0.078294
[25/200][3600/5963] Loss: 0.092891
[25/200][3720/5963] Loss: 0.161794
[25/200][3840/5963] Loss: 0.083128
[25/200][3960/5963] Loss: 0.314302
[25/200][4080/5963] Loss: 0.378472
[25/200][4200/5963] Loss: 0.116558
[25/200][4320/5963] Loss: 0.101664
[25/200][4440/5963] Loss: 0.092694
[25/200][4560/5963] Loss: 0.145160
[25/200][4680/5963] Loss: 0.082009
[25/200][4800/5963] Loss: 0.118395
[25/200][4920/5963] Loss: 0.192418
[25/200][5040/5963] Loss: 0.101984
[25/200][5160/5963] Loss: 0.119053
[25/200][5280/5963] Loss: 0.240595
[25/200][5400/5963] Loss: 0.094321
[25/200][5520/5963] Loss: 0.166930
[25/200][5640/5963] Loss: 0.058624
[25/200][5760/5963] Loss: 0.145344
[25/200][5880/5963] Loss: 0.477880
Start validation set
----------dd--e---b---t---o-----  i--i--  t------a----t--l--------m--------r---l---a-------  -d------ -----------o-----------------a---------   -d-i------  -d---i----n------   ---m-----ii--s--t--ii--o--------mi-----,----  1------- -gg------m---aa----l-s------  rr-ii--c-h---i-i--e----.---------- => debto ii tatlmrla d oa di din mistiomi, 1 gmals richiie., gt: debbo intrattenerla d’urgenza di due quistioni, le quali richie¬
-----------------------------aa----t---------u-------   s-----a------u----e----d----e----n----tt---i----,-----  --n---o-----n------  f-------e--------  f----a----l--l---a--------  ----e----g-----ii--s---t---e----a-----g---i--e-----------e------,,,-  --------d------------------------------------ => atu sauedenti, non fe falla egisteagiee, d, gt: altri precedenti, non fu fatta registrazione, cosi
Total number of images in validation set:     2000
Test loss: 111.428327, accuracy: 0.003500
Character error rate mean: 0.5086; Character error rate sd: 0.2732
Word error rate mean: 1.0511; Word error rate sd: 0.4781
Start validation set
-------------bb---r-i--n--g--i-nn-g----  t-h-e----m-------  a---------q---u---a-i-nn--t-ee-d-----------  ww--i---hh----------  U----u-nn--i---v--ee--r--s--a---l-------  J---u---r--i-ss--p------u---d-e--n--c--e-------——----t-h--a---t-------------- => bringing them aquainted wih Uuniversal Jurispudence—that, gt: bringing them acquainted with Universal Jurisprudence—that
---t-hh--e-----  h--uu---n---d--a-----m--e---n---t---a--l---------  o-r--------  s----a-----y---  -thh-ee------  -r----a----d--i--c--a-----l--------  i--dd----e------a---------  b-----e--l-----nn--g---i--gg----- -too-----  j-----u---rr-ii----¬--- => the hundamental or say the radical idea belngig to juri¬, gt: the fundamental or say the radical idea belonging to juris¬
Total number of images in validation set:     2000
Test loss: 8.700454, accuracy: 0.346000
Character error rate mean: 0.0820; Character error rate sd: 0.6629
Word error rate mean: 0.2298; Word error rate sd: 0.3379
Saving epoch experiments/expr_ICFHR_27Mar_alph_werr_fixed_extended/netCRNN_25_5963.pth
[26/200][120/5963] Loss: 0.097235
[26/200][240/5963] Loss: 0.075600
[26/200][360/5963] Loss: 0.123955
[26/200][480/5963] Loss: 0.181482
[26/200][600/5963] Loss: 0.131383
[26/200][720/5963] Loss: 0.123113
[26/200][840/5963] Loss: 0.178897
[26/200][960/5963] Loss: 0.072373
[26/200][1080/5963] Loss: 0.086039
[26/200][1200/5963] Loss: 0.291275
[26/200][1320/5963] Loss: 0.140523
[26/200][1440/5963] Loss: 0.109341
[26/200][1560/5963] Loss: 0.111572
[26/200][1680/5963] Loss: 0.095142
[26/200][1800/5963] Loss: 0.098245
[26/200][1920/5963] Loss: 0.226547
[26/200][2040/5963] Loss: 0.530176
[26/200][2160/5963] Loss: 0.403919
[26/200][2280/5963] Loss: 0.104820
[26/200][2400/5963] Loss: 0.647068
[26/200][2520/5963] Loss: 0.363492
[26/200][2640/5963] Loss: 0.063091
[26/200][2760/5963] Loss: 0.075138
[26/200][2880/5963] Loss: 0.061888
[26/200][3000/5963] Loss: 0.319920
[26/200][3120/5963] Loss: 0.059359
[26/200][3240/5963] Loss: 0.365214
[26/200][3360/5963] Loss: 0.219498
[26/200][3480/5963] Loss: 0.053402
[26/200][3600/5963] Loss: 0.247805
[26/200][3720/5963] Loss: 0.107871
[26/200][3840/5963] Loss: 0.120905
[26/200][3960/5963] Loss: -0.128836
[26/200][4080/5963] Loss: 0.213608
[26/200][4200/5963] Loss: 0.114298
[26/200][4320/5963] Loss: 0.096616
[26/200][4440/5963] Loss: 0.071989
[26/200][4560/5963] Loss: 0.502637
[26/200][4680/5963] Loss: 0.579125
[26/200][4800/5963] Loss: 0.089294
[26/200][4920/5963] Loss: 0.101196
[26/200][5040/5963] Loss: 0.111381
[26/200][5160/5963] Loss: 0.129574
[26/200][5280/5963] Loss: 0.051635
[26/200][5400/5963] Loss: 0.066068
[26/200][5520/5963] Loss: 0.116768
[26/200][5640/5963] Loss: 0.209580
[26/200][5760/5963] Loss: 0.140871
[26/200][5880/5963] Loss: 0.117731
[27/200][120/5963] Loss: 0.098947
[27/200][240/5963] Loss: 0.173249
[27/200][360/5963] Loss: 0.106500
[27/200][480/5963] Loss: 0.045487
[27/200][600/5963] Loss: 0.246746
[27/200][720/5963] Loss: 0.056748
[27/200][840/5963] Loss: 0.108595
[27/200][960/5963] Loss: 0.075911
[27/200][1080/5963] Loss: 0.287487
[27/200][1200/5963] Loss: 0.264799
[27/200][1320/5963] Loss: 0.289060
[27/200][1440/5963] Loss: 0.130290
[27/200][1560/5963] Loss: 0.076468
[27/200][1680/5963] Loss: 0.097615
[27/200][1800/5963] Loss: 0.130207
[27/200][1920/5963] Loss: 0.059532
[27/200][2040/5963] Loss: 0.425428
[27/200][2160/5963] Loss: 0.291089
[27/200][2280/5963] Loss: 0.093644
[27/200][2400/5963] Loss: 0.066824
[27/200][2520/5963] Loss: 0.114275
[27/200][2640/5963] Loss: 0.062012
[27/200][2760/5963] Loss: 0.060077
[27/200][2880/5963] Loss: 0.250143
[27/200][3000/5963] Loss: 0.143797
[27/200][3120/5963] Loss: 0.119642
[27/200][3240/5963] Loss: 0.145471
[27/200][3360/5963] Loss: 0.069209
[27/200][3480/5963] Loss: 0.147003
[27/200][3600/5963] Loss: 0.331729
[27/200][3720/5963] Loss: 0.057224
[27/200][3840/5963] Loss: 0.103851
[27/200][3960/5963] Loss: 0.047612
[27/200][4080/5963] Loss: 0.086525
[27/200][4200/5963] Loss: 0.057743
[27/200][4320/5963] Loss: 0.059823
[27/200][4440/5963] Loss: 0.066984
[27/200][4560/5963] Loss: 0.357860
[27/200][4680/5963] Loss: 0.264259
[27/200][4800/5963] Loss: 0.200701
[27/200][4920/5963] Loss: 0.115540
[27/200][5040/5963] Loss: 0.265365
[27/200][5160/5963] Loss: 0.378795
[27/200][5280/5963] Loss: 0.064385
[27/200][5400/5963] Loss: 0.080381
[27/200][5520/5963] Loss: 0.099194
[27/200][5640/5963] Loss: 0.042126
[27/200][5760/5963] Loss: 0.169134
[27/200][5880/5963] Loss: 0.050360
[28/200][120/5963] Loss: 0.303672
[28/200][240/5963] Loss: 0.124764
[28/200][360/5963] Loss: 0.161338
[28/200][480/5963] Loss: 0.081961
[28/200][600/5963] Loss: 0.081353
[28/200][720/5963] Loss: 0.106090
[28/200][840/5963] Loss: 0.158694
[28/200][960/5963] Loss: 0.127724
[28/200][1080/5963] Loss: 0.107547
[28/200][1200/5963] Loss: 0.130104
[28/200][1320/5963] Loss: 0.132802
[28/200][1440/5963] Loss: 0.138567
[28/200][1560/5963] Loss: 0.182503
[28/200][1680/5963] Loss: 0.160344
[28/200][1800/5963] Loss: 0.169429
[28/200][1920/5963] Loss: 0.164552
[28/200][2040/5963] Loss: 0.122469
[28/200][2160/5963] Loss: 0.078333
[28/200][2280/5963] Loss: 0.092293
[28/200][2400/5963] Loss: 0.224610
[28/200][2520/5963] Loss: 0.095775
[28/200][2640/5963] Loss: 0.086926
[28/200][2760/5963] Loss: 0.093402
[28/200][2880/5963] Loss: 0.075128
[28/200][3000/5963] Loss: 0.304849
[28/200][3120/5963] Loss: 0.325846
[28/200][3240/5963] Loss: 0.096454
[28/200][3360/5963] Loss: 0.423042
[28/200][3480/5963] Loss: 0.082529
[28/200][3600/5963] Loss: 0.727325
[28/200][3720/5963] Loss: 0.067242
[28/200][3840/5963] Loss: 0.066691
[28/200][3960/5963] Loss: 0.077619
[28/200][4080/5963] Loss: 0.055594
[28/200][4200/5963] Loss: 0.092323
